<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jerry's Blog</title>
    <description></description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 21 Aug 2020 00:44:27 +0900</pubDate>
    <lastBuildDate>Fri, 21 Aug 2020 00:44:27 +0900</lastBuildDate>
    <generator>Jekyll v3.9.0</generator>
    
      <item>
        <title>Paper Reading Roadmap</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;본 포스팅은 &lt;a href=&quot;http://dsba.korea.ac.kr&quot;&gt;고려대학교 산업경영공학부 Data Science &amp;amp; Business Analytics 연구실&lt;/a&gt;의 &lt;a href=&quot;https://www.facebook.com/groups/TensorFlowKR/permalink/1275047779502944/&quot;&gt;강필성 교수님의 자료&lt;/a&gt;를 정리한 포스팅입니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;contents-of-posting&quot;&gt;Contents of Posting&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#paper-reading-roadmap&quot;&gt;Paper Reading Roadmap&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#ml-basics&quot;&gt;ML Basics&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#data-mining&quot;&gt;Data Mining&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#general&quot;&gt;General&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#patter-mining&quot;&gt;Patter Mining&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#clustering&quot;&gt;Clustering&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#artificial-intelligence&quot;&gt;Artificial Intelligence&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#general-1&quot;&gt;General&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#reinforcement-learning&quot;&gt;Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#transfer-learning&quot;&gt;Transfer Learning&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#supervised-learning&quot;&gt;Supervised Learning&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#kernel-machines&quot;&gt;Kernel Machines&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#ensemble&quot;&gt;Ensemble&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#semi-supervvised-learning&quot;&gt;Semi-supervvised Learning&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#unsupervised-learning&quot;&gt;Unsupervised Learning&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#neural-network&quot;&gt;Neural Network&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#general-2&quot;&gt;General&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#structure&quot;&gt;Structure&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#learning-strategies&quot;&gt;Learning Strategies&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#nlp&quot;&gt;NLP&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#general-3&quot;&gt;General&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#topic-modeling&quot;&gt;Topic Modeling&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#repersentation-learning&quot;&gt;Repersentation Learning&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#classification&quot;&gt;Classification&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#summarization&quot;&gt;Summarization&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#machine-translation&quot;&gt;Machine Translation&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#question-answering&quot;&gt;Question Answering&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#vision&quot;&gt;Vision&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#classification-1&quot;&gt;Classification&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#object-detection&quot;&gt;Object Detection&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#localization--segmentation&quot;&gt;Localization &amp;amp; Segmentation&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;paper-reading-roadmap&quot;&gt;Paper Reading Roadmap&lt;/h1&gt;

&lt;h2 id=&quot;ml-basics&quot;&gt;ML Basics&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;The matrix calculus you need for deep learning&lt;/li&gt;
  &lt;li&gt;Statistical Modeling: The Two Cultures&lt;/li&gt;
  &lt;li&gt;Machine learning: Trends, perspectives, and prospects&lt;/li&gt;
  &lt;li&gt;An introduction to ROC analysis&lt;/li&gt;
  &lt;li&gt;Learning from imbalanced data&lt;/li&gt;
  &lt;li&gt;Variational inference: A review for statisticians&lt;/li&gt;
  &lt;li&gt;The expectation-maximization algorithm&lt;/li&gt;
  &lt;li&gt;Dimension Reduction: A Guided Tour&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-mining&quot;&gt;Data Mining&lt;/h2&gt;

&lt;h3 id=&quot;general&quot;&gt;General&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://dl.acm.org/doi/10.1145/1132960.1132963&quot;&gt;Interestingness Measures for Data Mining: A Survey&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf&quot;&gt;The PageRank citation ranking: Bringing order to the web&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://link.springer.com/content/pdf/10.1007/978-3-642-28108-2_19.pdf&quot;&gt;Process Mining Manifesto&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.jmlr.org/papers/volume3/guyon03a/guyon03a.pdf&quot;&gt;An Introduction to Variable and Feature Selection&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;patter-mining&quot;&gt;Patter Mining&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://web.stanford.edu/class/cs345d-01/rl/ar-mining.pdf&quot;&gt;Fast Algorithm for Mining Association Rules&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://dl.acm.org/doi/10.1145/3314107&quot;&gt;A survey of sequential pattern mining&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1805.10515.pdf&quot;&gt;A Survey of Parallel Sequential Pattern Mining&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;clustering&quot;&gt;Clustering&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf&quot;&gt;A density-based algorithm for discovering clusters in large spatial databases with noise&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://users.eecs.northwestern.edu/~yingliu/datamining_papers/survey.pdf&quot;&gt;Data Clustering: A Review&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cs.nju.edu.cn/zhouzh/zhouzh.files/course/dm/reading/reading06/grabmeier_dmkd02.pdf&quot;&gt;Techniques of Cluster Algorithms in Data Mining&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cc.gatech.edu/~isbell/reading/papers/berkhin02survey.pdf&quot;&gt;Survey of Clustering Data Mining Techniques&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://web.itu.edu.tr/sgunduz/courses/verimaden/paper/validity_survey.pdf&quot;&gt;On Clustering Validation Techniques&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cran.r-project.org/web/packages/clValid/vignettes/clValid.pdf&quot;&gt;clValid: An R Package for Cluster Validation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;artificial-intelligence&quot;&gt;Artificial Intelligence&lt;/h2&gt;

&lt;h3 id=&quot;general-1&quot;&gt;General&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.iro.umontreal.ca/~lisa/pointeurs/TR1312.pdf&quot;&gt;Learning Deep Architectures for AI&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1206.5538.pdf&quot;&gt;Representation learning: A review and new perspectives&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf&quot;&gt;Generative Adversarial Networks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.nature.com/articles/nature14544&quot;&gt;From evolutionary computation to the evolution of things&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.nature.com/articles/nature14541&quot;&gt;Probabilistic machine learning and artificial intelligence&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1908.00709.pdf&quot;&gt;AutoML: A Survey of the State-of-the-Art&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reinforcement-learning&quot;&gt;Reinforcement Learning&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://deepmind.com/research/publications/human-level-control-through-deep-reinforcement-learning&quot;&gt;Human-level control through deep reinforcement&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://deepmind.com/research/publications/mastering-game-go-deep-neural-networks-tree-search&quot;&gt;Mastering the game of Go with deep neural networks and tree search&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1811.12560.pdf&quot;&gt;An Introduction to Deep Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1803.10122.pdf&quot;&gt;World Models&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;transfer-learning&quot;&gt;Transfer Learning&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://papers.nips.cc/paper/5027-zero-shot-learning-through-cross-modal-transfer.pdf&quot;&gt;Zero-shot learning through cross-modal transfer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1708.01547.pdf&quot;&gt;Lifelong Learning with Dynamically Expandable Networks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;supervised-learning&quot;&gt;Supervised Learning&lt;/h2&gt;

&lt;h3 id=&quot;kernel-machines&quot;&gt;Kernel Machines&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;An Introduction to Kernel-based Learning Algorithms&lt;/li&gt;
  &lt;li&gt;A Tutorial on Support Vector Machine for Pattern Recognition&lt;/li&gt;
  &lt;li&gt;A Tutorial on Support Vector Regression&lt;/li&gt;
  &lt;li&gt;A Tutorial on nu-Support Vector Machines&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ensemble&quot;&gt;Ensemble&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Bagging Predictors&lt;/li&gt;
  &lt;li&gt;Random Forests&lt;/li&gt;
  &lt;li&gt;A short introduction to boosting&lt;/li&gt;
  &lt;li&gt;Greedy Function Approximation: A Gradient Boosting Machine&lt;/li&gt;
  &lt;li&gt;Gradient Boosting Machine, A Tutorial&lt;/li&gt;
  &lt;li&gt;XGBoost: A Scalable Tree Boosting System&lt;/li&gt;
  &lt;li&gt;LightGBM: A Highly Efficient Gradient Boosting Decision Tree&lt;/li&gt;
  &lt;li&gt;CatBoost : unbiased boosting with categorical features&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;semi-supervvised-learning&quot;&gt;Semi-supervvised Learning&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Combining Labeled and Unlabeled Data with Co-Training&lt;/li&gt;
  &lt;li&gt;Semi-supervised Learning with Deep Generative Models&lt;/li&gt;
  &lt;li&gt;Semi-Supervised Classification with Graph Convolutional Networks&lt;/li&gt;
  &lt;li&gt;MixMatch: A Holistic Approach to Semi-Supervised Learning&lt;/li&gt;
  &lt;li&gt;ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring&lt;/li&gt;
  &lt;li&gt;FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;unsupervised-learning&quot;&gt;Unsupervised Learning&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Anomaly Detection: A Survey&lt;/li&gt;
  &lt;li&gt;Deep Learning for Anomaly Detection: A Survey&lt;/li&gt;
  &lt;li&gt;A Review of Novelty Detection&lt;/li&gt;
  &lt;li&gt;LOF: Identifying Density-Based Local Outliers&lt;/li&gt;
  &lt;li&gt;Support Vector Data Description&lt;/li&gt;
  &lt;li&gt;Isolation Forest&lt;/li&gt;
  &lt;li&gt;Isolation-based Anomaly Detection&lt;/li&gt;
  &lt;li&gt;DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;neural-network&quot;&gt;Neural Network&lt;/h2&gt;

&lt;h3 id=&quot;general-2&quot;&gt;General&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Deep learning&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;structure&quot;&gt;Structure&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Long Short-Term Memory&lt;/li&gt;
  &lt;li&gt;LSTM: A Search Space Odyssey&lt;/li&gt;
  &lt;li&gt;Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling Sequence to sequence learning with neural networks&lt;/li&gt;
  &lt;li&gt;Memory Networks&lt;/li&gt;
  &lt;li&gt;End-To-End Memory Networks&lt;/li&gt;
  &lt;li&gt;WaveNet: A Generative Model for Raw Audio&lt;/li&gt;
  &lt;li&gt;An Introduction to Variational Autoencoders&lt;/li&gt;
  &lt;li&gt;A Comprehensive Survey on Graph Neural Networks&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;learning-strategies&quot;&gt;Learning Strategies&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift&lt;/li&gt;
  &lt;li&gt;Dropout: A Simple Way to Prevent Neural Networks from Overtting&lt;/li&gt;
  &lt;li&gt;ADAM: A Method for Stochastic Optimization&lt;/li&gt;
  &lt;li&gt;An overview of gradient descent optimization algorithms&lt;/li&gt;
  &lt;li&gt;Layer normalization Group normalization&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;nlp&quot;&gt;NLP&lt;/h2&gt;

&lt;h3 id=&quot;general-3&quot;&gt;General&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Natural Language Processing (Almost) from Scratch&lt;/li&gt;
  &lt;li&gt;Advances in natural language processing&lt;/li&gt;
  &lt;li&gt;Recent trends in deep learning based natural language processing&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;topic-modeling&quot;&gt;Topic Modeling&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;An introduction to latent semantic analysis&lt;/li&gt;
  &lt;li&gt;Probabilistic latent semantic analysis&lt;/li&gt;
  &lt;li&gt;Probabilistic topic models&lt;/li&gt;
  &lt;li&gt;Latent Dirichlet Allocation&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;repersentation-learning&quot;&gt;Repersentation Learning&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;A Neural Probabilistic Language Model&lt;/li&gt;
  &lt;li&gt;Distributed representations of words and phrases and their compositionality&lt;/li&gt;
  &lt;li&gt;Efficient Estimation of Word Representations in Vector Space&lt;/li&gt;
  &lt;li&gt;Glove: Global vectors for word representation&lt;/li&gt;
  &lt;li&gt;Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation Enriching word vectors with subword information&lt;/li&gt;
  &lt;li&gt;Bert: Pre-training of deep bidirectional transformers for language understanding&lt;/li&gt;
  &lt;li&gt;Deep contextualized word representations&lt;/li&gt;
  &lt;li&gt;Improving language understanding by generative pre-training&lt;/li&gt;
  &lt;li&gt;Language models are unsupervised multitask learners&lt;/li&gt;
  &lt;li&gt;Language Models are Few-Shot LearnersA Neural Probabilistic Language Model&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;classification&quot;&gt;Classification&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Convolutional neural networks for sentence classification&lt;/li&gt;
  &lt;li&gt;Deep learning for sentiment analysis: A survey&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;summarization&quot;&gt;Summarization&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;TextRank: Bringing Order into Texts&lt;/li&gt;
  &lt;li&gt;A Neural Attention Model for Abstractive Sentence Summarization&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;machine-translation&quot;&gt;Machine Translation&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;On the Properties of Neural Machine Translation: Encoder-Decoder Approaches&lt;/li&gt;
  &lt;li&gt;Effective Approaches to Attention-based Neural Machine Translation&lt;/li&gt;
  &lt;li&gt;Neural Machine Translation by Jointly Learning to Aligh and Translate&lt;/li&gt;
  &lt;li&gt;Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation&lt;/li&gt;
  &lt;li&gt;Attention is all you need&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;question-answering&quot;&gt;Question Answering&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;VQA: Visual Question Answering&lt;/li&gt;
  &lt;li&gt;Ask Me Anything: Dynamic Memory Networks for Natural Language Processing&lt;/li&gt;
  &lt;li&gt;Squad: 100,000+ questions for machine comprehension of text&lt;/li&gt;
  &lt;li&gt;Know what you don’t know: Unanswerable questions for SQuAD&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;vision&quot;&gt;Vision&lt;/h2&gt;

&lt;h3 id=&quot;classification-1&quot;&gt;Classification&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf&quot;&gt;Imagenet classification with deep convolutional neural networks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1311.2901.pdf&quot;&gt;Visualizing and understanding convolutional networks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1409.1556.pdf&quot;&gt;Very Deep Convolutional Networks for Large-Scale Image Recognition&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1409.4842.pdf&quot;&gt;Going deeper with convolutions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1512.03385.pdf&quot;&gt;Deep residual learning for image recognition&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1608.06993.pdf&quot;&gt;Densely Connected Convolutional Networks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;object-detection&quot;&gt;Object Detection&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1312.6229.pdf&quot;&gt;Overfeat: Integrated recognition, localization and detection using convolutional networks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1311.2524.pdf&quot;&gt;Rich feature hierarchies for accurate object detection and semantic segmentation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1504.08083.pdf&quot;&gt;Fast R-CNN&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1506.01497.pdf&quot;&gt;Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1506.02640.pdf&quot;&gt;You Only Look Once: Unified, Real-Time Object Detection&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1612.08242.pdf&quot;&gt;YOLO9000: Better, Faster, Stronger&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1804.02767.pdf&quot;&gt;YOLOv3: An Incremental Improvement&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2004.10934.pdf&quot;&gt;YOLOv4: Optimal Speed and Accuracy of Object Detection&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;localization--segmentation&quot;&gt;Localization &amp;amp; Segmentation&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1505.04597.pdf&quot;&gt;U-Net: Convolutional Networks for Biomedical Image Segmentation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1512.04150.pdf&quot;&gt;Learning deep features for discriminative localization&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1610.02391.pdf&quot;&gt;Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 21 Aug 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/08/21/paper_roadmap/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/08/21/paper_roadmap/</guid>
        
        <category>Paper</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>RAPIDS APIs ( cuML )</title>
        <description>&lt;p&gt;어제는 &lt;a href=&quot;https://jjerry-k.github.io/deeplearning/2020/08/19/rapids/&quot;&gt;RAPIDS에 대한 소개와 RAPIDS APIs 중 cuDF 에 대한 예제에 대한 포스팅&lt;/a&gt;을 했습니다.&lt;/p&gt;

&lt;p&gt;오늘은 RAPIDS APIS 중 &lt;a href=&quot;https://docs.rapids.ai/api/cuml/stable/&quot;&gt;cuML&lt;/a&gt; 에 대한 예제 포스팅을 간.단.하.게 해보겠습니다.&lt;/p&gt;

&lt;p&gt;비교를 위해 KNN Classifier를 준비하였고 성능 비교를 위해 &lt;a href=&quot;https://scikit-learn.org/stable/&quot;&gt;Scikit-learn&lt;/a&gt; 을 사용하였습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;c1&quot;&gt;# %%
# RAPIDS cuML kNN model
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;cudf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cuml&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;cuml.neighbors&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KNeighborsClassifier&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cuKNeighbors&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.neighbors&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KNeighborsClassifier&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;skKNeighbors&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;========================================&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;========================================&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;============= Using cuML ===============&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;========================================&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;========================================&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cudf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'./mnist/train.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cudf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'./mnist/test.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cuKNeighbors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_neighbors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;785&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# y_hat = model.predict(test) # Exception occured (version 0.14.0) 
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f&quot;Elapsed Time: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;========================================&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;========================================&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;========== Using Scikit-learn ==========&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;========================================&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;========================================&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'./mnist/train.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'./mnist/test.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;skKNeighbors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_neighbors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;785&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# y_hat = model.predict(test)
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f&quot;Elapsed Time: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;o&quot;&gt;========================================&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;========================================&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=============&lt;/span&gt; Using cuML &lt;span class=&quot;o&quot;&gt;===============&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;========================================&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;========================================&lt;/span&gt;
Elapsed Time: 0.3921339511871338

&lt;span class=&quot;o&quot;&gt;========================================&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;========================================&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;==========&lt;/span&gt; Using Scikit-learn &lt;span class=&quot;o&quot;&gt;==========&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;========================================&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;========================================&lt;/span&gt;
Elapsed Time: 23.88076663017273

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test 시 성능도 비교하려했으나 cuML 버전 에러로 인해 테스트는 못했습니다.&lt;/p&gt;

&lt;p&gt;그래도 fit 부분에서 매우 큰 차이를 보입니다!&lt;/p&gt;

&lt;p&gt;역시나….GPU네요!&lt;/p&gt;

&lt;h2 id=&quot;ps&quot;&gt;P.S&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;너무 간단하게 테스트하는건가…&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 20 Aug 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/08/20/rapids-cuml/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/08/20/rapids-cuml/</guid>
        
        <category>Tools</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>RAPIDS!!!</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;RAPIDS is a suite of software libraries for executing end-to-end data science &amp;amp; analytics pipelines entirely on GPUs.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;위 글은 &lt;a href=&quot;https://rapids.ai/index.html&quot;&gt;RAPIDS 공식 홈페이지&lt;/a&gt;에서 가져온 내용입니다.&lt;/p&gt;

&lt;p&gt;말 그대로 모든 과정을 GPU 에서 실행하도록 도와주는 라이브러리입니다.&lt;/p&gt;

&lt;h2 id=&quot;prerequisites&quot;&gt;PREREQUISITES&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;GPU&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;NVIDIA Pascal™ or better with &lt;strong&gt;&lt;a href=&quot;https://developer.nvidia.com/cuda-gpus&quot;&gt;compute capability&lt;/a&gt;&lt;/strong&gt; 6.0+&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;OS&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ubuntu 16.04/18.04 or CentOS 7 with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gcc/++&lt;/code&gt; 7.5+&lt;/li&gt;
  &lt;li&gt;See &lt;a href=&quot;https://docs.rapids.ai/notices/rsn0001&quot;&gt;RSN 1&lt;/a&gt; for details on our recent update to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gcc/++&lt;/code&gt; 7.5  RHEL 7 support is provided through CentOS 7 builds/installs&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Docker&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Docker CE v19.03+ and &lt;strong&gt;&lt;a href=&quot;https://github.com/NVIDIA/nvidia-docker#quickstart&quot;&gt;nvidia-container-toolkit&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://rapids.ai/start.html#-docker-container&quot;&gt;Legacy Support&lt;/a&gt; - Docker CE v17-18 and &lt;a href=&quot;https://github.com/NVIDIA/nvidia-docker/wiki/Installation-(version-2.0)&quot;&gt;nvidia-docker2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;CUDA &amp;amp; NVIDIA Drivers&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;One of the following supported versions: &lt;a href=&quot;https://developer.nvidia.com/cuda-10.0-download-archive&quot;&gt;10.0&lt;/a&gt; &amp;amp; v410.48+  &lt;a href=&quot;https://developer.nvidia.com/cuda-10.1-download-archive-update2&quot;&gt;10.1.2&lt;/a&gt; &amp;amp; v418.87+  &lt;a href=&quot;https://developer.nvidia.com/cuda-10.2-download-archive&quot;&gt;10.2&lt;/a&gt; &amp;amp; v440.33+&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;rapids-apis&quot;&gt;RAPIDS APIs&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;RAPIDS 에는 현재 5개의 라이브러리를 제공.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;cuDF ( 요것이 Main )&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Python GPU DataFrame library&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;cuML
    &lt;ul&gt;
      &lt;li&gt;a suite of libraries that implement machine learning algorithms and mathematical primitives functions&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;cuGraph
    &lt;ul&gt;
      &lt;li&gt;a GPU accelerated graph analytics library&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;nvStrings
    &lt;ul&gt;
      &lt;li&gt;a pandas-like API that will be familiar to data engineers &amp;amp; data scientists&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Cyber Log Accelerators(CLX)
    &lt;ul&gt;
      &lt;li&gt;a collection of RAPIDS examples for security analysts, data scientists, and engineers to quickly get started applying RAPIS and GPU acceleration to real-world cybersecurity use cases&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;installation-guide&quot;&gt;Installation Guide&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://rapids.ai/start.html#get-rapids&quot;&gt;https://rapids.ai/start.html#get-rapids&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;anaconda-or-miniconda&quot;&gt;Anaconda or Miniconda&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;설치하는데 시간이 꽤나 오래 걸려요…&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; rapidsai &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; nvidia &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; conda-forge &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; defaults &lt;span class=&quot;nv&quot;&gt;rapids&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0.14 &lt;span class=&quot;nv&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3.7 &lt;span class=&quot;nv&quot;&gt;cudatoolkit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;10.1
&lt;span class=&quot;c&quot;&gt;# cudatoolkit은 사용하는 DL 프레임워크 호환성 고려하세요!&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;example&quot;&gt;Example&lt;/h2&gt;

&lt;p&gt;이번 포스팅에선 cuDF 에 대한 예제를 보여드리려 합니다.&lt;/p&gt;

&lt;p&gt;추가적으로 &lt;a href=&quot;https://dask.org/&quot;&gt;Dask&lt;/a&gt;, &lt;a href=&quot;https://github.com/rapidsai/dask-cudf&quot;&gt;Dask-cuDF&lt;/a&gt; 라는 2개의 라이브러리를 사용합니다.&lt;/p&gt;

&lt;p&gt;먼저 사용할 Package 들을 import 해줍니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;cudf&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dask_cudf&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다음 예시는 pandas와 cudf 를 비교하는 예시입니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Series
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Series&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Pandas&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;gs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cudf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Series&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;cuDF&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dask_gs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dask_cudf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_cudf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;npartitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Dask-cuDF&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dask_gs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Pandas&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;3.0&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;NaN&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;4.0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;float64&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;cuDF&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;       &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;       &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;       &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;null&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;       &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int64&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Dask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuDF&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;       &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;       &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;       &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;null&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;       &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int64&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# DataFrame 
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;reversed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'c'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))})&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Pandas&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;gdf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cudf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;cuDF&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dask_gdf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dask_cudf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_cudf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;npartitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Dask-cuDF&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dask_gdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Pandas&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;19&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;cuDF&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;19&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Dask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuDF&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;19&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Sorting
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Pandas&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;cuDF&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Dask-cuDF&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dask_gdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Pandas&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;19&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;19&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;19&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;cuDF&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;19&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;19&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;19&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Dask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuDF&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;19&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;19&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;19&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이번엔 큰 DataFrame을 만들어서 sorting 속도를 비교하는 코드입니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# %%
# Speed Test
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_element&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000000&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_element&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;reversed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_element&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'c'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1200000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_element&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)})&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;gdf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cudf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dask_gdf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dask_cudf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_cudf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;npartitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dask_gdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;실행 속도는 ipython의 &lt;a href=&quot;https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-timeit&quot;&gt;timeit&lt;/a&gt; 이라는 magic function 을 이용하였습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timeit&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;c&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timeit&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;c&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timeit&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dask_gdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;c&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;num_element&lt;/code&gt;를 바꿔가면서 테스트를 해봤습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# num_element = 1000
&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;448&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;µs&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;38.8&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;µs&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;per&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loops&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;mf&quot;&gt;2.84&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ms&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.56&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ms&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;per&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loops&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;mf&quot;&gt;83.4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ms&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;47.7&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ms&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;per&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# num_element = 10000
&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.39&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ms&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;42.8&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;µs&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;per&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loops&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;mf&quot;&gt;3.14&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ms&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.99&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ms&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;per&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loops&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;mf&quot;&gt;89.9&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ms&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;24.3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ms&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;per&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loops&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# num_element = 100000
&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;13.8&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ms&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;467&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;µs&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;per&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loops&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;mf&quot;&gt;5.61&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ms&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.55&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ms&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;per&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loops&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;116&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ms&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;29.3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ms&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;per&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loops&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#num_element = 1000000
&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;225&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ms&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;31.4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ms&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;per&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;mf&quot;&gt;8.17&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ms&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;534&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;µs&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;per&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loops&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;118&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ms&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;27&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ms&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;per&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;±&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loops&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;적은 양에서는 CPU 가 더 빠르지만 점점 대규모로 늘어나니….GPU 가 빠르군요.&lt;/p&gt;

&lt;p&gt;아! Dask_cuDF는 보통 multi gpu 일 때 사용하는데 제가 실험한 환경은 NIPA 수시 사용자…환경이라 V100 단일 환경이었습니다.&lt;/p&gt;

&lt;p&gt;그래서…dask_gdf 에 대한 속도는 믿지 마세요..&lt;/p&gt;

&lt;h2 id=&quot;ps&quot;&gt;P.S&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;서터레스를 많이 받습니다.&lt;/li&gt;
  &lt;li&gt;원인은….’그’ 집회…&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 19 Aug 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/08/19/rapids/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/08/19/rapids/</guid>
        
        <category>Tools</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>개인적인 Vim 설정</title>
        <description>&lt;h1 id=&quot;지극히-개인이-사용하기-위한-vimrc&quot;&gt;지극히 개인이 사용하기 위한 vimrc&lt;/h1&gt;

&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;마음껏 편하신대로 Copy &amp;amp; Paste 하세요!&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;call&lt;/span&gt; plug#begin&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'~/.vim/plugged'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
Plug &lt;span class=&quot;s1&quot;&gt;'davidhalter/jedi-vim'&lt;/span&gt;
Plug &lt;span class=&quot;s1&quot;&gt;'preservim/nerdtree'&lt;/span&gt;
Plug &lt;span class=&quot;s1&quot;&gt;'jeetsukumaran/vim-pythonsense'&lt;/span&gt;
Plug &lt;span class=&quot;s1&quot;&gt;'jiangmiao/auto-pairs'&lt;/span&gt;
Plug &lt;span class=&quot;s1&quot;&gt;'Vimjas/vim-python-pep8-indent'&lt;/span&gt;
Plug &lt;span class=&quot;s1&quot;&gt;'dense-analysis/ale'&lt;/span&gt;
Plug &lt;span class=&quot;s1&quot;&gt;'neoclide/coc.nvim'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'branch'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'release'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&quot;
Plug &lt;span class=&quot;s1&quot;&gt;'liuchengxu/vista.vim'&lt;/span&gt;
Plug &lt;span class=&quot;s1&quot;&gt;'sheerun/vim-polyglot'&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;&quot;Plug 'python-mode/python-mode', { 'for': 'python', 'branch': 'develop'  }&lt;/span&gt;
Plug &lt;span class=&quot;s1&quot;&gt;'junegunn/seoul256.vim'&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;call&lt;/span&gt; plug#end&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;&quot; 세부 정보 출력&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;nu&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;title&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;showmatch&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ruler&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;&quot; 구문 강조 사용&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;has&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;syntax&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;syntax&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;on&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;endif&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;&quot; 들여쓰기 설정&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;autoindent&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;smartindent&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;tabstop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;shiftwidth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;softtabstop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;smarttab&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;expandtab&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;&quot; 한글 입력 설정&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;encoding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;utf&lt;span class=&quot;m&quot;&gt;-8&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;termencoding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;utf&lt;span class=&quot;m&quot;&gt;-8&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;&quot; 커서가 있는 줄을 강조함&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;cursorline&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;&quot; 상태바 표시를 항상한다&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;laststatus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;statusline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;\ %&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;%&lt;span class=&quot;k&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;%&lt;span class=&quot;k&quot;&gt;v&lt;/span&gt;\ &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;%P&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;%&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;%&lt;span class=&quot;k&quot;&gt;a&lt;/span&gt;\ %&lt;span class=&quot;k&quot;&gt;h&lt;/span&gt;%&lt;span class=&quot;k&quot;&gt;m&lt;/span&gt;%&lt;span class=&quot;k&quot;&gt;r&lt;/span&gt;\ %F\
&lt;span class=&quot;c&quot;&gt;&quot; 검색 설정&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ignorecase&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;&quot; 마지막으로 수정된 곳에 커서를 위치함&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;au&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;BufReadPost&lt;/span&gt; *
&lt;span class=&quot;se&quot;&gt;\&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;'\&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt; &amp;amp;&amp;amp; &lt;span class=&quot;nb&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;'\&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;$&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt;
&lt;span class=&quot;se&quot;&gt;\&lt;/span&gt; exe &lt;span class=&quot;s2&quot;&gt;&quot;norm g`\&quot;&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt;
&lt;span class=&quot;se&quot;&gt;\&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;endif&lt;/span&gt;


&lt;span class=&quot;c&quot;&gt;&quot;seoul256&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;g:seoul256_background&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;233&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;colo&lt;/span&gt; seoul256
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
        <pubDate>Sun, 16 Aug 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/living/2020/08/16/vimrc/</link>
        <guid isPermaLink="true">http://localhost:4000/living/2020/08/16/vimrc/</guid>
        
        <category>Vim</category>
        
        
        <category>Living</category>
        
      </item>
    
      <item>
        <title>Review: Cycle GAN</title>
        <description>&lt;h1 id=&quot;unpaired-image-to-image-translation-using-cycle-consistent-adversarial-networks&quot;&gt;Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks&lt;/h1&gt;

&lt;p&gt;Author: Jun-Yan Zhu∗, Taesung Park∗, Phillip Isola, Alexei A. Efros&lt;br /&gt;
Date: Mar 30, 2017&lt;br /&gt;
URL: https://arxiv.org/abs/1703.10593&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Image-to-image translation 은 paired data의 상황에서 많이 연구.&lt;/li&gt;
  &lt;li&gt;하지만 실제 환경에선 이런 paired data를 구하기 힘듦.&lt;/li&gt;
  &lt;li&gt;본 논문은 unpaired data 상황에서 Network가 image-to-image 를 잘 학습하는 것에 초점을 맞춤.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cyclegan/Untitled.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cyclegan/Untitled.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cyclegan/Untitled_1.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cyclegan/Untitled_1.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;formulation&quot;&gt;Formulation&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;$X, Y$: X, Y 도메인의 데이터&lt;/li&gt;
  &lt;li&gt;$G, F$: X to Y generator, Y to X generator&lt;/li&gt;
  &lt;li&gt;$D_X, D_Y$: X, Y 도메인에 대한 Discriminator&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;adversarial-loss&quot;&gt;Adversarial Loss&lt;/h2&gt;

\[\mathcal{L}_{GAN}(G, D_Y, X, Y) = \mathbb{E}_{y\sim p_{data}(y)}[\log D_Y(y)] + \mathbb{E}_{x\sim p_{data}(x)}[\log (1 - D_Y(G(x)))]\]

\[\mathcal{L}_{GAN}(F, D_X, Y, X) = \mathbb{E}_{x\sim p_{data}(x)}[\log D_X(x)] + \mathbb{E}_{y\sim p_{data}(y)}[\log (1 - D_x(F(y)))]\]

&lt;h2 id=&quot;cycle-consistency-loss&quot;&gt;Cycle Consistency Loss&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;각각의 X, Y 데이터를 Y, X 데이터로 변환 후 다시  X, Y 데이터 복원.&lt;/li&gt;
&lt;/ul&gt;

\[\mathcal{L}_{cyc}(G, F) = \mathbb{E}_{x\sim p_{data}(x)}[||F(G(x)) - x||_1 + \mathbb{E}_{y\sim p_{data}(y)}[||G(F(y)) - y||_1\]

&lt;h2 id=&quot;full-objective&quot;&gt;Full Objective&lt;/h2&gt;

\[\mathcal{L}(G, F, D_X, D_Y) = \mathcal{L}_{GAN}(G, D_Y, X, Y) + \mathcal{L}_{GAN}(F, D_X, Y, X) + \lambda\mathcal{L}_{cyc}(G, F)\]

\[G^*, F^* = argmin_{G, F}argmax_{D_X, D_Y}\mathcal{L}(G, F, D_X, D_Y)\]

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cyclegan/Untitled_2.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cyclegan/Untitled_2.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;implementation&quot;&gt;Implementation&lt;/h1&gt;

&lt;h2 id=&quot;network-architecture&quot;&gt;Network Architecture&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Generator에서 Instance Normalization 사용.&lt;/li&gt;
  &lt;li&gt;PixelGAN이 아닌 70x70 PatchGAN 사용.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;training-detail&quot;&gt;Training detail&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Loss 에서 $\lambda$ 는 10.&lt;/li&gt;
  &lt;li&gt;Optimizer: Adam&lt;/li&gt;
  &lt;li&gt;Learning rate: 0.002&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;result&quot;&gt;Result&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cyclegan/Untitled_3.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cyclegan/Untitled_3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cyclegan/Untitled_4.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cyclegan/Untitled_4.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cyclegan/Untitled_5.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cyclegan/Untitled_5.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ps&quot;&gt;P.S&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Cycle consistency가 매우 신박&lt;/li&gt;
  &lt;li&gt;Image translation 에선 Instance Normalization !&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Tue, 11 Aug 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/08/11/cycle_gan/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/08/11/cycle_gan/</guid>
        
        <category>Paper</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>Review: Pix2Pix</title>
        <description>&lt;h1 id=&quot;image-to-image-translation-with-conditional-adversarial-networks&quot;&gt;Image-to-Image Translation with Conditional Adversarial Networks&lt;/h1&gt;

&lt;p&gt;Author: Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei A. Efros
Date: Nov 26, 2018
URL: https://arxiv.org/abs/1611.07004&lt;/p&gt;

&lt;p&gt;GAN을 이용한 Image translation 의 시초에 가까운 Pix2Pix를 알아보려고 합니다.&lt;/p&gt;

&lt;p&gt;자세하게 리뷰하진 않을 겁니다.&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;이 논문의 main contribution은 다양한 문제에서 Conditional GAN이 합리적인 결과를 생성한다는 것을 입증하는 것.&lt;/li&gt;
  &lt;li&gt;이를 위해 Image-to-Image translation 으로 연구 진행.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;method&quot;&gt;Method&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;정말 간단한 구조&lt;/li&gt;
  &lt;li&gt;다음 사진은 Edge(Sketch) 영상을 Photo 영상으로 만드는 예시.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_1.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_1.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;objective&quot;&gt;Objective&lt;/h2&gt;

\[\mathcal{L}_{cGAN}(G, D) = \mathbb{E}_{x, y}[\log D(x, y)] + \mathbb{E}_{x, z}[\log (1-D(x, G(x, z))]\]

\[\mathcal{L}_{L1}(G) = \mathbb{E}_{x, y, z}[||y-G(x,z)||_1]\]

\[G^* = argmin_Gmax_D\mathcal{L}_{cGAN}(G, D) + \lambda\mathcal{L}_{L1}(G)\]

&lt;h2 id=&quot;network-architectures&quot;&gt;Network architectures&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;DCGAN 에서 제안한 방법으로 각 block을 구성.
    &lt;ul&gt;
      &lt;li&gt;Convolution → BatchNorm → ReLU&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;generator-with-skips&quot;&gt;Generator with skips&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;U-Net 과 비슷하나 Concatenate를 Add로 변경.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_2.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_2.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;markovian-discriminator-patchgan&quot;&gt;Markovian discriminator (PatchGAN)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;L1, L2 만 사용하면 blurry result가 만들어진다는 것은 많이 알려진 사항.&lt;/li&gt;
  &lt;li&gt;Low frequency 부분에 대한 부분은 L1 loss로 High frequency는 GAN loss 가 담당.&lt;/li&gt;
  &lt;li&gt;좀 더 다양한 High frequency 에 적합하도록 하기 위해 local image patch 에 대해 discriminator를 적용. (PatchGAN)&lt;/li&gt;
  &lt;li&gt;NxN patch 에 대해 각각 real/fake를 판별.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_3.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_3.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;optimization-and-inference&quot;&gt;Optimization and Inference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;D → G 와 같은 순서로 학습 진행&lt;/li&gt;
  &lt;li&gt;Optimizer: Adam
    &lt;ul&gt;
      &lt;li&gt;Learning rate: 0.0002&lt;/li&gt;
      &lt;li&gt;Momentum $\beta_1$: 0.5&lt;/li&gt;
      &lt;li&gt;Momentum $\beta_2$: 0.999&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Batch size: 1~10&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;experimants&quot;&gt;Experimants&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Semantic labels ↔photo&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Architectural labels&lt;/em&gt;→&lt;em&gt;photo&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Map&lt;/em&gt;↔&lt;em&gt;aerial photo&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;BW&lt;/em&gt;→&lt;em&gt;color photos&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Edges&lt;/em&gt;→&lt;em&gt;photo&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Sketch&lt;/em&gt;→&lt;em&gt;photo&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Day&lt;/em&gt;→&lt;em&gt;night&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Thermal&lt;/em&gt;→&lt;em&gt;color photos&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Photo with missing pixels&lt;/em&gt;→*inpainted photo*&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;evaluation-metrics&quot;&gt;Evaluation metrics&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Amazon Mechanical Turk (AMT)&lt;/li&gt;
  &lt;li&gt;FCN-score&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;analysis-of-the--objective-function&quot;&gt;Analysis of the  objective function&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_3.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_4.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_4.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;analysis-of-the-generator-architecture&quot;&gt;Analysis of the generator architecture&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;U-Net 기반의 구조로 했을 때가 훨씬 좋음.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_5.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_5.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_6.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_6.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;from-pixelgans-to-patchgans-to-imagegans&quot;&gt;From PixelGANs to PatchGANs to ImageGANs&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Discriminator의 출력을 1x1, 16x16, 70x70, 286x286과 같이 차례로 키우면서 실험.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_7.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_7.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_8.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_8.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;perceptual-validation&quot;&gt;Perceptual validation&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;사람이 보기에도 L1 + cGAN이 좋음.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_9.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_9.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Colorization에서는 좀 떨어짐.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_10.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_10.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;semantic-segmentation&quot;&gt;Semantic segmentation&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;해당 task 에서는 오히려 L1과 같은 reconstruction loss만을 이용한 구조가 적합해 보임.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_11.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_11.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_12.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_12.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;community-driven-research&quot;&gt;Community-driven Research&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Twitter 에 공개한 후 다른 연구자들의 실험.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_13.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_13.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_14.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/pix2pix/Untitled_14.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ps&quot;&gt;P.S&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;장마철… 물 조심하세요..&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 10 Aug 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/08/10/pix2pix/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/08/10/pix2pix/</guid>
        
        <category>Paper</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>Neptune...? 은 또 뭐여..</title>
        <description>&lt;p&gt;오늘은 &lt;a href=&quot;https://neptune.ai/&quot;&gt;neptune.ai&lt;/a&gt; 라는 툴을 소개시켜 드리려 합니다.&lt;/p&gt;

&lt;p&gt;Jupyter는 아는데…. Neptune은 또 뭐여…. 암튼 이 분야는 참.. 태양계를 좋아하는 듯합니다.&lt;/p&gt;

&lt;p&gt;이는 NN 실험을 편하고 효율적으로 할 수 있게 도와주는 툴입니다.&lt;/p&gt;

&lt;p&gt;각 실험 세팅 별로 Hyper parameter, Metrics를 기록하고 시각화하여 비교할 수 있습니다.&lt;/p&gt;

&lt;p&gt;그리고 개인에겐 &lt;strong&gt;100GB의 저장소를 제공&lt;/strong&gt;하기 때문에 타인과 공유도 가능해요!&lt;/p&gt;

&lt;p&gt;어찌보면 &lt;a href=&quot;https://jjerry-k.github.io/deeplearning/2020/03/01/wandb/&quot;&gt;Weights &amp;amp; Biases&lt;/a&gt; 랑 비슷하죠.&lt;/p&gt;

&lt;p&gt;다음은 &lt;a href=&quot;https://docs.neptune.ai/&quot;&gt;Neptune docs&lt;/a&gt; 에서 가져온 Neptune의 특징입니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;data exploration and analysis → decision science → machine learning and deep learning 와 같은  과정을 수행하는데 적합.&lt;/li&gt;
  &lt;li&gt;Python, Jupyter Notebook, R 에서 동작.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.neptune.ai/integrations/keras.html&quot;&gt;Keras&lt;/a&gt;, &lt;a href=&quot;https://docs.neptune.ai/integrations/pytorch_lightning.html&quot;&gt;PyTorch Lightning&lt;/a&gt;, &lt;a href=&quot;https://docs.neptune.ai/integrations/xgboost.html&quot;&gt;XGBoost&lt;/a&gt;, &lt;a href=&quot;https://docs.neptune.ai/integrations/matplotlib.html&quot;&gt;Matplotlib&lt;/a&gt; 와 같은 ML, DL에 사용되는 Python 라이브러리를 연동(통합).&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.neptune.ai/integrations/mlflow.html#&quot;&gt;MLflow&lt;/a&gt;, &lt;a href=&quot;https://docs.neptune.ai/integrations/tensorboard.html#&quot;&gt;TensorBoard&lt;/a&gt; , &lt;a href=&quot;https://docs.neptune.ai/integrations/sacred.html&quot;&gt;Sacred&lt;/a&gt; 와 같은 Tracking tool 과 연동(통합) 가능.&lt;/li&gt;
  &lt;li&gt;AWS, GCP, Kubernetes, Azure 와 같은 Cloud 와도 원활히 작동.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그럼 실제로 한번 써보도록 하겠습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Sign up 은 넘어갑니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;1-기본-환경-구축&quot;&gt;1. 기본 환경 구축&lt;/h2&gt;

&lt;p&gt;기존 환경에서 쓰실 분들은 쓰셔도 됩니다.&lt;/p&gt;

&lt;p&gt;저는 따로 환경을 만들어서 테스트를 했습니다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda create &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; neptune &lt;span class=&quot;nv&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3.7

conda activate neptune

conda &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;psutil matplotlib tensorflow-gpu &lt;span class=&quot;c&quot;&gt;# 혹은 tensorflow&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;2-neptune-설정&quot;&gt;2. Neptune 설정&lt;/h2&gt;

&lt;p&gt;Neptune을 설치합니다.&lt;/p&gt;

&lt;p&gt;conda를 쓰시는 분들께 보통 conda install 로 설치하라고 말씀을 드리지만.. 이번엔 특별히 pip install로 설치를 추천드립니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/neptune/Untitled.png?raw=true&quot; alt=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/neptune/Untitled.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;설치 후 자신이 사용하는 OS에 맞춰서 API token을 PC에 기입(?) 해주세요.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/neptune/Untitled_1.png?raw=true&quot; alt=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/neptune/Untitled_1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여기까지 하면 세팅은 끝납니다. 그 이후에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Run script&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Result in UI&lt;/code&gt; 부분은 하고 싶으신 분만 해보세요!&lt;/p&gt;

&lt;h2 id=&quot;3-mnist-를-이용한-실험&quot;&gt;3. Mnist 를 이용한 실험&lt;/h2&gt;

&lt;p&gt;다음과 같은 코드를 작성합니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;hashlib&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tempfile&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;neptune&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow.keras&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;callbacks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# For Efficiency
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gpus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;experimental&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;list_physical_devices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'GPU'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gpu&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;experimental&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_memory_growth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;logical_gpus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;experimental&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;list_logical_devices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'GPU'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Physical GPUs,&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logical_gpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Logical GPUs&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;RuntimeError&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
    
&lt;span class=&quot;c1&quot;&gt;# select project
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;neptune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'jjerry-k/mnist'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Define parameters
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PARAMS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'batch_size'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;'n_epochs'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;'shuffle'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;'learning_rate'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;'early_stopping'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;'optimizer'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Adam'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create experiment
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;neptune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create_experiment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'classification_example'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                          &lt;span class=&quot;n&quot;&gt;tags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'classification'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'MNIST'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                          &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PARAMS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Dataset
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mnist&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mnist&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mnist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_images&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_images&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;255.0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_images&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_images&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;255.0&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;class_names&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;neptune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_property&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'class_names'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class_name&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;class_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;label_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xticks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yticks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;binary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;class_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;neptune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'example_images'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gcf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lr_scheduler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;new_lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PARAMS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'learning_rate'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;new_lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PARAMS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'learning_rate'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;neptune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_metric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'learning_rate'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_lr&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Model
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;class_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'softmax'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PARAMS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'optimizer'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Adam'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PARAMS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'learning_rate'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PARAMS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'optimizer'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Nadam'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Nadam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PARAMS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'learning_rate'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PARAMS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'optimizer'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'SGD'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PARAMS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'learning_rate'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sparse_categorical_crossentropy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'accuracy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Log model summary
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;print_fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;neptune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'model_summary'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;log_train_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;neptune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_metric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'epoch_acc'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'accuracy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;neptune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_metric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'epoch_loss'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'loss'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;log_val_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Evaluate model
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;eval_metrics&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;evaluate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metric&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eval_metrics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;neptune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_metric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'eval_'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metrics_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
&lt;span class=&quot;c1&quot;&gt;# Training Network
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PARAMS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'batch_size'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PARAMS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'n_epochs'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PARAMS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'shuffle'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;validation_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;callbacks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;callbacks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LambdaCallback&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;on_epoch_end&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log_train_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;callbacks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LambdaCallback&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;on_epoch_end&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log_valdata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;callbacks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EarlyStopping&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;patience&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PARAMS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'early_stopping'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                                                   &lt;span class=&quot;n&quot;&gt;monitor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'accuracy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                                   &lt;span class=&quot;n&quot;&gt;restore_best_weights&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;callbacks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LearningRateScheduler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_scheduler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Log model weights
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tempfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TemporaryDirectory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;dir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'.'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;prefix&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'model_weights'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prefix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'model'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;listdir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prefix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;neptune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_artifact&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prefix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                             &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'model_weights'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;4-결과-확인&quot;&gt;4. 결과 확인&lt;/h2&gt;

&lt;p&gt;neptune에는 총 7개의 탭이 있습니다.&lt;/p&gt;

&lt;p&gt;각각 예시를 보시면 역할을 이해하실 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;charts&quot;&gt;Charts&lt;/h3&gt;

&lt;p&gt;여기에는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;neptune.log_metric()&lt;/code&gt;을 사용한 변수들이 &lt;strong&gt;그래프&lt;/strong&gt;로 기록됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/neptune/Untitled_2.png?raw=true&quot; alt=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/neptune/Untitled_2.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;log&quot;&gt;Log&lt;/h3&gt;

&lt;p&gt;Charts에 기록된 변수의 값이 기록되고 추가적으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;neptune.log_image()&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;neptune.log_text()&lt;/code&gt; 를 사용한 변수 또한 기록됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/neptune/Untitled_3.png?raw=true&quot; alt=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/neptune/Untitled_3.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;monitoring&quot;&gt;Monitoring&lt;/h3&gt;

&lt;p&gt;리소스 모니터링과 standard error, standard output을 볼 수 있어요.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/neptune/Untitled_4.png?raw=true&quot; alt=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/neptune/Untitled_4.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;artifacts&quot;&gt;Artifacts&lt;/h3&gt;

&lt;p&gt;neptune에 원하는 파일을 전송하여 저장할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/neptune/Untitled_5.png?raw=true&quot; alt=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/neptune/Untitled_5.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;source-code&quot;&gt;Source code&lt;/h3&gt;

&lt;p&gt;생략&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/neptune/Untitled_6.png?raw=true&quot; alt=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/neptune/Untitled_6.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;parameters&quot;&gt;Parameters&lt;/h3&gt;

&lt;p&gt;코드 상단에 적은 PARAMS 가 기록이 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/neptune/Untitled_7.png?raw=true&quot; alt=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/neptune/Untitled_7.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;detail&quot;&gt;Detail&lt;/h3&gt;

&lt;p&gt;뭐…실험의 정보, 시간 등 기록이 되고 추가적으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;neptune.set_property&lt;/code&gt;를 이용하여 Properties 에 변수를 추가할 수 있어요!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/neptune/Untitled_8.png?raw=true&quot; alt=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/neptune/Untitled_8.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;wandb와 비슷한 역할을 하는 neptune.ai라는 tool에 대해 다루었습니다.&lt;/p&gt;

&lt;p&gt;음….솔직히 wandb가 더 편한 듯 하네요. (코드가 짧아서)&lt;/p&gt;

&lt;p&gt;뭐 좀 더 다양하게 사용하면 이게 더 나을…수도?&lt;/p&gt;

&lt;p&gt;선택은 개인의 몫입니다.&lt;/p&gt;

&lt;h2 id=&quot;ps&quot;&gt;P.S.&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;점점…포스팅 주제 고갈…&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 23 Jul 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/07/23/neptune/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/07/23/neptune/</guid>
        
        <category>Tools</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>Netron! Network 구조를 보여주세요!</title>
        <description>&lt;p&gt;오늘은 &lt;a href=&quot;https://github.com/lutzroeder/netron&quot;&gt;netron&lt;/a&gt; 이라는 Tool를 드리려 합니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;본 포스팅은 &lt;a href=&quot;https://github.com/lutzroeder/netron&quot;&gt;https://github.com/lutzroeder/netron&lt;/a&gt; 내용을 이용하여 작성하였습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;간단히 말씀드리면 Neural network viewer 입니다.&lt;/p&gt;

&lt;p&gt;굉장히 많은 Framework들을 지원하고 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;ONNX&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.onnx&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.pb&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.pbtxt&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Keras&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.h5&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.keras&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Core ML&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.mlmodel&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Caffe&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.caffemodel&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.prototxt&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Caffe2&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;predict_net.pb&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Darknet&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.cfg&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;MXNet&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.model&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-symbol.json&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Barracuda&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.nn&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ncnn&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.param&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tengine&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.tmfile&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;TNN&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.tnnproto&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;UFF&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.uff&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;TensorFlow Lite&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.tflite&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 외에도 불안정하지만 다음과 같은 Framework 도 지원합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;TorchScript&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.pt&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.pth&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;PyTorch&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.pt&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.pth&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Torch&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.t7&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Arm NN&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.armnn&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;BigDL&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.bigdl&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.model&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Chainer&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.npz&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.h5&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;CNTK&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.model&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.cntk&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Deeplearning4j&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.zip&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;MediaPipe&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.pbtxt&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ML.NET&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.zip&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;MNN&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.mnn&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;PaddlePaddle&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.zip&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__model__&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;OpenVINO&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.xml&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;scikit-learn&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.pkl&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;TensorFlow.js&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;model.json&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.pb&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;TensorFlow&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.pb&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.meta&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.pbtxt&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.ckpt&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.index&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(솔직히 Torch, TensorFlow 종류는 왜 나눠서 설명하는지 잘 모르겠음…..하나로 합쳐 놓으면 안되나..)&lt;/p&gt;

&lt;h2 id=&quot;설치-및-사용법&quot;&gt;설치 및 사용법&lt;/h2&gt;

&lt;p&gt;netron은 PC에 설치해서 사용하거나 설치없이 Browser 버전으로 사용할 수도 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;: &lt;strong&gt;&lt;a href=&quot;https://github.com/lutzroeder/netron/releases/latest&quot;&gt;Download&lt;/a&gt;&lt;/strong&gt; the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.dmg&lt;/code&gt; file or run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;brew cask install netron&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt;: &lt;strong&gt;&lt;a href=&quot;https://github.com/lutzroeder/netron/releases/latest&quot;&gt;Download&lt;/a&gt;&lt;/strong&gt; the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.AppImage&lt;/code&gt; file or run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;snap install netron&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;: &lt;strong&gt;&lt;a href=&quot;https://github.com/lutzroeder/netron/releases/latest&quot;&gt;Download&lt;/a&gt;&lt;/strong&gt; the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.exe&lt;/code&gt; installer or run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;winget install netron&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Python Server&lt;/strong&gt;: Run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pip install netron&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;netron [FILE]&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;import netron; netron.start('[FILE]')&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Browser&lt;/strong&gt;: &lt;strong&gt;&lt;a href=&quot;https://www.lutzroeder.com/ai/netron&quot;&gt;Start&lt;/a&gt;&lt;/strong&gt; the browser version.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;한번 브라우저 버전을 실행시켜 보았습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/netron/Untitled.png?raw=true&quot; alt=&quot;https://jjerry-k.github.io/public/img/netron/Untitled.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Open Model&lt;/code&gt; 을 클릭 하신 후 보고 싶은 Network 저장 파일을 선택합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/netron/Untitled_1.png?raw=true&quot; alt=&quot;https://jjerry-k.github.io/public/img/netron/Untitled_1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Network 구조가 차례로 보이네요.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/netron/Untitled_2.png?raw=true&quot; alt=&quot;https://jjerry-k.github.io/public/img/netron/Untitled_2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;다음은 keras로 작성된 MobileNetV2 를 netron으로 띄운 후 앞 부분을 잘라낸 사진입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/netron/Untitled_3.png?raw=true&quot; alt=&quot;https://jjerry-k.github.io/public/img/netron/Untitled_3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;왼쪽에는 네트워크 구조를 볼 수 있고 만약 레이어를 선택하면 오른쪽에 Node(Layer)에 대한 세부 설정 값들을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;몇몇 프레임워크 별로 sample을 이렇게 제공해줍니다!&lt;/p&gt;

&lt;p&gt;open을 누르면 browser를 이용하여 볼 수 있네요!&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;ONNX&lt;/strong&gt;: &lt;a href=&quot;https://raw.githubusercontent.com/onnx/tutorials/master/tutorials/assets/squeezenet.onnx&quot;&gt;squeezenet&lt;/a&gt; [&lt;a href=&quot;https://lutzroeder.github.io/netron?url=https://raw.githubusercontent.com/onnx/tutorials/master/tutorials/assets/squeezenet.onnx&quot;&gt;open&lt;/a&gt;]&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;CoreML&lt;/strong&gt;: &lt;a href=&quot;https://raw.githubusercontent.com/Lausbert/Exermote/master/ExermoteInference/ExermoteCoreML/ExermoteCoreML/Model/Exermote.mlmodel&quot;&gt;exermote&lt;/a&gt; [&lt;a href=&quot;https://lutzroeder.github.io/netron?url=https://raw.githubusercontent.com/Lausbert/Exermote/master/ExermoteInference/ExermoteCoreML/ExermoteCoreML/Model/Exermote.mlmodel&quot;&gt;open&lt;/a&gt;]&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Darknet&lt;/strong&gt;: &lt;a href=&quot;https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolo.cfg&quot;&gt;yolo&lt;/a&gt; [&lt;a href=&quot;https://lutzroeder.github.io/netron?url=https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolo.cfg&quot;&gt;open&lt;/a&gt;]&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Keras&lt;/strong&gt;: &lt;a href=&quot;https://raw.githubusercontent.com/aio-libs/aiohttp-demos/master/demos/imagetagger/tests/data/mobilenet.h5&quot;&gt;mobilenet&lt;/a&gt; [&lt;a href=&quot;https://lutzroeder.github.io/netron?url=https://raw.githubusercontent.com/aio-libs/aiohttp-demos/master/demos/imagetagger/tests/data/mobilenet.h5&quot;&gt;open&lt;/a&gt;]&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;MXNet&lt;/strong&gt;: &lt;a href=&quot;https://raw.githubusercontent.com/soeaver/mxnet-model/master/cls/inception/inception_v3-symbol.json&quot;&gt;inception_v3&lt;/a&gt; [&lt;a href=&quot;https://lutzroeder.github.io/netron?url=https://raw.githubusercontent.com/soeaver/mxnet-model/master/cls/inception/inception_v3-symbol.json&quot;&gt;open&lt;/a&gt;]&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;TensorFlow&lt;/strong&gt;: &lt;a href=&quot;https://raw.githubusercontent.com/srom/chessbot/master/model/chessbot.pb&quot;&gt;chessbot&lt;/a&gt; [&lt;a href=&quot;https://lutzroeder.github.io/netron?url=https://raw.githubusercontent.com/srom/chessbot/master/model/chessbot.pb&quot;&gt;open&lt;/a&gt;]&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;TensorFlow Lite&lt;/strong&gt;: &lt;a href=&quot;https://raw.githubusercontent.com/google/mediapipe/master/mediapipe/models/hair_segmentation.tflite&quot;&gt;hair_segmentation&lt;/a&gt; [&lt;a href=&quot;https://lutzroeder.github.io/netron?url=https://raw.githubusercontent.com/google/mediapipe/master/mediapipe/models/hair_segmentation.tflite&quot;&gt;open&lt;/a&gt;]&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;TorchScript&lt;/strong&gt;: &lt;a href=&quot;https://raw.githubusercontent.com/ApolloAuto/apollo/master/modules/prediction/data/traced_online_pred_layer.pt&quot;&gt;traced_online_pred_layer&lt;/a&gt; [&lt;a href=&quot;https://lutzroeder.github.io/netron?url=https://raw.githubusercontent.com/ApolloAuto/apollo/master/modules/prediction/data/traced_online_pred_layer.pt&quot;&gt;open&lt;/a&gt;]&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Caffe&lt;/strong&gt;: &lt;a href=&quot;https://raw.githubusercontent.com/shicai/MobileNet-Caffe/master/mobilenet_v2.caffemodel&quot;&gt;mobilenet_v2&lt;/a&gt; [&lt;a href=&quot;https://lutzroeder.github.io/netron?url=https://raw.githubusercontent.com/shicai/MobileNet-Caffe/master/mobilenet_v2.caffemodel&quot;&gt;open&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ps&quot;&gt;P.S.&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;피곤…&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 20 Jul 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/07/20/netron/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/07/20/netron/</guid>
        
        <category>Tools</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>NIPA x VScode !</title>
        <description>&lt;p&gt;지금까지 &lt;a href=&quot;https://jjerry-k.github.io/deeplearning/2020/06/28/nipa_docker&quot;&gt;Docker(이하 도커) 세팅&lt;/a&gt; 까지 포스팅을 했었습니다.&lt;/p&gt;

&lt;p&gt;Docker 까진 좋은데…연결을 항상 Terminal 혹은 CMD를 켜서 ssh로 해야하나..? 생각이 듭니다.&lt;/p&gt;

&lt;p&gt;그래서 이래저래 찾아봤습니다.&lt;/p&gt;

&lt;p&gt;Docker 공식 문서를 보니 &lt;a href=&quot;https://docs.docker.com/engine/examples/running_ssh_service/&quot;&gt;Dockerize an SSH service&lt;/a&gt; 이런 글이 있더군요.&lt;/p&gt;

&lt;p&gt;이 글을 참고하여 image(이하 이미지)를 만들어 보기로 했습니다.&lt;/p&gt;

&lt;p&gt;그럼 빠르게 빠르게 진행하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;1-dockerfile-생성-및-build&quot;&gt;1. Dockerfile 생성 및 build&lt;/h2&gt;

&lt;div class=&quot;language-docker highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; nvidia/cuda:10.1-cudnn7-runtime-ubuntu16.04&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LABEL&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; maintainer &quot;Jerry Kim &amp;lt;jaeyeol2931@gmail.com&amp;gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ARG&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; PYTHON_VERSION=3.7&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;apt-get update
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;apt-get &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;        build-essential &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;        cmake &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;        git &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;        curl &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;        wget &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;        vim &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;        unzip &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;        ca-certificates &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;        libjpeg-dev &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;        libpng-dev &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;        openssh-server

&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;apt-get update &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt-get &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; upgrade

&lt;span class=&quot;c&quot;&gt;#RUN mkdir /var/run/sshd&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'root:{개인 비밀번호}'&lt;/span&gt; | chpasswd
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sed&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'s/PermitRootLogin prohibit-password/PermitRootLogin yes/'&lt;/span&gt; /etc/ssh/sshd_config

&lt;span class=&quot;c&quot;&gt;# SSH login fix. Otherwise user is kicked off after login&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sed&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'s@session\s*required\s*pam_loginuid.so@session optional pam_loginuid.so@g'&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; /etc/pam.d/sshd

&lt;span class=&quot;k&quot;&gt;ENV&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; NOTVISIBLE &quot;in users profile&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;export VISIBLE=now&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; /etc/profile

&lt;span class=&quot;k&quot;&gt;EXPOSE&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; 22&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CMD&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; [&quot;/usr/sbin/sshd&quot;, &quot;-D&quot;]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;rm&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-rf&lt;/span&gt; /var/lib/apt/lists/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;curl https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; ~/miniconda.sh

&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;chmod&lt;/span&gt; +x ~/miniconda.sh &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;    ~/miniconda.sh &lt;span class=&quot;nt&quot;&gt;-b&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; /opt/conda &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;    &lt;span class=&quot;nb&quot;&gt;rm&lt;/span&gt; ~/miniconda.sh

&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;/opt/conda/bin/conda &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$PYTHON_VERSION&lt;/span&gt; numpy pyyaml scipy ipython mkl mkl-include ninja cython typing opencv matplotlib tqdm &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;    /opt/conda/bin/conda &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; jupyter jupyterlab seaborn pillow pandas pylint scikit-learn scikit-image tensorflow-gpu &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;    /opt/conda/bin/conda update &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--all&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;    /opt/conda/bin/conda clean &lt;span class=&quot;nt&quot;&gt;-ya&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;중간에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RUN echo 'root:{개인 비밀번호}' | chpasswd&lt;/code&gt; 에서 ssh 접속시 사용할 비밀번호를 적어주세요!&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Example&lt;/span&gt;
RUN &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'root:test'&lt;/span&gt; | chpasswd
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위 내용들을 vim이나 nano같은 에디터를 이용해서 Dockerfile을 만들어주세요!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_vscode/Untitled.png&quot; alt=&quot;Phttps://jjerry-k.github.io/public/img/nipa_vscode/Untitled.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그리고 다음과 같이 커맨드를 입력하여 도커 이미지를 build 합니다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker build &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;이미지 이름&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_vscode/Untitled_1.png&quot; alt=&quot;Phttps://jjerry-k.github.io/public/img/nipa_vscode/Untitled_1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;뭐 이런 저런 Log 들이 촤라———라락 넘어갈겁니다. 계속 기다려 주세요….&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docker images&lt;/code&gt; 를 입력하면 제대로 생성된 것을 볼 수 있습니다!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_vscode/Untitled_2.png&quot; alt=&quot;Phttps://jjerry-k.github.io/public/img/nipa_vscode/Untitled_2.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-container-실행&quot;&gt;2. Container 실행&lt;/h2&gt;

&lt;p&gt;이미지를 실행하여 container(이하 컨테이너) 만들어 줍니다.&lt;/p&gt;

&lt;p&gt;세부 옵션은 &lt;strong&gt;구.글.링&lt;/strong&gt; 아시죠?&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker run &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-P&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt; /home/ubuntu/jerry/:/jerry &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;컨테이너 이름&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;이미지 이름&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

docker port &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;컨테이너 이름&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; 22
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_vscode/Untitled_3.png&quot; alt=&quot;Phttps://jjerry-k.github.io/public/img/nipa_vscode/Untitled_3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;컨테이너를 만들고 해당 컨테이너의 22번 포트 (ssh 포트)가 nipa의 몇번 포트와 연결되어 있는지 출력해줍니다.&lt;/p&gt;

&lt;h2 id=&quot;3-vscode를-이용하여-접속&quot;&gt;3. VSCode를 이용하여 접속&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;vscode 에 Remote - SSH 플러그인이 설치가 되어 있다는 전제 하에 진행합니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;새로운 호스트를 추가해줍니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_vscode/Untitled_4.png&quot; alt=&quot;Phttps://jjerry-k.github.io/public/img/nipa_vscode/Untitled_4.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ssh root@{NIPA IP} -p {포트 번호}&lt;/code&gt; 라고 입력하고 엔터!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_vscode/Untitled_5.png&quot; alt=&quot;Phttps://jjerry-k.github.io/public/img/nipa_vscode/Untitled_5.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그럼 우하단에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Host를 추가했습니다!&lt;/code&gt; 와 같이 알림이 뜹니다.&lt;/p&gt;

&lt;p&gt;추가를 했으니 이제 Host에 연결을 해봅니다.&lt;/p&gt;

&lt;p&gt;비밀번호는 맨 처음에 Dockerfile에서 썼던 비밀번호 입니다!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_vscode/Untitled_6.png&quot; alt=&quot;Phttps://jjerry-k.github.io/public/img/nipa_vscode/Untitled_6.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;아마 처음에는 세팅이 오래 걸릴겁니다. 우하단에 알림이 없어질 때까지 기다려주세요 !&lt;/p&gt;

&lt;p&gt;기초 세팅이 다 완료 되면 컨테이너의 vscode-server에 플러그인을 설치해야 합니다.&lt;/p&gt;

&lt;p&gt;저는 아래 4개 플러그인을 설치했어요.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_vscode/Untitled_7.png&quot; alt=&quot;Phttps://jjerry-k.github.io/public/img/nipa_vscode/Untitled_7.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그 후에 테스트 코드를 돌려봅니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_vscode/Untitled_8.png&quot; alt=&quot;Phttps://jjerry-k.github.io/public/img/nipa_vscode/Untitled_8.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;정상적으로 잘 작동하네요!&lt;/p&gt;

&lt;p&gt;후…이제 Vim으로 코딩을 안할 수 있습니다.&lt;/p&gt;

&lt;p&gt;이번 포스팅은 정말 환경 구축이 처음이신 분들께는 불친절한 포스팅일 수도 있습니다.&lt;/p&gt;

&lt;p&gt;죄송합니다. 일단 제 일기처럼 쓰는 포스팅이라서요. 감안해서 읽어주세요.&lt;/p&gt;

&lt;h2 id=&quot;ps&quot;&gt;P.S.&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;근데 막상 내가 NIPA를 …..주로 쓰지 않음…&lt;/li&gt;
  &lt;li&gt;나에게 NIPA는 환경 구축 포스팅을 적는 용도…&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 15 Jul 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/07/15/nipa_vscode/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/07/15/nipa_vscode/</guid>
        
        <category>Tools</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>Colab x VSCode !</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;본 포스팅은 &lt;a href=&quot;https://towardsdatascience.com/colab-free-gpu-ssh-visual-studio-code-server-36fe1d3c5243&quot;&gt;Colab on steroids: free GPU instances with SSH access and Visual Studio Code Server&lt;/a&gt; 내용을 (많이) 참고하여 작성하였습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;많은 분들이 Google Colaboratory (코랩) 를 사용하실겁니다. (무료니까…)&lt;/p&gt;

&lt;p&gt;무료로 고성능(?)의 하드웨어를 쓸 수 있다는 건 참 좋은 것입니다!&lt;/p&gt;

&lt;p&gt;하지만…문제는 Jupyter Notebook 형식으로 써야한다는거…아 물론 편하신 분들도 있겠죠!?&lt;/p&gt;

&lt;p&gt;전 개인적으로 별로 안좋아합니다. (물론 애초에 안쓰기도 함.)&lt;/p&gt;

&lt;p&gt;근데 SSH, VSCode Server를 이용해서 Colab에 접속을…하는 포스팅이 있더군요.&lt;/p&gt;

&lt;p&gt;갑자기 실험쥐 정신이 튀어나와서 진행을 해봤습니다.&lt;/p&gt;

&lt;p&gt;뻘소리 그만하고 간단 간단 설명 시작하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;1-ngrok으로-token-만들기&quot;&gt;1. ngrok으로 token 만들기&lt;/h2&gt;

&lt;p&gt;ngrok은 대충 로컬 웹 서버를 SSH 접속이나 모바일 테스트 할 수 있도록 공공 URL로 접근 가능토록 해주는 것입니다.  가격은 걱정하지 마세요. 1개는 무료거든요.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;어쨌든 가입을 하고 token을 생성 해줍니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_1.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_2.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_2.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-colab에-ngrok-설치-및-실행&quot;&gt;2. Colab에 ngrok 설치 및 실행&lt;/h2&gt;

&lt;p&gt;노트북 설정을 먼저 해주세요. (ex) CPU, GPU, TPU&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_3.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그리고 셀에 다음과 같이 코드를 실행합니다.&lt;/p&gt;

&lt;p&gt;아래 authtoken 에는 ngrok의 Authtoken을 적어주세요. (당연하지만 스트링으로)&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Install useful stuff
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;apt&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yes&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ssh&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nano&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;htop&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ranger&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;git&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;null&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# SSH setting
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;root:carbonara&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chpasswd&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;PasswordAuthentication yes&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ssh&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sshd_config&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;PermitUserEnvironment yes&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ssh&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sshd_config&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;PermitRootLogin yes&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ssh&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sshd_config&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;service&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ssh&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;restart&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;null&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Download ngrok
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wget&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nc&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;https&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;equinox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;VmDzA7iaHb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ngrok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linux&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;amd64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unzip&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;qq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ngrok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linux&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;amd64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Run ngrok
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;authtoken&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;PUT_YOUR_TOKEN_HERE&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;get_ipython&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;system_raw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'./ngrok authtoken $authtoken &amp;amp;&amp;amp; ./ngrok tcp 22 &amp;amp;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Get the address for SSH
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;requests&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;re&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sub&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'http://localhost:4040/api/tunnels'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;str_ssh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'tunnels'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'public_url'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;str_ssh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tcp://&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_ssh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;str_ssh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; -p &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_ssh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;str_ssh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;ssh root@&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_ssh&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;str_ssh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_4.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_4.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;출력으로 나온 커맨드를 이용하여 한번 터미널에서 테스트를 해봅니다. 비밀번호는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;carbonara&lt;/code&gt; 입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_5.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_5.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-vscode에서-실행하기&quot;&gt;3. VSCode에서 실행하기&lt;/h2&gt;

&lt;p&gt;먼저 Colab 화면에서 다음 코드를 실행해서 Google Drive를 마운트 해줍니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Mount Google Drive and make some folders for vscode
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;google.colab&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;drive&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;drive&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'/googledrive'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;googledrive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;My&lt;/span&gt;\ &lt;span class=&quot;n&quot;&gt;Drive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colabdrive&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;googledrive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;My&lt;/span&gt;\ &lt;span class=&quot;n&quot;&gt;Drive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colabdrive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;local&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;share&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;code&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;server&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ln&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;googledrive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;My&lt;/span&gt;\ &lt;span class=&quot;n&quot;&gt;Drive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colabdrive&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ln&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;googledrive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;My&lt;/span&gt;\ &lt;span class=&quot;n&quot;&gt;Drive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colabdrive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;local&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;share&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;code&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;local&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;share&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_6.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_6.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;VSCode를 켜고 ssh로 접속을 해봅니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_7.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_7.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;접속해서 Colab Notebooks 디렉토리에 접근한 화면입니다. Google Drive랑 동일한 것을 확인할 수 있죠!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_8.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_8.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;4-코드-작성-및-실행&quot;&gt;4. 코드 작성 및 실행&lt;/h2&gt;

&lt;p&gt;코드 실행 여부를 테스트 해보겠습니다.&lt;/p&gt;

&lt;p&gt;일단 Colab 에는 VSCode 플러그인이 설치 되어 있지 않기 때문에 python이나 개인적으로 필요한 플러그인들을 설치해줍니다.&lt;/p&gt;

&lt;p&gt;저는 테스트이니 아래 세 가지만 설치했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_9.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_9.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그럼 한번 실행해보죠.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_10.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_10.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;오…..신기…&lt;/p&gt;

&lt;p&gt;이렇게 연결해서 사용이 가능합니다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;htop&lt;/code&gt;를 이용해서 리소스 모니터링도 가능하죠.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_11.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_11.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여기까지 Colab x VSCode 포스팅입니다. 뭐….어떤 면에선 편할 것 같지만 막…편할 것 같진 않네요.&lt;/p&gt;

&lt;p&gt;아직 이 상황을 겪지 않아서 모르겠지만 원래 코랩의 큰 문제가 있죠. Session timeout….&lt;/p&gt;

&lt;p&gt;일정 시간동안 동작이 없으면 연결이 끊겨서 다시 실행을 시켜야하는….상황이 오죠.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_12.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_12.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;나한테 왜 그래…&lt;/p&gt;

&lt;p&gt;그 상황이 왔을 때 느낌으로는 VSCode의 SSH 접속이 끊길 것 같네요. 흠…. 실험 후에 추가로 적어 보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;ps&quot;&gt;P.S&lt;/h2&gt;

&lt;p&gt;끊겼습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/colab_vscode/Untitled_13.png?raw=true&quot; alt=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_13.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;VSCode 를 봐도..&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/colab_vscode/Untitled_14.png?raw=true&quot; alt=&quot;https://jjerry-k.github.io/public/img/colab_vscode/Untitled_14.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그렇습니다. 제 생각대로 Colab의 Session time이 끝나면…끊기네요..ㅎㅎ
편하게 쓰기는 힘들 듯…&lt;/p&gt;
</description>
        <pubDate>Mon, 13 Jul 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/07/13/colab_vscode/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/07/13/colab_vscode/</guid>
        
        <category>Tools</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>NIPA x Docker !</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;원래 NIPA GPU 서버를 대여받은 후에 포트 포워딩을 먼저 해줘야 합니다.
하지만 그 부분에 대해선 보안적인 부분이 있기 때문에 생략하겠습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이번엔 NIPA 내 개인 환경 세팅에 대해 포스팅을 해보려 합니다.&lt;/p&gt;

&lt;p&gt;개인마다 원하는 환경이 다르기 때문에 정말 필요하죠.&lt;/p&gt;

&lt;p&gt;물론 기본적으로 설치된 Anaconda  환경으로도 충분할 수 있지만 살짝쿵 문제가 있습니다.&lt;/p&gt;

&lt;p&gt;문제에 대해 살펴보겠습니다.&lt;/p&gt;

&lt;p&gt;NIPA GPU 서버에 접속을 하면 다음과 같은 화면이 출력됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_docker/Untitled.png&quot; alt=&quot;Untitled.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;먼저 말씀드렸던 conda 환경으로 기본적으로 다양한 환경이 제공되네요.&lt;/p&gt;

&lt;p&gt;저의 경우 이번에 tf-nightly가 필요했습니다.&lt;/p&gt;

&lt;p&gt;그래서 TensorFlow2, python3.6 환경을 activate  한 후 설치를 시도했죠.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_docker/Untitled_1.png&quot; alt=&quot;NIPA%20x%20Docker%20ef94d24dfbc64a6cae24a83a59bd352f/Untitled%201.png&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;what…?&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_docker/Untitled_2.png&quot; alt=&quot;NIPA%20x%20Docker%20ef94d24dfbc64a6cae24a83a59bd352f/Untitled%202.png&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;음….conda 버전의 문제인가 싶어서 base conda를 update  하려 했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_docker/Untitled_3.png&quot; alt=&quot;NIPA%20x%20Docker%20ef94d24dfbc64a6cae24a83a59bd352f/Untitled%203.png&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;what…?&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_docker/Untitled_2.png&quot; alt=&quot;NIPA%20x%20Docker%20ef94d24dfbc64a6cae24a83a59bd352f/Untitled%202.png&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;뭐야..이건 또 왜 안되는거야… 짜증이 났습니다.&lt;/p&gt;

&lt;p&gt;대충 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;너무 옛날 버전의 conda니까 최소 4.8로 재설치 해주세요.&lt;/code&gt; 라는 내용입니다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;하....이건 좀 너무한데...그냥 Docker나 설치하자..&lt;/code&gt; 라는 생각을 하게 되었습니다.&lt;/p&gt;

&lt;p&gt;그럼 Docker 설치에 대해 포스팅 해보겠습니다.&lt;/p&gt;

&lt;p&gt;Docker 에 대한 자세한 설명은 하지 않을 겁니다.&lt;/p&gt;

&lt;p&gt;홈페이지 혹은 Docker 에 대한 포스팅을 참고하시기 바랍니다.&lt;/p&gt;

&lt;p&gt;간단히 말씀드리면 OS 단계까지 가상환경을 만드는 겁니다.&lt;/p&gt;

&lt;p&gt;그럼 설치 방법에 대해 적겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# SET UP THE REPOSITORY&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get update

&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    apt-transport-https &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    ca-certificates &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    curl &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    gnupg-agent &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    software-properties-common

curl &lt;span class=&quot;nt&quot;&gt;-fsSL&lt;/span&gt; https://download.docker.com/linux/ubuntu/gpg | &lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-key add -

&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-key fingerprint 0EBFCD88

&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;add-apt-repository &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
   &lt;span class=&quot;s2&quot;&gt;&quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;lsb_release &lt;span class=&quot;nt&quot;&gt;-cs&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
   stable&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# INSTALL DOCKER ENGINE&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get update
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;docker-ce docker-ce-cli containerd.io

&lt;span class=&quot;c&quot;&gt;# VERIFY THAT DOCKER ENGINE IS INSTALLED CORRECTLY&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;docker run hello-world
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;만약에 제대로 설치 되었다면 마지막에 다음과 같은 출력이 남습니다&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_docker/Untitled_4.png&quot; alt=&quot;NIPA%20x%20Docker%20ef94d24dfbc64a6cae24a83a59bd352f/Untitled%204.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여기까지 하시면 기본 Docker 설치는 끝났습니다.&lt;/p&gt;

&lt;p&gt;하지만 이것만 설치하면 GPU 는 사용하지 못합니다.&lt;/p&gt;

&lt;p&gt;GPU를 쓰기 위해선 &lt;a href=&quot;https://github.com/NVIDIA/nvidia-docker&quot;&gt;nvidia-docker&lt;/a&gt;를 설치를 해야 합니다.&lt;/p&gt;

&lt;p&gt;nvidia-docker는 간단히 말하면 docker 에서 데스크탑의 GPU를 사용할 수 있도록 nvidia에서 만든(?)것입니다.&lt;/p&gt;

&lt;p&gt;설치법은 다음과 같습니다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Ubuntu 16.04/18.04/20.04, Debian Jessie/Stretch/Buster&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Add the package repositories&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;distribution&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; /etc/os-release&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$ID$VERSION_ID&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;
curl &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-L&lt;/span&gt; https://nvidia.github.io/nvidia-docker/gpgkey | &lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-key add -
curl &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-L&lt;/span&gt; https://nvidia.github.io/nvidia-docker/&lt;span class=&quot;nv&quot;&gt;$distribution&lt;/span&gt;/nvidia-docker.list | &lt;span class=&quot;nb&quot;&gt;sudo tee&lt;/span&gt; /etc/apt/sources.list.d/nvidia-docker.list

&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get update &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; nvidia-container-toolkit
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;systemctl restart docker

&lt;span class=&quot;c&quot;&gt;# Test nvidia-docker&lt;/span&gt;
docker run &lt;span class=&quot;nt&quot;&gt;--gpus&lt;/span&gt; all nvidia/cuda:10.0-base nvidia-smi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이 또한 설치가 제대로 되었다면 마지막에 다음과 같이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nvidia-smi&lt;/code&gt; 출력이 나올 겁니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_docker/Untitled_5.png&quot; alt=&quot;NIPA%20x%20Docker%20ef94d24dfbc64a6cae24a83a59bd352f/Untitled%205.png&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;하….편안….&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_docker/Untitled_6.png&quot; alt=&quot;NIPA%20x%20Docker%20ef94d24dfbc64a6cae24a83a59bd352f/Untitled%206.png&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;이번엔 NIPA에 Docker 설치하는 과정을 포스팅 해봤습니다.&lt;/p&gt;

&lt;p&gt;공짜로 빌려주는 건 좋으나 환경 구축은 역시나….해야 하네요.&lt;/p&gt;

&lt;p&gt;제가 쓰는 Docker image는 &lt;a href=&quot;https://jjerry-k.github.io/living/2020/05/05/dockerfile/&quot;&gt;개인적인 도커 파일&lt;/a&gt; 에 있으니 참고하세요!&lt;/p&gt;
</description>
        <pubDate>Sun, 28 Jun 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/06/28/nipa_docker/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/06/28/nipa_docker/</guid>
        
        <category>Tools</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>NIPA 컴퓨팅 자원 신청 방법 !</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://jjerry-k.github.io/deeplearning/2020/06/26/nipa_intro/&quot;&gt;저번 포스팅&lt;/a&gt;에 이어 이번엔 NIPA 컴퓨팅 자원 이용 신청에 관한 포스팅을 해보려 합니다!&lt;/p&gt;

&lt;p&gt;내용 출처: &lt;a href=&quot;http://www.aihub.or.kr/node/254&quot;&gt;http://www.aihub.or.kr/node/254&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;이용-절차&quot;&gt;이용 절차&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;일반 사용자
    &lt;ul&gt;
      &lt;li&gt;신청 대상: AI 제품·서비스를 연구·개발하고자 하는 국내 중소·벤처 기업, 스타트업, 공공기관, 대학교(원), 일반 협·단체&lt;/li&gt;
      &lt;li&gt;신청 기간: 2020. 1. 6.(월) ∼ 2. 7.(금)※ 추가 모집 : 2020.5.25.(월) ~ 11.30.(월)&lt;/li&gt;
      &lt;li&gt;신청 절차: 이용 신청서 작성 → 온라인 신청 사이트에 제출 → 서면 심사 → 선정결과 발표&lt;br /&gt;
  ※ 선정기준 : 지원 자격요건, AI 연구‧개발대상 여부, 사용계획서(목적, 연구‧개발분야, 사용내용, 필요성 등)를 중심으로 심사‧평가&lt;br /&gt;
  ※ 모집 규모 대비 초과 신청 시 중소·벤처기업, 공공기관, 대학교(원)에 자원이 우선 할당될 수 있음&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;수시 사용자
    &lt;ul&gt;
      &lt;li&gt;신청 대상: 일반 사용자와 개발자, 학생 등 개인&lt;/li&gt;
      &lt;li&gt;신청 기간: 2020.4.10.(금) ~ 2020.12.21.(월)&lt;/li&gt;
      &lt;li&gt;신청 절차: 이용신청 작성‧제출 → AI 연구‧개발대상 여부 확인 → 여유 자원 확인 → 서비스 이용&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;각각의 신청서 양식은 다음과 같습니다.&lt;/p&gt;

&lt;h3 id=&quot;일반-사용자용-신청서&quot;&gt;일반 사용자용 신청서&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.aihub.or.kr/sites/default/files/2020-05/[일반&quot;&gt;다운로드 링크&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_apply/Untitled.png&quot; alt=&quot;Untitled.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;수시-사용자용-신청서&quot;&gt;수시 사용자용 신청서&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.aihub.or.kr/sites/default/files/2020-05/[%EC%88%98%EC%8B%9C%20%EC%82%AC%EC%9A%A9%EC%9E%90%EC%9A%A9]%20%EA%B3%A0%EC%84%B1%EB%8A%A5%20%EC%BB%B4%ED%93%A8%ED%8C%85%20%EC%9E%90%EC%9B%90%20%EC%9D%B4%EC%9A%A9%20%EC%8B%A0%EC%B2%AD%EC%84%9C.hwp&quot;&gt;다운로드 링크&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_apply/Untitled_1.png&quot; alt=&quot;Untitled_1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;당연한거지만 일반 사용자가 수시 사용자에 비해 작성해야할 것이 많습니다.&lt;/p&gt;

&lt;p&gt;신청서 작성 방법은 예시가 너무 잘 적혀있기 때문에 따로 설명을 드리지 않겠습니다. (궁금하신게 있다면 따로 댓글 남겨주세요!)&lt;/p&gt;

&lt;p&gt;신청서를 작성하신 후엔 AIHub 사이트 로그인을 하신 후 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;이용신청&lt;/code&gt; 으로 넘어갑니다.&lt;br /&gt;
그럼 다음과 같은 화면이 나오는데 (수시 사용자 기준) &lt;strong&gt;1~8번 중 해당하는 부분 선택하&lt;/strong&gt;고 &lt;strong&gt;개인 정보&lt;/strong&gt; 채워주시면 됩니다!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_apply/Untitled_2.png&quot; alt=&quot;Untitled_2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;다 채운 후 이용신청을 누르시면 한…. 하루, 이틀? 정도 후에 메일과 핸드폰으로 문자 안내가 옵니다!&lt;br /&gt;
메일에는 NIPA 서버 사용방법, 문자에는 관리 페이지 이용 안내가 옵니다. &lt;br /&gt;
신청이 어렵지 않으니 많이 많이 신청하시고 즐거운 딥러닝 공부, 연구하세요! (홍보 아님)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_apply/go.png&quot; alt=&quot;go.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ps&quot;&gt;P.S.&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;중요! ! ! &lt;strong&gt;수시 사용자는 계속 사용하려면 10일마다 연장 신청 해야함. 꼭! 반드시!&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;위 내용을 지키지 않으면 서버 초기화되서 내용들 다 사라짐!!!&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;너무 대충 포스팅을…하는걸까…&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 27 Jun 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/06/27/nipa_apply/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/06/27/nipa_apply/</guid>
        
        <category>Tools</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>NIPA...NIPA가 뭐죠..</title>
        <description>&lt;p&gt;요즘 커뮤니티(V-AIS) 에선 NIPA에 대한 얘기가 많이 나옵니다.&lt;br /&gt;
NIPA는 &lt;a href=&quot;https://www.nipa.kr/&quot;&gt;&lt;strong&gt;정보통신산업진흥원&lt;/strong&gt;&lt;/a&gt; 의 약자인데 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;근데 그래서 이게 왜..?&lt;/code&gt; 라는 의문을 가지실 겁니다. &lt;br /&gt;
지금 AI Hub에서 지원하는 &lt;a href=&quot;http://www.aihub.or.kr/node/223&quot;&gt;&lt;strong&gt;AI 컴퓨팅 자원 지원 사업&lt;/strong&gt;&lt;/a&gt;을 하고 있는데요.&lt;br /&gt;
그 사업에서 컴퓨팅 자원을 관리하는게 NIPA 입니다. 그래서 NIPA, NIPA 하죠..&lt;/p&gt;

&lt;p&gt;간단하게 그림으로 보여드리면 이렇습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_intro/Untitled.png&quot; alt=&quot;Untitled.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;더 간단하게 설명드리면 &lt;strong&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GPU서버 지원해드림 ㅇㅇ&lt;/code&gt;&lt;/strong&gt; 이겁니다.&lt;/p&gt;

&lt;p&gt;어느 정도 사양이냐…&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_intro/Untitled_1.png&quot; alt=&quot;Untitled_1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;일반 사용자&lt;/strong&gt;와 &lt;strong&gt;수시 사용자&lt;/strong&gt;로 나뉘는데요. 그 차이는 사이트에서 확인하시길..&lt;/p&gt;

&lt;p&gt;이렇게 보면 GPU로 뭐 쓰는지 잘 모르시겠죠. 그래서 가져왔습니다.&lt;/p&gt;

&lt;p&gt;제가 포스팅, 환경구축과 같은 자료를 만들기 위해 신청한 서버입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_intro/Untitled_2.png&quot; alt=&quot;Untitled_2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 GPU 사진은 &lt;strong&gt;수시 사용자&lt;/strong&gt; 기준입니다. 일반 사용자면 V100 두개겠네요.&lt;/p&gt;

&lt;p&gt;뭐 이런 서버를 &lt;strong&gt;공짜&lt;/strong&gt;로 제공을 해줍니다.&lt;/p&gt;

&lt;p&gt;집에 서버가 따로 없는 분들이라면 이보다 좋은 건 없겠죠. (게다가 VRAM이 32기가임….)&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;strong&gt;헤헿 겁나 좋군&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/nipa_intro/good.png&quot; alt=&quot;good.png&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;다음엔 NIPA 신청 방법에 대한 포스팅은 간단히 해보겠습니다.&lt;/p&gt;

&lt;p&gt;그럼 모두 즐거운 딥러닝 공부, 연구하세요.&lt;/p&gt;

&lt;h2 id=&quot;ps&quot;&gt;P.S.&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;수시 사용자의 경우 기본 10일 사용, 10일마다 사용 연장신청을 해야함.&lt;/li&gt;
  &lt;li&gt;당연하지만 신청해놓고 사용안하면 검열 후 강제 반납.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 26 Jun 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/06/26/nipa_intro/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/06/26/nipa_intro/</guid>
        
        <category>Tools</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>TensorFlow Multi GPU 사용법</title>
        <description>&lt;p&gt;이번 포스팅은 Multi GPU 시스템에서 Google의 머신러닝 오픈 소스 플랫폼인 &lt;a href=&quot;https://www.tensorflow.org/&quot;&gt;TensorFlow&lt;/a&gt;사용법에 관한 것입니다!&lt;br /&gt;
거두절미하고 바로 코딩으로 들어가겠습니다!&lt;/p&gt;

&lt;h2 id=&quot;single-gpu-예시&quot;&gt;Single GPU 예시&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;다음 코드는 Single GPU를 이용하여 mnist data를 분류하는 코드입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Import Package
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow.keras&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Data Prepare
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mnist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expand_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expand_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Train Data's Shape : &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Test Data's Shape : &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Build Network
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,)))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxPool2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxPool2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'softmax'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparse_categorical_crossentropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'accuracy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;                
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Network Built!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Training Network
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4096&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;history&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;validation_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;multi-gpu-예시&quot;&gt;Multi GPU 예시&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;다음 코드는 Multi GPU를 이용한 코드입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Import Package
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow.keras&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Data Prepare
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mnist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expand_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expand_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Train Data's Shape : &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Test Data's Shape : &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Build Network
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strategy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distribute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MirroredStrategy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strategy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scope&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,)))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxPool2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxPool2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'softmax'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparse_categorical_crossentropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'accuracy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;                
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Network Built!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Training Network
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batch_size_each_gpu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4096&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size_each_gpu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;history&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;validation_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;어렵지 않습니다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Build Network&lt;/code&gt; 주석 부분과 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Training Network&lt;/code&gt; 부분에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;batch_size&lt;/code&gt;만 조금 수정해주시면 끝납니다!&lt;br /&gt;
&lt;img src=&quot;https://jjerry-k.github.io/public/img/tf_multi_gpu/bob.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;하지만 이렇게 하면 무식하게 GPU의 모든 메모리를 할당합니다.&lt;br /&gt;
그렇기 떄문에 다음과 같이 코드를 추가하여 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;필요한 만큼&lt;/code&gt; 할당하도록 합니다.&lt;/p&gt;

&lt;h2 id=&quot;필요한-만큼의-gpu-메모리만-사용하기&quot;&gt;필요한 만큼의 GPU 메모리만 사용하기&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Import Package
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow.keras&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Data Prepare
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mnist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expand_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expand_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Train Data's Shape : &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Test Data's Shape : &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# For Efficiency
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gpus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;experimental&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;list_physical_devices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'GPU'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gpu&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;experimental&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_memory_growth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;logical_gpus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;experimental&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;list_logical_devices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'GPU'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Physical GPUs,&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logical_gpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Logical GPUs&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;RuntimeError&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Build Network
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strategy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distribute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MirroredStrategy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strategy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scope&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,)))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxPool2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxPool2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'softmax'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparse_categorical_crossentropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'accuracy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;                
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Network Built!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Training Network
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batch_size_each_gpu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4096&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size_each_gpu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;history&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;validation_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;기존 Multi GPU 코드와 달라진 점은&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;For Efficiency&lt;/code&gt;라는 부분이 추가.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;strategy = tf.distribute.MirroredStrategy()&lt;/code&gt;을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Build Network&lt;/code&gt;에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;For Efficiency&lt;/code&gt;의 가장 첫번째 라인으로 이동.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이렇게 변경 후 실행 후 nvidia-smi와 같은 모니터링 툴을 확인해보시면 이전과는 다르게 GPU 메모리를 필요한 만큼만 사용하는걸 보실 수 있습니다!&lt;/p&gt;

&lt;h2 id=&quot;ps&quot;&gt;P.S&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;다음은 뭘로 포스팅하지…&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;번외편-using-gradient-tape&quot;&gt;번외편 (Using gradient tape)&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;c1&quot;&gt;# %%
# Import Package
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow.keras&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;gpus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;experimental&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;list_physical_devices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'GPU'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Currently, memory growth needs to be the same across GPUs
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gpu&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;experimental&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_memory_growth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;logical_gpus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;experimental&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;list_logical_devices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'GPU'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Physical GPUs,&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logical_gpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Logical GPUs&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;RuntimeError&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Memory growth must be set before GPUs have been initialized
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# %%
# Data Prepare
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batch_size_each_gpu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4096&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size_each_gpu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mnist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expand_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expand_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Train Data's Shape : &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Test Data's Shape : &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# %%
# Build Network
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;build_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;build_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxPool2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxPool2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flatten&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dense&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'softmax'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Network Built!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Set mirrored Strategy
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strategy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distribute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MirroredStrategy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strategy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scope&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Prepare dataset 
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;train_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_tensor_slices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;train_dist_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strategy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;experimental_distribute_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_tensor_slices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;test_dist_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strategy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;experimental_distribute_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Make Network
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Set Loss &amp;amp; Metric function
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;loss_object&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SparseCategoricalCrossentropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Reduction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NONE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;compute_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;per_example_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compute_average_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;per_example_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;global_batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
    &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'test_loss'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;train_accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SparseCategoricalAccuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'train_accuracy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SparseCategoricalAccuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'test_accuracy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Set optimizer
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Define taining, test function
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GradientTape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainable_variables&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apply_gradients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainable_variables&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;train_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; 
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;test_step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;t_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;test_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Define training, test function suitable for Mirrored Strategy 
&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;function&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;distributed_train_step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;per_replica_losses&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strategy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;experimental_run_v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strategy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;reduce&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distribute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReduceOp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;per_replica_losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
 
    &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;function&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;distributed_test_step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strategy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;experimental_run_v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Train Network
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    
        &lt;span class=&quot;c1&quot;&gt;# Training Loop
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;total_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;num_batches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_dist_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;total_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distributed_train_step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;num_batches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_batches&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Test Loop
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_dist_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;distributed_test_step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;template&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;에포크 {}, 손실: {}, 정확도: {}, 테스트 손실: {}, 테스트 정확도: {}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;test_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
        <pubDate>Sun, 14 Jun 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/06/14/tf2_multi_gpu/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/06/14/tf2_multi_gpu/</guid>
        
        <category>TensorFlow</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>Review: DETR</title>
        <description>&lt;h1 id=&quot;end-to-end-object-detection-with-transformers&quot;&gt;End-to-End Object Detection with Transformers&lt;/h1&gt;

&lt;p&gt;Author: Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, and Sergey Zagoruyko
Date: May 27, 2020
URL: https://ai.facebook.com/research/publications/end-to-end-object-detection-with-transformers&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;현재 Object detection model들은 Input부터 Output (bounding bos, category label) 까지 Direct 하지 못함.  Post processing 이 영향을 끼치기 때문에…&lt;/li&gt;
  &lt;li&gt;본 논문에선 Direct prediction approach 제안.&lt;/li&gt;
  &lt;li&gt;이전에도 몇몇 실험이 있었으나 그 당시에는 prior knowledge를 준다거나 성능이 별로 좋지 못했음.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.03762&quot;&gt;Transformer&lt;/a&gt; 를 사용.&lt;/li&gt;
  &lt;li&gt;새로운 Loss function 도입.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/DETR/Untitled.png&quot; alt=&quot;jjerry-k.github.io/public/img/DETR/Untitled.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;related-works&quot;&gt;Related Works&lt;/h1&gt;

&lt;h2 id=&quot;set-prediction&quot;&gt;Set Prediction&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;현재까지 Direct로 set(box, class)을 prediction 하는 방법이 없음.&lt;/li&gt;
  &lt;li&gt;Post processing 이 없는 model 제안.&lt;/li&gt;
  &lt;li&gt;이를 위해 Hungarian algorithm 기반의 loss 설계.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;transformers-and-parallel-decoding&quot;&gt;Transformers and Parallel Decoding&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;다른 RNN 계열보다 Long sequence 에 적합한 model&lt;/li&gt;
  &lt;li&gt;auto-regressive model&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;object-detection&quot;&gt;Object detection&lt;/h2&gt;

&lt;h3 id=&quot;set-based-loss&quot;&gt;Set-based loss&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;기존에 bipatite matching loss 를 사용했지만  NMS 를 사용해야 성능이 향상되었음.&lt;/li&gt;
  &lt;li&gt;그 후 Learnable NMS 를 사용한 방법이 제시 되었으나 hand-crafted context feature 를 사용 하기에 효율적이지 못함.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;recurrent-detectors&quot;&gt;Recurrent detectors&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;이름에서 알 수 있듯 RNN 계열을 도입한 Object detection&lt;/li&gt;
  &lt;li&gt;기존 방법에선 Small dataset을 이용했고 RNN 계열을 이용했기에 parallel 구조를 가져가지 못했음.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;the-detr-model&quot;&gt;The DETR model&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;DETR은 크게 두 개의 장점이 있음. → a set prediction loss, a architecture&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/DETR/Untitled_1.png&quot; alt=&quot;jjerry-k.github.io/public/img/DETR/Untitled_1.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;object-detection-set-prediction-loss&quot;&gt;Object detection set prediction loss&lt;/h2&gt;

\[\hat{\sigma} = {argmin}_{\sigma \in \mathfrak{S}_N} \sum^N_i \mathcal{L}_{match}(y_i, \hat{y}_{\sigma(i)})\]

\[\mathcal{L}_{match}(y_i, \hat{y}_{\sigma(i)}) = -1_{c_i \neq \phi}\hat{p}_{\sigma(i)}(c_i) +1_{c_i \neq \phi}\mathcal{L}_{box}(b_i, \hat{b}_{\sigma(i)})\]

\[\mathcal{L}_{Hungarian}(y, \hat{y}) = \sum^N_i[-\log\hat{p}_{\hat{\sigma}(i)}(c_i) +1_{c_i \neq \phi}\mathcal{L}_{box}(b_i, \hat{b}_{\hat{\sigma}(i)})]\]

&lt;h3 id=&quot;bounding-box-loss&quot;&gt;Bounding box loss&lt;/h3&gt;

\[\lambda_{iou}\mathcal{L}_{iou}(b_i, \hat{b}_{\sigma(i)}) + \lambda_{\mathrm{L}1}\|b_i - \hat{b}_{\sigma(i)}\|_1\]

&lt;h2 id=&quot;detr-architecture&quot;&gt;DETR architecture&lt;/h2&gt;

&lt;h3 id=&quot;backbone&quot;&gt;Backbone&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;일반적인 Backbone 사용.&lt;/li&gt;
  &lt;li&gt;마지막 feataure map은 원본 사이즈 H, W 에 비해 32분의 1 downsampling, C는 2048&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;transformer-encoder&quot;&gt;Transformer encoder&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Attention is all you need의 Transformer의 encoder와 동일한 구조.&lt;/li&gt;
  &lt;li&gt;Fixed positional encodings 으로 인하여 permutation-invariant 한 구조!&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;transformer-decoder&quot;&gt;Transformer decoder&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Attention is all you need의 Transformer의 decoder와 동일한 구조.&lt;/li&gt;
  &lt;li&gt;기존 Transformer와 차이는&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;prediction-feed-forward-networks-ffns&quot;&gt;Prediction feed-forward networks (FFNs)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;ReLU를 사용하는 d dimension의 linear layer 3 개 사용.&lt;/li&gt;
  &lt;li&gt;한 branch 에서는 Normalized center coordinate, height, width 를 예측.&lt;/li&gt;
  &lt;li&gt;다른 하나의 branch는 class label을 softmax를 이용하여 예측.&lt;/li&gt;
  &lt;li&gt;DETR은 항상 N개의 box에 대해 예측. 하지만 실제 object 수가 적을때는 나머지 box들을 no object 로 처리.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;auxiliary-decoding-losses&quot;&gt;Auxiliary decoding losses&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Transformer decoder에  Auxiliary loss 를 추가.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;experiment&quot;&gt;Experiment&lt;/h1&gt;

&lt;h2 id=&quot;comparison-with-faster-r-cnn&quot;&gt;Comparison with Faster R-CNN&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/DETR/Untitled_2.png&quot; alt=&quot;jjerry-k.github.io/public/img/DETR/Untitled_2.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ablations&quot;&gt;Ablations&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/DETR/Untitled_3.png&quot; alt=&quot;jjerry-k.github.io/public/img/DETR/Untitled_3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/DETR/Untitled_4.png&quot; alt=&quot;jjerry-k.github.io/public/img/DETR/Untitled_4.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;panoptic-segmentation&quot;&gt;Panoptic segmentation&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/DETR/Untitled_5.png&quot; alt=&quot;jjerry-k.github.io/public/img/DETR/Untitled_5.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ps&quot;&gt;P.S&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;내용 보충 예정.&lt;/li&gt;
  &lt;li&gt;신박한 컨셉.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 13 Jun 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/06/13/DETR/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/06/13/DETR/</guid>
        
        <category>Paper</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>D-Link ddns 서비스 종료</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://eu.dlink.com/uk/en/products/dir-850l-wireless-ac1200-dual-band-gigabit-cloud-router&quot;&gt;D-Link의 DIR-815L&lt;/a&gt; 을 잘 쓰고 있었습니다…&lt;br /&gt;
라즈베리파이와 연결하여 DDNS 도해놓고..&lt;br /&gt;
근데 어느 날 다음과 같은 글이 메일, 공지로 올라오더군요.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;안녕하세요. D-Link Korea 입니다. 저희 dlink 제품군에서 제공되었던 무료 dlinkddns 서비스 종료에 관한 안내 말씀드립니다. 죄송합니다만, dlinkddns 무료 서비스는 기존에 오라클사의 dyn ddns 와의 계약만료일인 2020년 7월 2일 종료될 예정입니다. 이후에는 정상적인 무료 ddns서비스 이용이 불가하니 계속해서 dlinkddns 서비스를 이용하기를 원하실 경우에는 유료상품으로 전환하시기 바랍니다. ■ 유료전환 http://dlinkddns.com 사이트 접속시 유료전환은 안내 팝업과 함께 결재시 50% 할인 메뉴 클릭하여 진행합니다. 이외에 관련해서 궁금한 점이 있으신 분은 D-Link Korea 고객센터(1899-3540)로 문의하시기 바랍니다. 기존 무료로 지원되던 dlinkddns 서비스 종료에, 앞으로 더욱 나은 서비스로 보답하겠습니다. 감사합니다.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;What the…?&lt;br /&gt;
후… 공유기를 새로 사던 DDNS 서비스를 이용하던 해야겠네요.&lt;br /&gt;
디자인이랑 DDNS 때문에 샀는데.. 젠장.. 앞으론 그냥 Iptime 쓸래요.&lt;/p&gt;
</description>
        <pubDate>Sun, 31 May 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/living/2020/05/31/Dlink_ddns/</link>
        <guid isPermaLink="true">http://localhost:4000/living/2020/05/31/Dlink_ddns/</guid>
        
        <category>Hardware</category>
        
        
        <category>Living</category>
        
      </item>
    
      <item>
        <title>Review: ShuffleNetV2</title>
        <description>&lt;h1 id=&quot;shufflenet-v2-practical-guidelines-for-efficient-cnn-architecture-design&quot;&gt;ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design&lt;/h1&gt;

&lt;p&gt;Author: Ningning Ma, Xiangyu Zhang, Hai-Tao Zheng, Jian Sun&lt;br /&gt;
Date: Jul 30, 2018&lt;br /&gt;
URL: https://arxiv.org/abs/1807.11164&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;CNN 계열이 AlexNet 부터 정확도, 속도가 많이 발전하고 있음.&lt;/li&gt;
  &lt;li&gt;실제로는 제한된 컴퓨팅 파워에서(Mobile과 같은) 최고의 성능을 내는데 목표로 하고 있음.&lt;/li&gt;
  &lt;li&gt;이로 인해 Xception, MobileNet, ShuffleNet 등이 개발 되었음.&lt;/li&gt;
  &lt;li&gt;지금까지는 모델의 연산량을 이용하여 모델의 효율성을 판단하였으나 적합한 지표가 아님을 주장.&lt;/li&gt;
  &lt;li&gt;FLOPs와 speed 간의 성능 비교가 옳지 않은 주요 이유가 두 가지.
    &lt;ul&gt;
      &lt;li&gt;memory access cost(MAC): 메모리 접근량(사용량)&lt;/li&gt;
      &lt;li&gt;depending on the platform&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;practical-guidelines-for-ecient-network-design&quot;&gt;Practical Guidelines for Ecient Network Design&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;본 연구는 GPU 하드웨어(1080ti), ARM 하드웨어(Snapdragon 810) 이 두 가지 환경에서 실험.&lt;/li&gt;
  &lt;li&gt;모델의 Runtime을 쪼개보면 다음과 같은 차트가 그려짐.&lt;/li&gt;
  &lt;li&gt;FLOPs는 Convolution 에 대해 설명하기 떄문에 비교 지표로 적절하지 못함을 강조.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_1.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_1.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;위 문제를 근거로 다음과 같이 여러 개의 가이드 라인을 제시.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;g1-equal-channel-width-minimizes-memory-access-cost-mac&quot;&gt;G1) Equal channel width minimizes memory access cost (MAC)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;근래에 많이 사용되는 depthwise separable convoltuion에서 연산량의 대부분은 pointwise convolution 이 차지.&lt;/li&gt;
  &lt;li&gt;1x1 convolution 이 차지하는 연산량은 다음과 같음.&lt;/li&gt;
&lt;/ul&gt;

\[h, w: \text{the spatial size of the input feature map} \\ c_1, c_2: \text{Number of channels about input and output } \\ B=hwc_1c_2, \text{ FLOPs of the }1 \times 1 \text{ convolution}\]

&lt;ul&gt;
  &lt;li&gt;현 상황에서 MAC의 수식은 다음과 같음.&lt;/li&gt;
&lt;/ul&gt;

\[MAC = hw(c_1+c_2) +c_1c_2 = hwc_1 + hwc_2 + c_1c_2 \\ hwc_1: \text{Number of input feature map's element} \\ hwc_2: \text{Number of output feature map's element} \\ c_1c_2: \text{Number of filter's element}\]

&lt;ul&gt;
  &lt;li&gt;MAC의 lower bound 는 다음과 같음.&lt;/li&gt;
&lt;/ul&gt;

\[MAC \ge 2\sqrt{hwB} + \frac{B}{hw} \to 2hw\sqrt{c_1c_2} + c_1c_2\]

&lt;ul&gt;
  &lt;li&gt;$c_1 = c_2$ 이면 MAC가 최소.&lt;/li&gt;
  &lt;li&gt;전체 연산량은 고정해놓고 $c_1:c_2$의 비율을 바꿔가면서 runtime 비교.&lt;/li&gt;
  &lt;li&gt;1:1일때가 가장 빠른 성능을 보임.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_2.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_2.png&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;It reaches the lower bound when the numbers of input and output channels are equal.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;g2-excessive-group-convolution-increases-mac&quot;&gt;G2) Excessive group convolution increases MAC&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Group convolution 이 많은 네트워크의 핵심이지만 Groups가 커지면 MAC을 증가시킴. → 안쓸 수는 없으니 적당히 쓰는게 좋다.&lt;/li&gt;
  &lt;li&gt;그룹에 따라 연산량이 줄어들기 때문에 B는 다음과 같음.&lt;/li&gt;
&lt;/ul&gt;

\[B=hwc_1c_2/g\]

\[MAC = hw(c_1+c_2) + \frac{c_1c_2}{g} \\ = hwc_1 + hwc_2 + \frac{c_1c_2}{g} \\ = hwc_1 + \frac{Bg}{c_1} + \frac{B}{hw}\]

&lt;ul&gt;
  &lt;li&gt;Groups 에 따라 runtime 비교.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_3.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_3.png&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;The group number should be carefully chosen based on the target platform and task. It is unwise to use a large group number simply because this may enable using more channels, because the benet of accuracy increase can easily be outweighed by the rapidly increasing computational cost.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;g3-network-fragmentation-reduces-degree-of-parallelism&quot;&gt;G3) Network fragmentation reduces degree of parallelism&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Inception 과 같이 여러 branch를 parallel하게 구성할 경우 성능은 좋아졌지만 효율성은 감소시킴. → GPU 같은 자원에는 어울리지 않음.&lt;/li&gt;
  &lt;li&gt;Fragmentation 에 따른 runtime 비교.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_4.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_4.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_5.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_5.png&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Fragmented structure has been shown benecial for accuracy, it could decrease eciency because it is unfriendly for devices with strong parallel computing powers like GPU. It also introduces extra overheads such as kernel launching and synchronization.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;g4-element-wise-operations-are-non-negligible&quot;&gt;G4) Element-wise operations are non-negligible&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Activation, Add 와 같은 Element-wise operation들의 비율이 꽤 존재. Figure 2 참고&lt;/li&gt;
  &lt;li&gt;이 연산은 FLOPs는 적지만 상대적으로 MAC은 큼.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Depthwise convolution 또한 element-wise 여서 MAC/FLOPs 가 클 것이라 생각.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;각 상황에 대한 runtime 비교.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_6.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_6.png&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;We observe around 20% speedup is obtained on both GPU and ARM, after ReLU and shortcut are removed.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;conclusion-and-discussions&quot;&gt;Conclusion and Discussions&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;use “balanced convolutions (equal channel width);&lt;/li&gt;
  &lt;li&gt;be aware of the cost of using group convolution;&lt;/li&gt;
  &lt;li&gt;reduce the degree of fragmentation;&lt;/li&gt;
  &lt;li&gt;reduce element-wise operations.&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;다른 네트워크들에 대한 고찰
    &lt;ul&gt;
      &lt;li&gt;ShuffleNet V1
        &lt;ul&gt;
          &lt;li&gt;Heavily group convolutions → G2&lt;/li&gt;
          &lt;li&gt;Bottleneck-like building blocks → G1&lt;/li&gt;
          &lt;li&gt;Residual Block → G3&lt;/li&gt;
          &lt;li&gt;Element-wise operation→ G4&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;MobileNet V2
        &lt;ul&gt;
          &lt;li&gt;Inverted bottleneck structure → G1&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Depthwise convolution &amp;amp; ReLU
        &lt;ul&gt;
          &lt;li&gt;Element-wise operation → G4&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;NAS
        &lt;ul&gt;
          &lt;li&gt;Highly fragmentation → G3&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;shuenet-v2-an-ecient-architecture&quot;&gt;ShueNet V2: an Ecient Architecture&lt;/h1&gt;

&lt;h2 id=&quot;review-of-shuenet-v1&quot;&gt;Review of ShueNet v1&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;G1, G2, G3, G4 모두 지키지 않음.&lt;/li&gt;
  &lt;li&gt;이를 해결한 구조가 ShuffleNet V2 의 유닛 (Fig 3 (c), Fig 3 (d))&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_7.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_7.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;channel-split-and-shuenet-v2&quot;&gt;Channel Split and ShueNet V2&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Fig 3 (c)
    &lt;ul&gt;
      &lt;li&gt;Input feature 을 절반으로 나눠 두개의 branch 생성.&lt;/li&gt;
      &lt;li&gt;Left branch는 아무 연산도 진행 X. → G3 에 대한 회피법.&lt;/li&gt;
      &lt;li&gt;Right branch는 동일한 Number of filter로 1x1 Conv → 3x3 DWConv → 1x1 Conv 수행. → G1에 대한 회피법.&lt;/li&gt;
      &lt;li&gt;1x1 Conv 는 Group 을 나누지 않음 → G2에 대한 회피법.&lt;/li&gt;
      &lt;li&gt;Residual Block의 Add operation 을 Concatenate 로 변경 → G4에 대한 회피법.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Fig 3 (d)
    &lt;ul&gt;
      &lt;li&gt;Downsampling block&lt;/li&gt;
      &lt;li&gt;Input feature 그대로 두개의 branch 생성.&lt;/li&gt;
      &lt;li&gt;Number of filter는 모두 동일&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;네트워크 구조&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_8.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_8.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;analysis-of-network-accuracy&quot;&gt;Analysis of Network Accuracy&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;ShuffleNet V2는 효율적이며 성능도 좋음.
    &lt;ul&gt;
      &lt;li&gt;더 많은 channel, 더 큰 network를 만들 수 있음.&lt;/li&gt;
      &lt;li&gt;DenseNet 이나 CondenseNet 처럼 feature reuse 과 매우 유사함.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;DenseNet의 feature reuse 패턴과 ShuffleNet V2의 feature reuse 패턴 비교.&lt;/li&gt;
  &lt;li&gt;붉을 수록 Source layer와 Target layer의 연결성이 강하다는 의미.&lt;/li&gt;
  &lt;li&gt;DenseNet과 같이 ShuffleNet V2에서도 Target layer가 멀어질 수록 연결성이 약함.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_9.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_9.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;experiment&quot;&gt;Experiment&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;총 4개의 모델과 비교.
    &lt;ul&gt;
      &lt;li&gt;ShuffleNet V1&lt;/li&gt;
      &lt;li&gt;MobileNet V2&lt;/li&gt;
      &lt;li&gt;Xception&lt;/li&gt;
      &lt;li&gt;DenseNet&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_10.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_10.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;accuracy-vs-flops&quot;&gt;Accuracy vs. FLOPs&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;연산량을 40 MFLOPs 로 고정시키고 Network 를 구성한 후 성능 비교. (Table 8 상단)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;inference-speed-vs-flopsaccuracy&quot;&gt;Inference Speed vs. FLOPs/Accuracy&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;연산량을 특정 값 범위로 고정시키고 runtime 비교. (Fig 1 참조)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_11.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_11.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;compared-with-mobilenet-v1&quot;&gt;Compared with MobileNet v1&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;MobileNet V1의 경우 Accuracy가 좋지 않으나  GPU runtime은 가장 빠름.&lt;/li&gt;
  &lt;li&gt;이는 위에서 제시한 가이드 라인을 어느 정도 가장 잘 만족하기 때문.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;compared-automatic-model-search&quot;&gt;Compared automatic model search&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;NAS 는 매우 느리지만 제시한 가이드 라인을 만족하고 speed에 대한 metric을 사용한다면 충분히 좋은 성능을 보일 것.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;compatibility-with-other-methods&quot;&gt;Compatibility with other methods&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Squeeze-and-excitation 과 같은 module과 같이 사용할 수 있음.&lt;/li&gt;
  &lt;li&gt;속도는 떨어지나 정확도는 상승. (Table 8 하단)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;generalization-to-large-models&quot;&gt;Generalization to Large Models&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;2GFLOPs 이상의 큰 모델을 생성할 수 있음.&lt;/li&gt;
  &lt;li&gt;50개의 레이어를 가진 모델을 생성해도 ResNet-50 과 비교하여 적은 연산량, 뛰어난 성능을 보임. (Table 6 상단)&lt;/li&gt;
  &lt;li&gt;SE module, residual block을 사용하여 더욱 깊게 만들어도 상대적으로 연산량이 적으면서 뛰어난 성능을 보임. (Table 6 하단)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_12.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_12.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;object-detection&quot;&gt;Object Detection&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1711.07264&quot;&gt;Light-Head RCNN&lt;/a&gt; 사용.&lt;/li&gt;
  &lt;li&gt;Classification 에서 성능이 별로였던 Xception 이 Detection 에선 성능이 좋음. → Receptive Field가 크기 때문이라고 생각.&lt;/li&gt;
  &lt;li&gt;3x3 depthwise convolution 을 추가하여 Receptive Field를 키워보니 (ShuffleNet V2*) runtime은 늘었으나 성능이 증가함.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_13.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_13.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ps&quot;&gt;P.S&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;어려웠다.&lt;/li&gt;
  &lt;li&gt;항상 가이드 라인을 지키면서 모델을 설계할 수 있을까?&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 09 May 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/05/09/ShuffleNetV2/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/05/09/ShuffleNetV2/</guid>
        
        <category>Paper</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>Review: ResNeXt</title>
        <description>&lt;h1 id=&quot;aggregated-residual-transformations-for-deep-neural-networks&quot;&gt;Aggregated Residual Transformations for Deep Neural Networks&lt;/h1&gt;

&lt;p&gt;Author: Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, Kaiming He&lt;br /&gt;
Date: Nov 16, 2016&lt;br /&gt;
URL: https://arxiv.org/abs/1611.05431&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Network desine 에 고려해야할 hyper-parameter가 너무 많음. (Width, filter size, Height, ….)&lt;/li&gt;
  &lt;li&gt;VGG, ResNet은 비슷한 구조의 레이어를 계속 쌓는 방법을 사용.&lt;/li&gt;
  &lt;li&gt;Inception 은 성능은 이전보다 뛰어나지만 이전 방법들과 다르게 복잡한 구조를 쌓는 방법 사용.&lt;/li&gt;
  &lt;li&gt;본 논문에서는 VGG/ResNet과 같이 비슷한 레이어를 반복하지만 AlexNet 에서 나온 처음 제안된 Group Convolution 을 적용하여 split-transform-merge stretegy 를 도입.&lt;/li&gt;
  &lt;li&gt;일반적인 Reidual Block과 ResNeXt의 Residual Block 비교.&lt;/li&gt;
  &lt;li&gt;Cardinality = Number of Groups,&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;method&quot;&gt;Method&lt;/h1&gt;

&lt;h2 id=&quot;template&quot;&gt;Template&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;전체적인 구조는 기존의 VGG/ResNet과 같이 일정 Block 을 반복하여 쌓는 구조.&lt;/li&gt;
  &lt;li&gt;반복되는 블럭은 동일한 hyper parameter 사용.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_1.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_1.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;revisiting-simple-neurons&quot;&gt;Revisiting Simple Neurons&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;가장 기본적인 뉴런의 구조&lt;/li&gt;
&lt;/ul&gt;

\[\sum_{i=1}^Dw_ix_i\]

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_2.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_2.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;기본 뉴런 또한 split-transform-merge (Splitting, Transforming, Aggregating)의 구조를 가짐.&lt;/li&gt;
  &lt;li&gt;Vector X 가 $x_i$로 Splitting, $x_iw_i$로 Transforming, $\sum_{i=1}^D$ 로 Aggregating&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;aggregated-transformations&quot;&gt;Aggregated Transformations&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Networt-in-Network와 다르게 Network-in-Neuron이라는 컨셉으로 차원 확장&lt;/li&gt;
&lt;/ul&gt;

\[\mathcal{F}(x) = \sum_{i=1}^C\mathcal{T}_i(\mathrm{x})\]

&lt;ul&gt;
  &lt;li&gt;다른 방식이지만 동일하다는 것을 설명&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_3.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_4.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_4.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model-capacity&quot;&gt;Model Capacity&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Complexity, Number of parameter 를 유지하면서 실험.&lt;/li&gt;
  &lt;li&gt;다른 Hyper parameter는 수정하고 싶지 않기 때문에 Residual Block의 Cardinality C와 bottleneck d를 수정&lt;/li&gt;
  &lt;li&gt;Cardinality와 bottleneck d의 관계&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_5.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_5.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;result&quot;&gt;Result&lt;/h1&gt;

&lt;h2 id=&quot;on-imagenet-1k&quot;&gt;On ImageNet-1K&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Cardinality를 1~32 씩 증가시키되 complexity 는 유지하도록 설정하고 실험.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_6.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_6.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_7.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_7.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Increasing Cardinality 와  Increasing depth or width 비교&lt;/li&gt;
  &lt;li&gt;Cardinality 의 성능이 더 좋음.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_8.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_8.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Residual connections 여부에 따른 비교&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_9.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_9.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;State-of-the-art model 과 비교&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_10.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_10.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;on-imagenet-5k&quot;&gt;On ImageNet-5K&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;5000개 클래스에서도 잘 되더라.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_11.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_11.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_12.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_12.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;on-cifar&quot;&gt;On CIFAR&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_13.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_13.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_14.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_14.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;on-coco-object-detection&quot;&gt;On COCO object detection&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Faster RCNN에 적용.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_15.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/resnext/Untitled_15.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ps&quot;&gt;P.S&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;AlexNet의 선견지명.&lt;/li&gt;
  &lt;li&gt;하긴 안좋으면 논문으로 쓸리가 없지.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 08 May 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/05/08/ResNeXt/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/05/08/ResNeXt/</guid>
        
        <category>Paper</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>Review: ShuffleNetV1</title>
        <description>&lt;h1 id=&quot;shufflenet-an-extremely-efficient-convolutional-neural-network-for-mobile-devices&quot;&gt;ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices&lt;/h1&gt;

&lt;p&gt;Author: Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, Jian Sun&lt;br /&gt;
Date: Jul 04, 2017&lt;br /&gt;
URL: https://arxiv.org/abs/1707.01083&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Visual recognition 에서 deeper, larger CNN을 설계하는 것이 트렌드.&lt;/li&gt;
  &lt;li&gt;하지만 이는 매우 많은 연산량을 필요로함.&lt;/li&gt;
  &lt;li&gt;본 논문은 정해놓은 범위의 연산량에서 최고로 효율적인 구조는 찾아내는 것을 목표로 함.&lt;/li&gt;
  &lt;li&gt;Xception, ResNeXt 에서 1x1 Convolution 을 사용하는데 두 네트워크에서 대부분의 연산량이 1x1 Convolution 이 차지하고 있어 비효율적.&lt;/li&gt;
  &lt;li&gt;이를 보완하기 위해 AlexNet에서 처음 제안한 group convolution 적용.&lt;/li&gt;
  &lt;li&gt;Group convolution 의 단점을 보완하기 위해 channel shuffle operation 또한 제안.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;method&quot;&gt;Method&lt;/h1&gt;

&lt;h2 id=&quot;channel-shuffle-for-group-convolutions&quot;&gt;Channel Shuffle for Group Convolutions&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;상대적으로 연산량이 많은 1x1 Convolution을 ResNeXt 에서 사용한 Group Convolution 으로 적용.&lt;/li&gt;
  &lt;li&gt;하지만 Group으로 계속 진행하다보면 특정 채널에 편향된 결과를 보이는 문제가 생길 것이므로 channel을 shuffle 해줌.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv1/Untitled.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv1/Untitled.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;shufflenet-unit&quot;&gt;ShuffleNet Unit&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;ShuffleNet에서 사용된 Bottle unit은 Xception과 MobileNet에서 사용된 Residual Block에서 1x1 Convolution을 Group Convolution으로 변경하고 Channel Shuffle을 추가한 것.&lt;/li&gt;
  &lt;li&gt;Stride unit 에선 element-wise addition이 아닌 concatenation으로 대체.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_1.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_1.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;network-architecture&quot;&gt;Network Architecture&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_2.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_2.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;result&quot;&gt;Result&lt;/h1&gt;

&lt;h2 id=&quot;ablation-study&quot;&gt;Ablation Study&lt;/h2&gt;

&lt;h3 id=&quot;pointwise-group-convolutions&quot;&gt;Pointwise Group Convolutions&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Groups 에 따른 성능 비교.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ShuffleNet s$\times$ 에서 s는 필터 개수에 대한 scaling factor.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;무조건 많이 나눈다고 좋은 것은 아님.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_3.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_3.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;channel-shuffle-vs-no-shuffle&quot;&gt;Channel Shuffle vs. No Shuffle&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Channel Shuffle 여부에 따른 성능 비교.&lt;/li&gt;
  &lt;li&gt;Shuffle 적용시 성능이 뚜렷하게 증가한 것을 확인.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_4.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_4.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;comparison-with-other-sturcture-units&quot;&gt;Comparison with Other Sturcture Units&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;제한된 연산량 내에서 다른 Network 들과 성능 비교.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_5.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_5.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;기존에 비슷한 성능의 Network들과 연산량 비교.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_6.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_6.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;comparison-with-mobilenets-and-other-frameworks&quot;&gt;Comparison with MobileNets and Other Frameworks&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Mobile devices에 특화된 MobileNet과 성능 비교&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_7.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_7.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;generalization-ability&quot;&gt;Generalization Ability&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;MS COCO Data를 사용하여 Object detection 성능 비교.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_8.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_8.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;actual-speedup-evaluation&quot;&gt;Actual Speedup Evaluation&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Mobile device에서 Inference 속도 비교.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_9.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_9.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ps&quot;&gt;P.S&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;GPU가 부족해서 했다던 Group Convolution의 부활..?&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 07 May 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/05/07/ShuffleNetV1/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/05/07/ShuffleNetV1/</guid>
        
        <category>Paper</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>Review: CutMix</title>
        <description>&lt;h1 id=&quot;cutmix-regularization-strategy-to-train-strong-classifiers-with-localizable-features&quot;&gt;CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features&lt;/h1&gt;

&lt;p&gt;Author: Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun, Junsuk Choe, Youngjoon Yoo&lt;br /&gt;
Date: May 13, 2019&lt;br /&gt;
URL: https://arxiv.org/abs/1905.04899&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;CNN 은 computer vision 문제에 많이 사용되고 있음.&lt;/li&gt;
  &lt;li&gt;효율적이고 높은 성능을 위해 data augmentation, regularization 등 기법을 적용.&lt;/li&gt;
  &lt;li&gt;특정 부분에 overfitting(?) 되는 것을 방지하기 위해 dropout, regional dropout 과 같은 방법 사용.&lt;/li&gt;
  &lt;li&gt;그 외에도 일부분을 0으로 채운다거나 노이즈로 채우는 방법, 정보가 있는 부분의 pixel을 줄이는 방법 등이 성능 향상을 보였으나 CNN은 데이터가 많이 고픈데….데이터를 없앤다..? 라는 부분에서 의문을 가짐.&lt;/li&gt;
  &lt;li&gt;영상의 일부를 자르고 다른 영상으로 대체하는 CutMix 를 제안.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;cutmix&quot;&gt;CutMix&lt;/h1&gt;

&lt;h2 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;A, B 두개의 클래스만 존재.&lt;/li&gt;
&lt;/ul&gt;

\[(x, y): \text{Training image, label} \\ (A, B): \text{Training class} \\ (x_A, y_A), (x_B, y_B): \text{Training sample}\]

&lt;ul&gt;
  &lt;li&gt;어느 부분을 섞을 것인지 binary mask (M) 생성&lt;/li&gt;
  &lt;li&gt;생성된 mask를 통해 섞을 비율 lambda 추출.&lt;/li&gt;
  &lt;li&gt;Label의 경우 비율에 One-hot encoding이 합친 후 영상에서의 각 클래스의 비율로 변경.&lt;/li&gt;
&lt;/ul&gt;

\[\mathrm{M}: \text{Binary mask where to drop out and fill} \\ \lambda: \text{Combination ratio} \\ \tilde{x} = \mathrm{M} \bigodot x_A + (1 - \mathrm{M}) \bigodot x_B \\ \tilde{y} = \lambda{y_A} + (1 - \lambda)y_B\]

&lt;ul&gt;
  &lt;li&gt;M에서 bounding box 좌표 (B) 추출.&lt;/li&gt;
  &lt;li&gt;x, y 좌표는 Uniform distribution.&lt;/li&gt;
  &lt;li&gt;$x_B$에서 B 를 매칭시켜서 crop 후 B에 매칭되는 $x_A$ 의 부분에 paste.&lt;/li&gt;
&lt;/ul&gt;

\[\mathrm{B}: \text{Bounding box coordinates }  (r_x, r_y, r_w, r_h) \\ r_x \sim \text{Unif }(0, W), r_w = W\sqrt{1-\lambda}, \\ r_y \sim \text{Unif } (0, H), r_h = H\sqrt{1-\lambda}\]

&lt;h2 id=&quot;discussion&quot;&gt;Discussion&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;CutMix를 이용했을 때 CNN이 어느 부분을 학습하는지 확인.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_1.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_1.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;다른 method와 비교하여 CutMix의 주요 차이점.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_2.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_2.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Validation Error를 비교했을 때 기존의 모델에 비해 CutMix 적용시 Error가 낮음.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_3.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_3.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;experiments&quot;&gt;Experiments&lt;/h1&gt;

&lt;h2 id=&quot;image-classification&quot;&gt;Image Classification&lt;/h2&gt;

&lt;h3 id=&quot;imagenet-classification&quot;&gt;ImageNet Classification&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Baseline, 다른 augmentation method와 비교&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_4.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_4.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;두 Model에 CutMix를 적용하여 성능 비교.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_5.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_5.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;cifar-classification&quot;&gt;CIFAR Classification&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;다른 Regularization 들과 비교.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_6.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_6.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;가벼운 Model 에 적용하여 비교.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_7.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_7.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CIFAR-10에 적용한 결과.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_8.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_8.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;ablation-studies&quot;&gt;Ablation Studies&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;CutMix 에서 alpha가 뭐지…….&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_9.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_9.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CutMix하는 방법을 다양하게 적용했을 때 성능 비교&lt;/li&gt;
  &lt;li&gt;Center Gaussian: Uniform distribution → Gaussian distribution&lt;/li&gt;
  &lt;li&gt;Fixed-size: 16 x 16 ( $\lambda = 0.75$ )로 고정&lt;/li&gt;
  &lt;li&gt;Scheduled: 학습이 진행될 수록 CutMix 확률을 0부터 1까지 증가&lt;/li&gt;
  &lt;li&gt;One-hot: 패치 비율에 따라 Portion label이 아닌 One-hot encoding으로 적용&lt;/li&gt;
  &lt;li&gt;Complete-label: lambda 를 고려하지 않고 $y = 0.5y_A + 0.5y_B$로 적용&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_10.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_10.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;weakly-supervised-object-localization&quot;&gt;Weakly Supervised Object Localization&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Localization 부분에 대해 다른 방법들과 비교.&lt;/li&gt;
  &lt;li&gt;학습 후 CAM을 이용해서 bounding box를 그린 것으로 보임.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_11.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_11.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_12.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_12.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;transfer-learning-of-pretrained-model&quot;&gt;Transfer Learning of Pretrained Model&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Object detection, Image captioning 에 적용하여 성능 비교.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_13.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_13.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;robustness-and-uncertainty&quot;&gt;Robustness and Uncertainty&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Adversarial attack 에 대해 Accuracy 비교.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1412.6572&quot;&gt;Fast Gradient Sign Method (FGSM)&lt;/a&gt;을 이용하여 adversarial perturbation 생성.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_14.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_14.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Occlusion 상황에 대해서 성능 비교.&lt;/li&gt;
  &lt;li&gt;가운데 부분 혹은 Boundary 에 0~224 크기 사이의 hole을 생성.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_15.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_15.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Uncertainty&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_16.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_16.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;cutmix-algorithm&quot;&gt;CutMix Algorithm&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_17.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cutmix/Untitled_17.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ps&quot;&gt;P.S&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Appendix에 내용이 더 있지만… 간단히 정리하려니 넣기 좀 힘듦.&lt;/li&gt;
  &lt;li&gt;당연한 얘기지만 모든 데이터에 적용하기엔 어려움이 있을 것으로 보임.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 06 May 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/05/06/CutMix/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/05/06/CutMix/</guid>
        
        <category>Paper</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>개인적인 도커 파일</title>
        <description>&lt;h1 id=&quot;지극히-개인이-사용하기-위한-dockerfile&quot;&gt;지극히 개인이 사용하기 위한 Dockerfile&lt;/h1&gt;

&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;환경을 만들 때마다 추가될 예정입니다.&lt;/li&gt;
  &lt;li&gt;마음껏 편하신대로 Copy &amp;amp; Paste 하세요!&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;tensorflow&quot;&gt;TensorFlow&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&quot;language-Dockerfile&quot;&gt;FROM nvidia/cuda:10.1-cudnn7-runtime-ubuntu18.04
LABEL maintainer &quot;Jerry Kim &amp;lt;jaeyeol2931@gmail.com&amp;gt;&quot;
ARG PYTHON_VERSION=3.7
RUN apt-get update
RUN apt-get install -y \
        build-essential \
        cmake \
        git \
        curl \
        wget \
        ca-certificates \
        libjpeg-dev \
        libpng-dev

RUN apt-get update &amp;amp;&amp;amp; apt-get -y upgrade

RUN rm -rf /var/lib/apt/lists/*

RUN curl https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -o ~/miniconda.sh

RUN chmod +x ~/miniconda.sh &amp;amp;&amp;amp; \
    ~/miniconda.sh -b -p /opt/conda &amp;amp;&amp;amp; \
    rm ~/miniconda.sh

RUN /opt/conda/bin/conda install -y python=$PYTHON_VERSION numpy pyyaml scipy ipython mkl mkl-include ninja cython typing opencv matplotlib tqdm &amp;amp;&amp;amp; \
    /opt/conda/bin/conda install -y jupyter jupyterlab seaborn pillow pandas pylint scikit-learn scikit-image tensorflow-gpu &amp;amp;&amp;amp; \
    /opt/conda/bin/conda update -y --all &amp;amp;&amp;amp; \
    /opt/conda/bin/conda clean -ya

ENV PATH /opt/conda/bin:$PATH

&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Tue, 05 May 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/living/2020/05/05/dockerfile/</link>
        <guid isPermaLink="true">http://localhost:4000/living/2020/05/05/dockerfile/</guid>
        
        <category>Docker</category>
        
        
        <category>Living</category>
        
      </item>
    
      <item>
        <title>Review: EfficientNet</title>
        <description>&lt;h1 id=&quot;efficientnet-rethinking-model-scaling-for-convolutional-neural-networks&quot;&gt;EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks&lt;/h1&gt;

&lt;p&gt;Author: Mingxing Tan, Quoc V. Le&lt;br /&gt;
Date: May 28, 2019&lt;br /&gt;
URL: https://arxiv.org/abs/1905.11946&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;ConvNet 의 성능을 높이는데 Depth, Width, Image size 중 하나를 증가 시키는게 일반적인 방법.&lt;/li&gt;
  &lt;li&gt;본 논문에서는 ConvNet의 성능과 효율성을 증가시키기 위한 원론적인 방법에 대한 연구.&lt;/li&gt;
  &lt;li&gt;실험의 결과로 &lt;strong&gt;&lt;em&gt;Compound scaling method&lt;/em&gt;&lt;/strong&gt; 를 제안.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;compound-model-scaling&quot;&gt;Compound Model Scaling&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Scaling 문제에 대한 정의, Approache 별 연구, 새로운 방법에 대한  내용 서술.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;problem-formulation&quot;&gt;Problem Formulation&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Model scaling은 Baseline 에서 Length(Depth), Width, Resolution 를 확장.&lt;/li&gt;
  &lt;li&gt;하지만 실제론 리소스에 제약이 있으니 이에 맞춰 문제를 새롭게, 단순하게 정의.&lt;/li&gt;
  &lt;li&gt;Design space를 줄이기 위해 모든 레이어는 상수 값을 이용하여 규칙적으로 변화하도록 함.&lt;/li&gt;
  &lt;li&gt;최종 목적은 제한된 리소스에서 성능을 최대화하는 것.&lt;/li&gt;
&lt;/ul&gt;

\[\mathcal{N}: \text{ConvNet} \\ \mathcal{F}_i: \text{Layer architecture} \\ L_i: \text{Network length} \\ C_i: \text{Width} \\ H_i, W_i: \text{Input resolution}\]

\[{max}_{d, w, r} Accuracy(\mathcal{N}(d, w, r)) \\ s.t. \mathcal{N}(d, w, r) = \bigodot_{i=1...s}\hat{\mathcal{F}}_i^{d \cdot \hat{L}_i}(X_{\langle r\cdot \hat{H}_i, r \cdot \hat{W}_i, w\cdot \hat{C}_i \rangle} ) \\ Memory(\mathcal{N}) \leq \text{target memory} \\FLOPS(\mathcal{N}) \leq \text{target flops}\]

&lt;h2 id=&quot;scaling-dimensions&quot;&gt;Scaling Dimensions&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;두번째 문제는 d, w, r 이 서로 dependent 하고 제한된 리소스에 따라 값이 변화.&lt;/li&gt;
  &lt;li&gt;그래서 기존에는 다음 세 개의 요소 중 하나를 변경함.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;depth-d&quot;&gt;Depth (d)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;VGGNet, GoogLeNet, ResNet 등등 레이어를 많이 많이 !&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;width-w&quot;&gt;Width (w)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;채널 수를 늘리고 깊이를 줄이는 방식.&lt;/li&gt;
  &lt;li&gt;하지만 &lt;strong&gt;higher level feature를 잡기 힘들 수 있음.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;resolution-r&quot;&gt;Resolution (r)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;클수록 더 양질의 패턴을 찾을 수 있음.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_1.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_1.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Observation 1: 이를 통해서 어떤 요소를 증가시키던 성능이 오르는 것을 확인 하지만 Model이 무거워짐.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;compound-scaling&quot;&gt;Compound Scaling&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;경험적으로 세 요소가 dependent 하다는 것을 이미 알고 있음.&lt;/li&gt;
  &lt;li&gt;다른 depth, resolution 을 이용하여 성능 비교.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_2.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_2.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Observation 2: 세 요소의 balance가 매우 중요..&lt;/li&gt;
  &lt;li&gt;다음과 같은 compound scaling method 제안.&lt;/li&gt;
&lt;/ul&gt;

\[\phi: \text{Compound Coefficient} \\ depth: d = \alpha^\phi \\ width: w = \beta^\phi \\ resolution: r = \gamma^\phi \\ \text{s.t. }\alpha \cdot \beta^2 \cdot \gamma^2 \approx 2 \\ \alpha \ge 1, \beta \ge 1, \gamma \ge 1\]

&lt;ul&gt;
  &lt;li&gt;각 값은 small grid search로 결정된 상수 값.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;efficientnet-architecture&quot;&gt;EfficientNet Architecture&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_3.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_3.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;EfficientNet-B0 를 baseline network로 하여  Accuracy, FLOPS 둘 다 최적화하도록 multi-objective neural architecture search 적용.
    &lt;ul&gt;
      &lt;li&gt;Step 1
        &lt;ul&gt;
          &lt;li&gt;$\phi$ =1 로 고정&lt;/li&gt;
          &lt;li&gt;식 2, 3을 기반으로 하여 small grid search&lt;/li&gt;
          &lt;li&gt;EfficientNet-B0에 가장 적합한 값을 $\alpha$=1.2, $\beta$=1.1, $\gamma$=1.15&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Step 2
        &lt;ul&gt;
          &lt;li&gt;$\alpha$, $\beta$, $\gamma$를 고정하고 $\phi$를 변경하여 실험.&lt;/li&gt;
          &lt;li&gt;Result (ImageNet Result for EfficientNet) 참고&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;result&quot;&gt;Result&lt;/h1&gt;

&lt;h2 id=&quot;scaling-up-mobilenets-and-resnets&quot;&gt;Scaling Up MobileNets and ResNets&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Compound scale 을 증명하기 위해 MobileNet과 ResNet을 이용하여 비교.&lt;/li&gt;
  &lt;li&gt;기존의 방법들은 3개중 1개의 요소만 scaling.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_4.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_4.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;imagenet-result-for-efficientnet&quot;&gt;ImageNet Result for EfficientNet&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Training Setting
    &lt;ul&gt;
      &lt;li&gt;Optimization
        &lt;ul&gt;
          &lt;li&gt;RMSProp&lt;/li&gt;
          &lt;li&gt;Decay: 0.9&lt;/li&gt;
          &lt;li&gt;Momentum: 0.9&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Batch normalization
        &lt;ul&gt;
          &lt;li&gt;Momentum: 0.99&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Weight decay: 1e-5&lt;/li&gt;
      &lt;li&gt;Initial learning rate: 0.256
        &lt;ul&gt;
          &lt;li&gt;Decay: 0.97 (every 2.4 epochs)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Swish Activation&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1805.09501&quot;&gt;AutoAugmentation&lt;/a&gt;: 뭔지 모르겠군 1&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1603.09382&quot;&gt;Stochastic depth&lt;/a&gt;: 뭔지 모르겠군 2
        &lt;ul&gt;
          &lt;li&gt;Drop connect ratio: 0.2&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Dropout
        &lt;ul&gt;
          &lt;li&gt;0.2 ~ 0.5 (B0 ~ B7)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;B0부터 B7 까지 성능 비교.&lt;/li&gt;
  &lt;li&gt;GPipe에 비해 &lt;strong&gt;8.4배 적고 좋은 성능.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_5.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_5.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CPU를 이용한 Inference 속도 비교.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_6.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_6.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;모델별 FLOPS-Accuracy curve&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_7.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_7.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;transfer-learning-result-for-efficientnet&quot;&gt;Transfer Learning Result for EfficientNet&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;ImageNet pretrained model 을 이용하여 각종 Dataset을 Transfer learning 한 성능 비교&lt;/li&gt;
  &lt;li&gt;사용한 Dataset&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_8.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_8.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Transfer learning 결과&lt;/li&gt;
  &lt;li&gt;전체적으로 모델이 가벼움.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_9.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_9.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;기존의 모델들과 비교하여 가볍지만 뛰어난 성능을 보임.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_10.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_10.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;discussion&quot;&gt;Discussion&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;EfficientNet-B0 를 이용하여 각기 다른 scaling method를 이용하여 성능 비교&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_11.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_11.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_12.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_12.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_13.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/efficientnet/Untitled_13.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ps&quot;&gt;P.S&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;이런 연구는..NAS(Network Architecture Search)가 답..인건가&lt;/li&gt;
  &lt;li&gt;근데 이것도 하드웨어가 빵빵해야….. 크흡&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 02 May 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/05/02/EfficientNet/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/05/02/EfficientNet/</guid>
        
        <category>Paper</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>Review: CBAM</title>
        <description>&lt;h1 id=&quot;cbam-convolutional-block-attention-module&quot;&gt;CBAM: Convolutional Block Attention Module&lt;/h1&gt;

&lt;p&gt;Author: Sanghyun Woo, Jongchan Park, Joon-Young Lee, In So Kweon&lt;br /&gt;
Date: Jul 17, 2018&lt;br /&gt;
URL: https://arxiv.org/abs/1807.06521&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;BAM 에서 설명한 것처럼 최근 CNN 성능 향상에 주로 연구되는 요소는 depth, width, cardinality.&lt;/li&gt;
  &lt;li&gt;본 논문에선 Convolutional Block Attention Module(CBAM) 제안.&lt;/li&gt;
  &lt;li&gt;Convolution을 이용하여 channel, spatial information 을 추출하고 섞어서 사용.&lt;/li&gt;
  &lt;li&gt;channel, spatial attention module은 각각 “what”, “where”에 대한 정보를 학습할 수 있음.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cbam/Untitled.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cbam/Untitled.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;convolutional-block-attention-module&quot;&gt;Convolutional Block Attention Module&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;CBAM 의 구조는 다음 사진과 같음.&lt;/li&gt;
&lt;/ul&gt;

\[F: \text{Input feature map} \\ F':\text{Channel attention module feature map} \\ F'': \text{Spatial attention module feature map} \\ F' = M_c(F)\bigotimes F \\F'' = M_s(F')\bigotimes F'\]

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cbam/Untitled_1.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cbam/Untitled_1.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;channel-attention-branch&quot;&gt;Channel attention branch&lt;/h2&gt;

\[M_c(F) = \sigma(MLP(AvgPool(F)) + MLP(MaxPool(F))) \\ = \sigma(W1(W0(F^c_{avg})) + W1(W0(F^c_{max})))\]

&lt;p&gt;W0 의 output channel 크기: F의 채널 수 / reduction ratio(r)&lt;/p&gt;

&lt;p&gt;W1 의 output channel 크기: F의 채널 수&lt;/p&gt;

&lt;h2 id=&quot;spatial-attention-branch&quot;&gt;Spatial attention branch&lt;/h2&gt;

\[M_s(F)=\sigma(f^{7\times7}([AvgPool(F); MaxPool(F)])) \\ = \sigma(f^{7 \times 7}([F^s_{avg};F^s_{max}]))\]

&lt;ul&gt;
  &lt;li&gt;7x7 Convolution의 output channel 크기: 1&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;arrangement-of-attention-modules&quot;&gt;Arrangement of attention modules&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;두 branch의 순서를 어떻게 배열할지 고민.&lt;/li&gt;
  &lt;li&gt;실험적으로 Channel → Spatial 로 하기로 함.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ablation-study-using-imagenet-1k&quot;&gt;Ablation study using ImageNet-1K&lt;/h1&gt;

&lt;h2 id=&quot;channel-attention&quot;&gt;Channel attention&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Pooling 기법별 성능 비교&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cbam/Untitled_2.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cbam/Untitled_2.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;spatial-attention&quot;&gt;Spatial attention&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Pooling, convolution kernel size 에 따른 성능 비교&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cbam/Untitled_3.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cbam/Untitled_3.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;arrangement-of-the-channel-and-spatial-attention&quot;&gt;Arrangement of the channel and spatial attention&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Attention module 순서에 따른 성능 비교&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cbam/Untitled_4.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cbam/Untitled_4.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;result&quot;&gt;Result&lt;/h1&gt;

&lt;h3 id=&quot;classification-result-on-imagenet-1k&quot;&gt;Classification Result on ImageNet-1K&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cbam/Untitled_5.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cbam/Untitled_5.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cbam/Untitled_6.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cbam/Untitled_6.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cbam/Untitled_7.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cbam/Untitled_7.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;object-detection-on-ms-coco-and-voc-2007&quot;&gt;Object Detection on MS COCO and VOC 2007&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cbam/Untitled_8.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cbam/Untitled_8.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cbam/Untitled_9.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cbam/Untitled_9.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;network-visualization-with-grad-cam&quot;&gt;Network Visualization with Grad-CAM&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/cbam/Untitled_10.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/cbam/Untitled_10.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ps&quot;&gt;P.S&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;BAM과 동일하게 Original Code가 있지만….논문과 다른 부분이 매우 많음.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 30 Apr 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/04/30/CBAM/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/04/30/CBAM/</guid>
        
        <category>Paper</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>Review: BAM</title>
        <description>&lt;h1 id=&quot;bam-bottleneck-attention-module&quot;&gt;BAM: Bottleneck Attention Module&lt;/h1&gt;

&lt;p&gt;Author: Jongchan Park, Sanghyun Woo, Joon-Young Lee, In So Kweon&lt;br /&gt;
Date: Jul 17, 2018&lt;br /&gt;
URL: https://arxiv.org/abs/1807.06514&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;DL은 Classification, Detection, Segmentation 등 많은 패턴 인식 분야에서 강력한 Tool로 사용.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;성능을 올리기 위해서 좋은 backbone을 설계하는 것이 기본적인 접근법.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;직관적인 방법은 더 깊게 설계하는 것.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;VGGNet는 AlexNet 보다 두배 이상.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ResNet 은 VGGNet보다 22배 이상이면서 residual connections 사용하여 gradient flow 를 향상.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;GoogLeNet 은 매우 깊고 같은 layer에서 다양한 feature를 사용하여 성능 향상.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;DenseNet 이전 layer의 feature map 들을 concatenation 하여 사용.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;WideResNet, PyramidNet layer의 channels 를 증가하여 성능 향상.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ResNeXt, Xception과 같은 backbone은 grouped convolutions을 이용하여 성능 향상.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;본 논문에선 attention 의 효과를 보기 위해 기존의 architecture 에 사용하기 쉬운 가벼운 Bottle Attention Module(BAM) 제안&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/bam/Untitled.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/bam/Untitled.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;bottleneck-attention-module&quot;&gt;Bottleneck Attention Module&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;BAM 의 구조는 다음 사진과 같음.&lt;/li&gt;
&lt;/ul&gt;

\[F: \text{Input feature map} \\ M(F): \text{Attention map} \\F' = F + F\bigotimes M(F) \\ M(F) = \sigma(M_c(F) + M_s(F))\]

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/bam/Untitled_1.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/bam/Untitled_1.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;channel-attention-branch&quot;&gt;Channel attention branch&lt;/h2&gt;

\[M_c(F) = BN(MLP(AvgPool(F))) \\ = BN(W_1(W_0AvgPool(F) + b_0)+b_1)\]

&lt;p&gt;W0 의 output channel 크기: F의 채널 수 / reduction ratio(r)&lt;/p&gt;

&lt;p&gt;W1 의 output channel 크기: F의 채널 수&lt;/p&gt;

&lt;h2 id=&quot;spatial-attention-branch&quot;&gt;Spatial attention branch&lt;/h2&gt;

\[M_s(F)=BN(f_3^{1\times1}(f_2^{3\times3}(f_1^{3\times3}(f_0^{1\times1}(F)))))\]

&lt;ul&gt;
  &lt;li&gt;모든 연산은 convolution 연산.&lt;/li&gt;
  &lt;li&gt;3x3 Convolution 연산 수행시엔 dilation convolution 사용.&lt;/li&gt;
  &lt;li&gt;첫번째~세번째 Convolution 의 output channel 크기: F의 채널 수 / reduction ratio(r)&lt;/li&gt;
  &lt;li&gt;마지막 Convolution 의 output channel 크기: 1&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;combine-two-attention-branches&quot;&gt;Combine two attention branches&lt;/h2&gt;

\[M(F) = \sigma(M_c(F) + M_s(F))\]

&lt;ul&gt;
  &lt;li&gt;Channel attention branch 출력: 1x1xR&lt;/li&gt;
  &lt;li&gt;Spatial attention branch 출력: HxWx1&lt;/li&gt;
  &lt;li&gt;두 attention branch를 합치는 방법으로 element-wise summation, multiplication, max operation 고려.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ablation-study-using-cifar-100&quot;&gt;Ablation study using CIFAR-100&lt;/h1&gt;

&lt;h2 id=&quot;dilation-value-and-reduction-ratio&quot;&gt;Dilation value and Reduction ratio&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Dilation value와 Reduction ratio에 따른 성능 비교&lt;/li&gt;
  &lt;li&gt;Table 1 (a)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;separate-or-combined-branches--combining-methods&quot;&gt;Separate or Combined branches &amp;amp; Combining methods&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;두 attention branch 사용 방법에 따른 성능 비교&lt;/li&gt;
  &lt;li&gt;Table 1 (b)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;comparison-with-placing-original-convblocks&quot;&gt;Comparison with placing original convblocks&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;BAM 사용 여부에 따른 성능 비교&lt;/li&gt;
  &lt;li&gt;Table 1 (c)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/bam/Untitled_2.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/bam/Untitled_2.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;bottleneck-the-efficient-point-to-place-bam&quot;&gt;Bottleneck: The efficient point to place BAM&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;BAM 사용 위치에 따른 성능 비교.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/bam/Untitled_3.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/bam/Untitled_3.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;result&quot;&gt;Result&lt;/h1&gt;

&lt;h2 id=&quot;classification-result-on-cifar-100-and-imagenet-1k&quot;&gt;Classification Result on CIFAR-100 and ImageNet-1K&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/bam/Untitled_4.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/bam/Untitled_4.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;object-detection-on-ms-coco-and-voc-2007&quot;&gt;Object Detection on MS COCO and VOC 2007&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/bam/Untitled_5.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/bam/Untitled_5.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;comparison-with-squeeze-and-excitation&quot;&gt;Comparison with Squeeze-and-Excitation&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/bam/Untitled_6.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/bam/Untitled_6.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;ps&quot;&gt;P.S&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Original Code가 있지만….논문과 다른 부분이 매우 많음.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 29 Apr 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/04/29/BAM/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/04/29/BAM/</guid>
        
        <category>Paper</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>Review: MobileNet V3</title>
        <description>&lt;h1 id=&quot;searching-for-mobilenetv3&quot;&gt;Searching for MobileNetV3&lt;/h1&gt;

&lt;p&gt;Author: Andrew G. Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingxing Tan,
Weijun Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, Quoc V. Le, Hartwig Adam&lt;br /&gt;
Date: May 06, 2019&lt;br /&gt;
URL: https://arxiv.org/abs/1905.02244&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Efficient neural network 는 low latency, higher accuracy 와 더불어 전력소모가 줄어들게 하기 때문에 배터리 수명 보존에도 기여.&lt;/li&gt;
  &lt;li&gt;이에 힘입어 다음 세대의 더 효율적인 네트워크 제안.&lt;/li&gt;
  &lt;li&gt;본 논문에서 중요한 것은 네 가지.
    &lt;ul&gt;
      &lt;li&gt;Complementary search techniques&lt;/li&gt;
      &lt;li&gt;New efficient versions of non-linearities practical&lt;/li&gt;
      &lt;li&gt;New efficient network design&lt;/li&gt;
      &lt;li&gt;New efficient segmentation decoder&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;efficient-mobile-building-blocks&quot;&gt;&lt;strong&gt;Efficient Mobile Building Blocks&lt;/strong&gt;&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;MobileNetV2의 Inverted residual structure에 &lt;a href=&quot;https://arxiv.org/abs/1709.01507&quot;&gt;squeeze and excitation&lt;/a&gt; 을 추가.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/mobilev3/Untitled.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/mobilev3/Untitled.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;network-search&quot;&gt;&lt;strong&gt;Network Search&lt;/strong&gt;&lt;/h1&gt;

&lt;h2 id=&quot;platform-aware-nas-for-block-wise-search&quot;&gt;&lt;strong&gt;Platform-Aware NAS for Block-wise Search&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;RNN-based controller, factorized hierarchical search space&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;netadapt-for-layer-wise-search&quot;&gt;&lt;strong&gt;NetAdapt for Layer-wise Search&lt;/strong&gt;&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;platform-aware NAS로 찾은 Seed network architecture 로 시작.&lt;/li&gt;
  &lt;li&gt;매 스텝마다:
(a) 이전의 proposal 에 비해 latency가 최소 a만큼 감소된 새로운 proposal 생성. 
(b) 각 proposal은 이전 스텝의 pre-trained model을 사용하여 새로 제안된 architecture를 채우고 누락된 weight에 대해선 적절한 값으로 채움. 각 proposal 은 T step 동안 finetuning하고 대략적인 accuracy 추출.
(c) 몇몇 metric을 이용하여 최적의 proposal 을 선택.&lt;/li&gt;
  &lt;li&gt;목표로하는 latency에 도달할 때까지 반복.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;network-improvements&quot;&gt;&lt;strong&gt;Network Improvements&lt;/strong&gt;&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Network의 초반, 후반부의 expansive layer 구조 수정.&lt;/li&gt;
  &lt;li&gt;새로운 non-linearity fuction 제안.
    &lt;ul&gt;
      &lt;li&gt;h-swish: swish 의 변형 버전, 빠른 계산 속도, 경량화&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;redesigning-expensive-layers&quot;&gt;&lt;strong&gt;Redesigning Expensive Layers&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/mobilev3/Untitled_1.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/mobilev3/Untitled_01.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;nonlinearities&quot;&gt;&lt;strong&gt;Nonlinearities&lt;/strong&gt;&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;sigmoid → h-swish&lt;/p&gt;

\[hard\text{-}swish(x) = x\frac{ReLU6(x + 3)}{6}\]

    &lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/mobilev3/Untitled_2.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/mobilev3/Untitled_02.png&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;h-swish 를 deeper layer에서만 사용.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/mobilev3/Untitled_3.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/mobilev3/Untitled_03.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/mobilev3/Untitled_4.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/mobilev3/Untitled_04.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;large-squeeze-and-excite&quot;&gt;&lt;strong&gt;Large squeeze-and-excite&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1807.11626&quot;&gt;MnasNet: Platform-Aware Neural Architecture Search for Mobile&lt;/a&gt; 에서 Squeeze-and-Excite(SE) bottleneck 크기만큼 convolutional bottleneck 발생.&lt;/li&gt;
  &lt;li&gt;본 논문에선 expansion layer의 채널의 1/4로 고정.&lt;/li&gt;
  &lt;li&gt;파라미터 미약하게 증가하면서 정확도 증가.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;result&quot;&gt;Result&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/mobilev3/Untitled_5.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/mobilev3/Untitled_05.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/mobilev3/Untitled_6.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/mobilev3/Untitled_06.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;ps&quot;&gt;P.S&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Batch size를 4096으로 테스트…. 역시 하드웨어 깡패 구글…&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Tue, 28 Apr 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/04/28/MobileNetV3/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/04/28/MobileNetV3/</guid>
        
        <category>Paper</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>Review: MobileNet V2</title>
        <description>&lt;h1 id=&quot;mobilenetv2-inverted-residuals-and-linear-bottlenecks&quot;&gt;MobileNetV2: Inverted Residuals and Linear Bottlenecks&lt;/h1&gt;

&lt;p&gt;Author: Mark Sandler, Andrew G. Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen&lt;br /&gt;
Date: Jan 13, 2018&lt;br /&gt;
URL: https://arxiv.org/abs/1801.04381&lt;/p&gt;

&lt;h1 id=&quot;abstract&quot;&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;새로운 mobile architecture!&lt;/li&gt;
  &lt;li&gt;mobile에서 Object detection, Semantic segmentation 에 적용할 수 있음!&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;introduction&quot;&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;MobileNet과 비슷한 얘기&lt;/li&gt;
  &lt;li&gt;새로운 모듈 제안! → Inverted residual block&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;preliminaries-discussion-and-intuition&quot;&gt;&lt;strong&gt;Preliminaries, discussion and intuition&lt;/strong&gt;&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;논문의 가장 큰 특징은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Depthwise  Separable Convolution&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Linear Bottlenecks&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Inverted Residuals&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;depthwiseseparableconvolutions&quot;&gt;&lt;strong&gt;Depthwise Separable Convolutions&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1610.02357&quot;&gt;Xception&lt;/a&gt; 에서부터 제안된 Convolution&lt;/li&gt;
  &lt;li&gt;Efficient network의 핵심 Block&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;linear-bottlenecks&quot;&gt;&lt;strong&gt;Linear Bottlenecks&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;MobileNetV1에서 computation 과 accuracy의 trade-off 를 비교하기 위해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;width multiplier parameter&lt;/code&gt;를 사용.&lt;/li&gt;
  &lt;li&gt;본 논문에선 1x1 Convolution 을 이용하여 dimension reduction 수행.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;inverted-residuals&quot;&gt;&lt;strong&gt;Inverted Residuals&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;기존의 Residual Block 과 비슷한 구조 (Bottleneck → Expansion &amp;amp; Skip connection).&lt;/li&gt;
  &lt;li&gt;본 논문에선 Expansion → Bottleneck &amp;amp; Skip connection 구조의 Inverted Residual Block 사용.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/mobilev2/Untitled.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/mobilev2/Untitled.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/mobilev2/Untitled_1.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/mobilev2/Untitle_01.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;model-architecture&quot;&gt;&lt;strong&gt;Model Architecture&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/mobilev2/Untitled_2.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/mobilev2/Untitle_02.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;ablation-study&quot;&gt;&lt;strong&gt;Ablation study&lt;/strong&gt;&lt;/h1&gt;

&lt;h2 id=&quot;inverted-residual-connections&quot;&gt;Inverted residual connections&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Skip connection 을 bottleneck 후에 하는 것이 성능이 더 좋음.&lt;/li&gt;
  &lt;li&gt;Figure 6 (b) 참고&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;importance-of-linear-bottleneck&quot;&gt;Importance of linear bottleneck&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Bottleneck 에서는 activation 을 사용하지 않는 것이 더 좋음.&lt;/li&gt;
  &lt;li&gt;Figure 6 (a) 참고&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/mobilev2/Untitled_3.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/mobilev2/Untitle_03.png&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 27 Apr 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/04/27/MobileNetV2/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/04/27/MobileNetV2/</guid>
        
        <category>Paper</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>개인적인 맥북 세팅법</title>
        <description>&lt;h1 id=&quot;after-macos-install&quot;&gt;After MacOS Install&lt;/h1&gt;

&lt;h2 id=&quot;1-install-applications&quot;&gt;1. Install applications&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Kakao Talk&lt;/li&gt;
  &lt;li&gt;Between&lt;/li&gt;
  &lt;li&gt;Snap
    &lt;ul&gt;
      &lt;li&gt;Add Terminal shortcut&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Speedtest&lt;/li&gt;
  &lt;li&gt;Magnet&lt;/li&gt;
  &lt;li&gt;MenuBar Stats
    &lt;ul&gt;
      &lt;li&gt;Add MenuBar Stats Plugins Manager&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.seense.com/menubarstats/plugins3/&quot;&gt;https://www.seense.com/menubarstats/plugins3/&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Buddy for Youtube&lt;/li&gt;
  &lt;li&gt;Bandizip
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://kr.bandisoft.com/bandizip/x/&quot;&gt;https://kr.bandisoft.com/bandizip/x/&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Notion
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.notion.so/desktop&quot;&gt;https://www.notion.so/desktop&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2-install-brew&quot;&gt;2. Install brew&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/usr/bin/ruby &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;curl &lt;span class=&quot;nt&quot;&gt;-fsSL&lt;/span&gt; https://raw.githubusercontent.com/Homebrew/install/master/install&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;3-install-oh-my-zsh&quot;&gt;3. Install oh-my-zsh&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sh &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;curl &lt;span class=&quot;nt&quot;&gt;-fsSL&lt;/span&gt; https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;4-install-pyenv&quot;&gt;4. Install pyenv&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://jjerry-k.github.io/python/2018/09/27/python4mac/&quot;&gt;Python Installation for mac&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;5-edit-zshrc&quot;&gt;5. Edit .zshrc&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# If you come from bash you might have to change your $PATH.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# export PATH=$HOME/bin:/usr/local/bin:$PATH&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Path to your oh-my-zsh installation.&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ZSH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;/Users/jerry/.oh-my-zsh&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Set name of the theme to load --- if set to &quot;random&quot;, it will&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# load a random theme each time oh-my-zsh is loaded, in which case,&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# to know which specific one was loaded, run: echo $RANDOM_THEME&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# See https://github.com/robbyrussell/oh-my-zsh/wiki/Themes&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;ZSH_THEME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;jreese&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Set list of themes to pick from when loading at random&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Setting this variable when ZSH_THEME=random will cause zsh to load&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# a theme from this variable instead of looking in ~/.oh-my-zsh/themes/&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# If set to an empty array, this variable will have no effect.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# ZSH_THEME_RANDOM_CANDIDATES=( &quot;robbyrussell&quot; &quot;agnoster&quot; )&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Uncomment the following line to use case-sensitive completion.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# CASE_SENSITIVE=&quot;true&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Uncomment the following line to use hyphen-insensitive completion.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Case-sensitive completion must be off. _ and - will be interchangeable.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# HYPHEN_INSENSITIVE=&quot;true&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Uncomment the following line to disable bi-weekly auto-update checks.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# DISABLE_AUTO_UPDATE=&quot;true&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Uncomment the following line to automatically update without prompting.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# DISABLE_UPDATE_PROMPT=&quot;true&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Uncomment the following line to change how often to auto-update (in days).&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# export UPDATE_ZSH_DAYS=13&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Uncomment the following line if pasting URLs and other text is messed up.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# DISABLE_MAGIC_FUNCTIONS=true&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Uncomment the following line to disable colors in ls.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# DISABLE_LS_COLORS=&quot;true&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Uncomment the following line to disable auto-setting terminal title.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# DISABLE_AUTO_TITLE=&quot;true&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Uncomment the following line to enable command auto-correction.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# ENABLE_CORRECTION=&quot;true&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Uncomment the following line to display red dots whilst waiting for completion.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# COMPLETION_WAITING_DOTS=&quot;true&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Uncomment the following line if you want to disable marking untracked files&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# under VCS as dirty. This makes repository status check for large repositories&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# much, much faster.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# DISABLE_UNTRACKED_FILES_DIRTY=&quot;true&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Uncomment the following line if you want to change the command execution time&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# stamp shown in the history command output.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# You can set one of the optional three formats:&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# &quot;mm/dd/yyyy&quot;|&quot;dd.mm.yyyy&quot;|&quot;yyyy-mm-dd&quot;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# or set a custom format using the strftime function format specifications,&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# see 'man strftime' for details.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# HIST_STAMPS=&quot;mm/dd/yyyy&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Would you like to use another custom folder than $ZSH/custom?&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# ZSH_CUSTOM=/path/to/new-custom-folder&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Which plugins would you like to load?&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Standard plugins can be found in ~/.oh-my-zsh/plugins/*&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Custom plugins may be added to ~/.oh-my-zsh/custom/plugins/&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Example format: plugins=(rails git textmate ruby lighthouse)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Add wisely, as too many plugins slow down shell startup.&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;plugins&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=(&lt;/span&gt;git&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$ZSH&lt;/span&gt;/oh-my-zsh.sh

&lt;span class=&quot;c&quot;&gt;# User configuration&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# export MANPATH=&quot;/usr/local/man:$MANPATH&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# You may need to manually set your language environment&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# export LANG=en_US.UTF-8&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Preferred editor for local and remote sessions&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# if [[ -n $SSH_CONNECTION ]]; then&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#   export EDITOR='vim'&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# else&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#   export EDITOR='mvim'&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# fi&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Compilation flags&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# export ARCHFLAGS=&quot;-arch x86_64&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Set personal aliases, overriding those provided by oh-my-zsh libs,&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# plugins, and themes. Aliases can be placed here, though oh-my-zsh&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# users are encouraged to define aliases within the ZSH_CUSTOM folder.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# For a full list of active aliases, run `alias`.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Example aliases&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# alias zshconfig=&quot;mate ~/.zshrc&quot;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# alias ohmyzsh=&quot;mate ~/.oh-my-zsh&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Set pyenv&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PYENV_ROOT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/.pyenv&quot;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PYENV_ROOT&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;bin:&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;pyenv init -&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# &amp;gt;&amp;gt;&amp;gt; conda initialize &amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# !! Contents within this block are managed by 'conda init' !!&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;__conda_setup&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'/Users/jerry/.pyenv/versions/miniconda3-latest/bin/conda'&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'shell.zsh'&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'hook'&lt;/span&gt; 2&amp;gt; /dev/null&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$?&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-eq&lt;/span&gt; 0 &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
    &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$__conda_setup&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;else
    if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/Users/jerry/.pyenv/versions/miniconda3-latest/etc/profile.d/conda.sh&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/Users/jerry/.pyenv/versions/miniconda3-latest/etc/profile.d/conda.sh&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else
        &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;/Users/jerry/.pyenv/versions/miniconda3-latest/bin:&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;fi
fi
&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;unset &lt;/span&gt;__conda_setup
&lt;span class=&quot;c&quot;&gt;# &amp;lt;&amp;lt;&amp;lt; conda initialize &amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;6-create-conda-environment&quot;&gt;6. Create conda environment&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;

conda &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; ipykernel jupyter jupyterlab pylint
conda update &lt;span class=&quot;nt&quot;&gt;--all&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt;
conda create &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; tf &lt;span class=&quot;nv&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3.7
conda create &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; tc &lt;span class=&quot;nv&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3.7

&lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; ~/.pyenv/versions/miniconda3-latest/etc/profile.d/conda.sh

&lt;span class=&quot;c&quot;&gt;# Create TensorFlow Environment&lt;/span&gt;
conda activate tf
conda &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; numpy scipy pandas matplotlib pylint
conda &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; seaborn pillow scikit-image opencv scikit-learn tqdm ipython ipykernel ipywidgets
conda &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; tensorflow
conda update &lt;span class=&quot;nt&quot;&gt;--all&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt;
python &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; ipykernel &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--user&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; tf &lt;span class=&quot;nt&quot;&gt;--display-name&lt;/span&gt; TensorFlow
conda deactivate

&lt;span class=&quot;c&quot;&gt;# Create PyTorch Environment&lt;/span&gt;
conda activate tc
conda &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; numpy scipy pandas matplotlib pylint
conda &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; seaborn pillow scikit-image opencv scikit-learn tqdm ipython ipykernel ipywidgets
conda &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; pytorch pytorch torchvision
conda update &lt;span class=&quot;nt&quot;&gt;--all&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt;
python &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; ipykernel &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--user&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; tc &lt;span class=&quot;nt&quot;&gt;--display-name&lt;/span&gt; PyTorch
conda deactivate
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;7-install-vscode&quot;&gt;7. Install VSCode&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://code.visualstudio.com/docs/?dv=osx&quot;&gt;https://code.visualstudio.com/docs/?dv=osx&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Install plugin
    &lt;ul&gt;
      &lt;li&gt;python&lt;/li&gt;
      &lt;li&gt;pylance&lt;/li&gt;
      &lt;li&gt;Rainbow Brackets&lt;/li&gt;
      &lt;li&gt;indent-rainbow&lt;/li&gt;
      &lt;li&gt;Remote - SSH&lt;/li&gt;
      &lt;li&gt;kite
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://kite.com/download/&quot;&gt;https://kite.com/download/&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;c/c++&lt;/li&gt;
      &lt;li&gt;markdown-all-in-one&lt;/li&gt;
      &lt;li&gt;leetcode
        &lt;ul&gt;
          &lt;li&gt;brew install node&lt;/li&gt;
          &lt;li&gt;Sign in using github&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 26 Apr 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/living/2020/04/26/macbook-setup/</link>
        <guid isPermaLink="true">http://localhost:4000/living/2020/04/26/macbook-setup/</guid>
        
        <category>Macbook</category>
        
        
        <category>Living</category>
        
      </item>
    
      <item>
        <title>Raspberry pi 4 에 Transmission 세팅하기</title>
        <description>&lt;h1 id=&quot;raspberry-pi-4--transmission-container&quot;&gt;Raspberry pi 4 &amp;amp; Transmission Container&lt;/h1&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;1-docker-install&quot;&gt;1. Docker Install&lt;/h1&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl &lt;span class=&quot;nt&quot;&gt;-fsSL&lt;/span&gt; get.docker.com &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; get-docker.sh

&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;bash get-docker.sh

&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;usermod &lt;span class=&quot;nt&quot;&gt;-aG&lt;/span&gt; docker pi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;그리고 재부팅&lt;/p&gt;

&lt;h1 id=&quot;2-pull-transmission-image&quot;&gt;2. Pull Transmission Image&lt;/h1&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker pull linuxserver/transmission
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;3-create-transmission-container&quot;&gt;3. Create Transmission Container&lt;/h1&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker create &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;transmission &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;PUID&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1000 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;PGID&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1000 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;TZ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Asia/Seoul &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;USER&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;={&lt;/span&gt;username&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;PASS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;={&lt;/span&gt;password&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; 9091:9091 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; 51413:51413 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; 51413:51413/udp &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;path to data&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;:/config &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;path to downloads&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;:/downloads &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;path to watch folder&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;:/watch &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;--restart&lt;/span&gt; unless-stopped &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    linuxserver/transmission
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;4-run-container&quot;&gt;4. Run Container&lt;/h1&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker start transmission
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
        <pubDate>Mon, 20 Apr 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/living/2020/04/20/rpi_transmission/</link>
        <guid isPermaLink="true">http://localhost:4000/living/2020/04/20/rpi_transmission/</guid>
        
        <category>Hardware</category>
        
        
        <category>Living</category>
        
      </item>
    
      <item>
        <title>Google Coral USB 사용기</title>
        <description>&lt;h1 id=&quot;raspberry-pi-4--google-coral-usb-accelerator&quot;&gt;Raspberry pi 4 &amp;amp; Google Coral USB Accelerator&lt;/h1&gt;

&lt;p&gt;평소에 라즈베리파이 4를 NAS로 사용하고 있었습니다.  &lt;a href=&quot;https://jjerry-k.github.io/living/2018/07/10/Raspberry-Mini-PC/&quot;&gt;이런 느낌으로..&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;하지만…항상 마음 속에는 “흠….라즈베리파이로 딥러닝을 돌려보고 싶다…” 라는 생각을 하고 있었죠.&lt;/p&gt;

&lt;p&gt;평소와 같이 &lt;del&gt;평화로운 중고나라&lt;/del&gt; 를 탐색하고 있었습니다. (모니터가 사고 싶어서 ….)&lt;/p&gt;

&lt;p&gt;근데 . . 갑자기 . . ? 왜 인지 모르겠지만 Google Coral USB Accelerator 를 검색하고 싶더군요.&lt;/p&gt;

&lt;p&gt;그래서 바로 검색을 했고 7마넌(나름 저렴)에 올라와있길래 일요일에 주문을 했습니다.&lt;/p&gt;

&lt;p&gt;그리고 오늘 집에 도착을 했죠.&lt;/p&gt;

&lt;p&gt;이제 사용을 해보려고 합니다.&lt;/p&gt;

&lt;p&gt;준비물을 소개하도록 하죠.&lt;/p&gt;

&lt;h1 id=&quot;준비물&quot;&gt;준비물&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;라즈베리 파이&lt;/li&gt;
  &lt;li&gt;Coral Accelerator&lt;/li&gt;
  &lt;li&gt;Webcam&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/coral/01.png&quot; alt=&quot;01.jpg&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;step-1-연결&quot;&gt;Step 1. 연결&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/coral/02.png&quot; alt=&quot;02.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/coral/03.png&quot; alt=&quot;03.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;모두 연결 후 라즈베리파이를 켜면 위 사진과 같이 USB에 흰색 불이 들어옵니다.&lt;/p&gt;

&lt;h1 id=&quot;step-2-라즈베리파이-세팅&quot;&gt;Step 2. 라즈베리파이 세팅&lt;/h1&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#!/bin/bash

echo &quot;deb https://packages.cloud.google.com/apt coral-edgetpu-stable main&quot; | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list

curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

sudo apt-get update

sudo apt-get install libedgetpu1-std

# Check Your Platform 
# https://www.tensorflow.org/lite/guide/python
sudo pip3 install https://dl.google.com/coral/python/tflite_runtime-2.1.0.post1-cp37-cp37m-linux_armv7l.whl

#!/bin/bash

git clone https://github.com/google-coral/examples-camera.git

cd examples-camera

sh download_models.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;download_models.sh&lt;/code&gt;를 실행하시면 다음과 같이  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;all_models&lt;/code&gt;라는 디렉토리 안에 각 데이터셋 별 labelmap.txt와 학습된 모델의 tflite 파일이 있습니다.&lt;/p&gt;

&lt;p&gt;여기서 밑줄 친 파일을 이용해서 object detection 을 해볼겁니다! 일단 그 다음 세팅으로 넘어가죠.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/coral/04.png&quot; alt=&quot;04.png&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#!/bin/bash

cd opencv

sh install_requirements.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;opencv를 이용한 스크립트를 사용하기 위해 필요한 것들을 설치합니다.&lt;/p&gt;

&lt;h1 id=&quot;step-3-스크립트-실행&quot;&gt;Step 3. 스크립트 실행&lt;/h1&gt;

&lt;p&gt;이제 opencv 디렉토리 안에 detect.py를 실행 시켜줄건데요. 옵션이 몇개 있습니다. 한번 살펴보도록 하죠.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;usage: detect.py [-h] [--model MODEL] [--labels LABELS] [--top_k TOP_K]
                 [--camera_idx CAMERA_IDX] [--threshold THRESHOLD]

optional arguments:
  -h, --help            show this help message and exit
  --model MODEL         .tflite model path
  --labels LABELS       label file path
  --top_k TOP_K         number of categories with highest score to display
  --camera_idx CAMERA_IDX
                        Index of which video source to use.
  --threshold THRESHOLD
                        classifier score threshold
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;한번 다음과 같이 실행을 해보겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python detect.py \
--model ../all_models/mobilenet_ssd_v2_face_quant_postprocess_edgetpu.tflite \
--labels ../all_models/coco_labels.txt \
--top_k 3 \
--threshold 0.7
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/coral/05.png&quot; alt=&quot;05.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;막 빠를 줄 알았는데 Webcam 의 한계라 그런지… FPS가 낮네요..&lt;/p&gt;

&lt;p&gt;추후에 카메라 모듈을 이용해서 해봐야겠습니다.&lt;/p&gt;

&lt;p&gt;그럼 간단한 이용기를 마치겠습니다.&lt;/p&gt;
</description>
        <pubDate>Tue, 31 Mar 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/03/31/coral/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/03/31/coral/</guid>
        
        <category>Tools</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>Review: StarGAN v2</title>
        <description>&lt;h1 id=&quot;stargan-v2-diverse-image-synthessis-for-multiple-domains&quot;&gt;StarGAN v2: Diverse Image Synthessis for Multiple Domains&lt;/h1&gt;

&lt;p&gt;Author: Yunjey Choi, Youngjung Uh, Jaejun Yoo, Jung-Woo Ha&lt;br /&gt;
Date: Dec 04, 2019&lt;br /&gt;
URL: https://arxiv.org/abs/1912.01865&lt;/p&gt;

&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Image translation 을 잘 하는 Model을 학습하려면 다음 사항을 만족해야함
    &lt;ul&gt;
      &lt;li&gt;Diversity of generated images&lt;/li&gt;
      &lt;li&gt;Scalability over multiple domains&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;기존의 방법들은 limited diversity, multiple models(networks)를 다룸.&lt;/li&gt;
  &lt;li&gt;StarGAN v2는 두 조건 모두 만족.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Domain: 시각적으로 구별되는 범주&lt;/li&gt;
  &lt;li&gt;Style: 각 영상이 가지는 독특한 외관적 특성&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;stargan-v2&quot;&gt;StarGAN v2&lt;/h1&gt;

&lt;h2 id=&quot;proposed-framework&quot;&gt;Proposed framework&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_1.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_1.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;4개의 Network 로 구성.&lt;/li&gt;
  &lt;li&gt;Generator (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;G&lt;/code&gt;)
    &lt;ul&gt;
      &lt;li&gt;Image &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt;와 Style code &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s&lt;/code&gt;를 입력으로 받아 새로운 영상을 생성.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.06868&quot;&gt;adaptive instance normalization (AdaIN)&lt;/a&gt; 사용.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_2.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_2.png&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Mapping network (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;F&lt;/code&gt;)
    &lt;ul&gt;
      &lt;li&gt;Latent code &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;z&lt;/code&gt;와 Domain code &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;y&lt;/code&gt;를 입력으로 받아 Style code &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s&lt;/code&gt;생성.&lt;/li&gt;
      &lt;li&gt;Multi Layer Perceptron 구조.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_3.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_3.png&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Style encoder (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;E&lt;/code&gt;)
    &lt;ul&gt;
      &lt;li&gt;Image &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt;와 Domain code &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;y&lt;/code&gt;를 입력으로 받아 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt;에서 Style code &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s&lt;/code&gt;를 추출.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Discriminator (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;D&lt;/code&gt;)
    &lt;ul&gt;
      &lt;li&gt;Image &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt;를 입력으로 받아 Domain code &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;y&lt;/code&gt;와 Real/Fake 분류.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_4.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_4.png&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;training-objectives&quot;&gt;Training objectives&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Adversarial objective
    &lt;ul&gt;
      &lt;li&gt;GAN 에서 기본적으로 사용되는 Loss&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\mathcal{L}_{adv}=\mathbb{E}_{\mathrm{x},y}[\log{D_y}(\mathrm{x})] + \mathbb{E}_{\mathrm{x}, \tilde{y}, \mathrm{z}}[\log{(1-D_{\tilde{y}}(G(\mathrm{x}, \tilde{\mathrm{s}})))}\]

&lt;ul&gt;
  &lt;li&gt;Style reconstruction
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;G(x, s)&lt;/code&gt; 를 Style encoder &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;E&lt;/code&gt; 에 넣어 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s&lt;/code&gt; 추출 후 입력 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s&lt;/code&gt;와 비교&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\mathcal{L}_{sty}=\mathbb{E}_{\mathrm{x},\tilde{y}, \mathrm{z}}[\parallel\tilde{\mathrm{s}}-E_{\tilde{y}}(G(\mathrm{x}, \tilde{\mathrm{s}}))\parallel_1]\]

&lt;ul&gt;
  &lt;li&gt;Style diversification
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;G&lt;/code&gt;가 다양한 Image를 생성할 수 있도록 Regularization 하는 역할.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;z1, z2&lt;/code&gt; 가 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;F&lt;/code&gt;에 의해 생성된 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s1, s2&lt;/code&gt;와 입력 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt;를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;G&lt;/code&gt;의 입력으로 새로운 영상 생성.&lt;/li&gt;
      &lt;li&gt;L1 Norm 계산.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\mathcal{L}_{ds}=\mathbb{E}_{\mathrm{x},\tilde{y}, \mathrm{z}_1, \mathrm{z}_2}[\parallel G(\mathrm{x}, \tilde{\mathrm{s}}_1) - G(\mathrm{x}, \tilde{\mathrm{s}}_2) \parallel_1]\]

&lt;ul&gt;
  &lt;li&gt;Preserving source characteristics
    &lt;ul&gt;
      &lt;li&gt;Cycle GAN 의 cycle consistency loss.&lt;/li&gt;
      &lt;li&gt;target domain의 style 을 적용한 영상을 다시 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;E(x)&lt;/code&gt;로 추출된 s를 이용하여 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x'&lt;/code&gt;로 reconstruction 한 후 L1 Norm 계산.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\mathcal{L}_{cyc}=\mathbb{E}_{\mathrm{x}, y, \tilde{y}, \mathrm{z}}[\parallel \mathrm{x} - G(G(\mathrm{x}, \tilde{\mathrm{s}}), \hat{\mathrm{s}})\parallel_1]\]

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Full objective&lt;/p&gt;

\[\mathcal{L}_D = -\mathcal{L}_{adv} \\ \mathcal{L}_{F, G, E}=\mathcal{L}_{adv} + \lambda_{sty} \mathcal{L}_{sty} - \lambda_{ds} \mathcal{L}_{ds} + \lambda_{cyc} \mathcal{L}_{cyc}\]

    &lt;ul&gt;
      &lt;li&gt;About $\lambda$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Dataset&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;sty&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;ds&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;cyc&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;CelebA-HQ&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;AFHQ&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;experiments&quot;&gt;Experiments&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Baselines
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1804.04732&quot;&gt;MUNIT&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1808.00948&quot;&gt;DRIT&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1903.05628&quot;&gt;MSGAN&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1711.09020&quot;&gt;StarGAN&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Datasets
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html&quot;&gt;CelebA-HQ&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/clovaai/stargan-v2/blob/master/download.sh&quot;&gt;AFHQ&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Evaluation metrics
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.08500&quot;&gt;Frechet inception distance (FID)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1801.03924&quot;&gt;Learned perceptual image patch similarity (LPIPS)&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;analysis-of-individual-components&quot;&gt;Analysis of individual components&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;StarGAN에서 본 연구에서 제안하는 방법들을 하나하나 넣어가면서 성능 실험.&lt;/li&gt;
  &lt;li&gt;정량적 평가를 보면 추가할 때마다 좋아지는 것을 볼 수 있음.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_5.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_5.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;각 단계별 생성한 영상의 결과&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_6.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_6.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;comparison-on-diverse-image-synthesis&quot;&gt;Comparison on diverse image synthesis&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;다른 방법들과 비교&lt;/li&gt;
  &lt;li&gt;Latent-guided synthesis ( Latent code 만을 이용하여 생성 )&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_7.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_7.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_8.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_8.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Referenc-guided synthesis ( Style code 를 이용한 생성 )&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_9.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_9.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_10.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_10.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Human evaluation
    &lt;ul&gt;
      &lt;li&gt;방법 별로 100개의 sample 생성 후 사람이 판단.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_11.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_11.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;result&quot;&gt;Result&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;겁나….잘 생성함…&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_12.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_12.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_13.png&quot; alt=&quot;https://jjerry-k.github.io/public/img/starganv2/Untitled_13.png&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 04 Mar 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/deeplearning/2020/03/04/starganv2/</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2020/03/04/starganv2/</guid>
        
        <category>Paper</category>
        
        
        <category>DeepLearning</category>
        
      </item>
    
  </channel>
</rss>
