<!DOCTYPE html>
<html lang="en-us">
  <head>
  <head>
    <link href="http://gmpg.org/xfn/11" rel="profile">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
  
    <!-- Enable responsiveness on mobile devices-->
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  
    <title>
      
        Blog &middot; Jerry's Blog
      
    </title>
  
    <!-- CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">
    <link rel="stylesheet" href="/public/css/main.css">
  
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png">
    <link rel="shortcut icon" href="/public/favicon.ico">
  
    <!-- RSS -->
    <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
  
    <!-- scroll -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    <script>
      $( window ).scroll( function() {
        if ( $( this ).scrollTop() > 500 ) {
          $( '.top' ).fadeIn();
        } else {
          $( '.top' ).fadeOut();
        }
      } );
      $( '.top' ).click( function() {
        $( 'html, body' ).stop().animate( { scrollTop : 0 }, 100);
        return false;
      } );
    </script>
    
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (absbygoogle = window.adsbygoogle || []).push({
          google_ad_client: "ca-pub-1054696837285307",
          enable_page_level_ads: true
      });
    </script>
    
    <!-- 
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        //jax: ["input/TeX", "output/HTML-CSS"],
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
          inlineMath: [ ['$', '$'] ],
          displayMath: [ ['$$', '$$'] ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
        //,
        //displayAlign: "left",
        //displayIndent: "2em"
      });
      MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
        alert("Math Processing Error: "+message[1]);
      });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
        alert("Math Processing Error: "+message[1]);
      });
    </script>
    <script type="text/javascript" async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript">
    </script>
     -->
    
    
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      //jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$'] ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
      //,
      //displayAlign: "left",
      //displayIndent: "2em"
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
  

    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script src="/dest/simple-jekyll-search.js" type="text/javascript"></script>
    <script type="text/javascript">
    $(document).ready(function(){
      document.search.searchinput.focus();
    });
    </script>
  </head>
  
  <style>blockquote {font-size: 1em; line-height: 1.4}</style>
  
  <!-- New line Start-->
  <!--  -->
  <!-- New line End -->
  </head>
  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <div class="sidebar-personal-info">
      <div class="sidebar-personal-info-section">
        <a href="https://gravatar.com/22a6447c0c965de55f4ce9691aed2af4">
          <img src="https://www.gravatar.com/avatar/22a6447c0c965de55f4ce9691aed2af4?s=350" title="View on Gravatar" alt="View on Gravatar" />
        </a>
      </div>
      <div class="sidebar-personal-info-section">
        <p></p>
      </div>
      
      
      
      <div class="sidebar-personal-info-section">
        <p> Follow me  :  
        
        
        
        <a href="https://github.com/jjerry-k">
          <i class="fa fa-github" aria-hidden="true"></i>
        </a>
        
        |
        
        
        
        <a href="https://www.facebook.com/jerry.kim.566">
          <i class="fa fa-facebook" aria-hidden="true"></i>
        </a>
        
        |
        
        
        
        <a href="mailto:jaeyeol2931@gmail.com">
          <i class="fa fa-envelope" aria-hidden="true"></i>
        </a>
        
        
        
        </p>
      </div>
      
    </div>
  </div>

  <nav class="sidebar-nav">
    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/">
          Home
        </a>

        
      </span>

    
      
      
      

      

      <span class="foldable">
        <a class="sidebar-nav-item " href="/blog/">
          Contents
        </a>

        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/blog/">
                Blog
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/python/">
                Python
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/ubuntu/">
                Ubuntu
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/living/">
                Living
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/deeplearning/">
                Deep Learning
              </a>
          
        
      </span>

    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/about/">
          About
        </a>

        
      </span>

    

  </nav>

  <div class="sidebar-item">
    <p>
    &copy; 2020 Jerry. This work is liscensed under <a href="http://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a>.
    </p>
  </div>

  <div class="sidebar-item">
    <p>
    Powered by <a href="http://jekyllrb.com">jekyll</a>
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
          <div class="top" style="position:fixed; right:10%; bottom:15px; display:none; z-index:9999;">
            <a href="#">
              <img src="https://jjerry-k.github.io/public/top.png" width="40" height="40" class="top" style="border-radius:5px; background-color: #000; margin-bottom:0; margin-right:7px; float:left;">
            </a>
            
            <a href="/blog//">
              <img src="https://jjerry-k.github.io/public/contents.png" width="40" height="40" class="top" style="border-radius:5px; background-color: #000; margin-bottom:0; float:left;">
            </a>
          </div>
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title" align="center">
            <a href="/" title="Home" title="Jerry's Blog">
              <img class="masthead-logo" src="/public/logo.png"/>
            </a>
            <small></small>
            <a href="https://donaricano.com/mypage/1391188679_guPzXC" target="_blank">
              <img src="https://d1u4yishnma8v5.cloudfront.net/mobile-gift.png" width="60" height="60" style="position:absolute; top:0.25rem; right:4rem" alt="donaricano-btn" style="height: 130px !important;width: 130px !important;" />
            </a>
            <img src="http://jjerry-k.github.io/public/search.png" width="20" height="20" style="position:absolute; top:1.3rem; right:1.5rem" data-toggle="modal" data-target="#myModal">
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/05/08/ResNeXt/">
        Review: ResNeXt
      </a>
    </h1>

    <span class="post-date">08 May 2020</span>
     | 
    
    <a href="/blog/tags/#paper" class="post-tag">Paper</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <h1 id="aggregated-residual-transformations-for-deep-neural-networks">Aggregated Residual Transformations for Deep Neural Networks</h1>

<p>Author: Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, Kaiming He<br />
Date: Nov 16, 2016<br />
URL: https://arxiv.org/abs/1611.05431</p>

<h1 id="introduction">Introduction</h1>

<ul>
  <li>Network desine 에 고려해야할 hyper-parameter가 너무 많음. (Width, filter size, Height, ….)</li>
  <li>VGG, ResNet은 비슷한 구조의 레이어를 계속 쌓는 방법을 사용.</li>
  <li>Inception 은 성능은 이전보다 뛰어나지만 이전 방법들과 다르게 복잡한 구조를 쌓는 방법 사용.</li>
  <li>본 논문에서는 VGG/ResNet과 같이 비슷한 레이어를 반복하지만 AlexNet 에서 나온 처음 제안된 Group Convolution 을 적용하여 split-transform-merge stretegy 를 도입.</li>
  <li>일반적인 Reidual Block과 ResNeXt의 Residual Block 비교.</li>
  <li>Cardinality = Number of Groups,</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled.png" /></p>

<h1 id="method">Method</h1>

<h2 id="template">Template</h2>

<ul>
  <li>전체적인 구조는 기존의 VGG/ResNet과 같이 일정 Block 을 반복하여 쌓는 구조.</li>
  <li>반복되는 블럭은 동일한 hyper parameter 사용.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_1.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_1.png" /></p>

<h2 id="revisiting-simple-neurons">Revisiting Simple Neurons</h2>

<ul>
  <li>가장 기본적인 뉴런의 구조</li>
</ul>

<p>[\sum_{i=1}^Dw_ix_i]</p>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_2.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_2.png" /></p>

<ul>
  <li>기본 뉴런 또한 split-transform-merge (Splitting, Transforming, Aggregating)의 구조를 가짐.</li>
  <li>Vector X 가 $x_i$로 Splitting, $x_iw_i$로 Transforming, $\sum_{i=1}^D$ 로 Aggregating</li>
</ul>

<h2 id="aggregated-transformations">Aggregated Transformations</h2>

<ul>
  <li>Networt-in-Network와 다르게 Network-in-Neuron이라는 컨셉으로 차원 확장</li>
</ul>

<p>[\mathcal{F}(x) = \sum_{i=1}^C\mathcal{T}_i(\mathrm{x})]</p>

<ul>
  <li>다른 방식이지만 동일하다는 것을 설명</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_3.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_3.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_4.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_4.png" /></p>

<h2 id="model-capacity">Model Capacity</h2>

<ul>
  <li>Complexity, Number of parameter 를 유지하면서 실험.</li>
  <li>다른 Hyper parameter는 수정하고 싶지 않기 때문에 Residual Block의 Cardinality C와 bottleneck d를 수정</li>
  <li>Cardinality와 bottleneck d의 관계</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_5.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_5.png" /></p>

<h1 id="result">Result</h1>

<h2 id="on-imagenet-1k">On ImageNet-1K</h2>

<ul>
  <li>Cardinality를 1~32 씩 증가시키되 complexity 는 유지하도록 설정하고 실험.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_6.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_6.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_7.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_7.png" /></p>

<ul>
  <li>Increasing Cardinality 와  Increasing depth or width 비교</li>
  <li>Cardinality 의 성능이 더 좋음.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_8.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_8.png" /></p>

<ul>
  <li>Residual connections 여부에 따른 비교</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_9.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_9.png" /></p>

<ul>
  <li>State-of-the-art model 과 비교</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_10.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_10.png" /></p>

<h2 id="on-imagenet-5k">On ImageNet-5K</h2>

<ul>
  <li>5000개 클래스에서도 잘 되더라.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_11.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_11.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_12.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_12.png" /></p>

<h2 id="on-cifar">On CIFAR</h2>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_13.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_13.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_14.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_14.png" /></p>

<h2 id="on-coco-object-detection">On COCO object detection</h2>

<ul>
  <li>Faster RCNN에 적용.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_15.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_15.png" /></p>

<h2 id="ps">P.S</h2>

<ul>
  <li>AlexNet의 선견지명.</li>
  <li>하긴 안좋으면 논문으로 쓸리가 없지.</li>
</ul>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/05/08/ResNeXt/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/05/08/ResNeXt/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/05/07/ShuffleNetV1/">
        Review: ShuffleNetV1
      </a>
    </h1>

    <span class="post-date">07 May 2020</span>
     | 
    
    <a href="/blog/tags/#paper" class="post-tag">Paper</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <h1 id="shufflenet-an-extremely-efficient-convolutional-neural-network-for-mobile-devices">ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices</h1>

<p>Author: Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, Jian Sun<br />
Date: Jul 04, 2017<br />
URL: https://arxiv.org/abs/1707.01083</p>

<h1 id="introduction">Introduction</h1>

<ul>
  <li>Visual recognition 에서 deeper, larger CNN을 설계하는 것이 트렌드.</li>
  <li>하지만 이는 매우 많은 연산량을 필요로함.</li>
  <li>본 논문은 정해놓은 범위의 연산량에서 최고로 효율적인 구조는 찾아내는 것을 목표로 함.</li>
  <li>Xception, ResNeXt 에서 1x1 Convolution 을 사용하는데 두 네트워크에서 대부분의 연산량이 1x1 Convolution 이 차지하고 있어 비효율적.</li>
  <li>이를 보완하기 위해 AlexNet에서 처음 제안한 group convolution 적용.</li>
  <li>Group convolution 의 단점을 보완하기 위해 channel shuffle operation 또한 제안.</li>
</ul>

<h1 id="method">Method</h1>

<h2 id="channel-shuffle-for-group-convolutions">Channel Shuffle for Group Convolutions</h2>

<ul>
  <li>상대적으로 연산량이 많은 1x1 Convolution을 ResNeXt 에서 사용한 Group Convolution 으로 적용.</li>
  <li>하지만 Group으로 계속 진행하다보면 특정 채널에 편향된 결과를 보이는 문제가 생길 것이므로 channel을 shuffle 해줌.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled.png" /></p>

<h2 id="shufflenet-unit">ShuffleNet Unit</h2>

<ul>
  <li>ShuffleNet에서 사용된 Bottle unit은 Xception과 MobileNet에서 사용된 Residual Block에서 1x1 Convolution을 Group Convolution으로 변경하고 Channel Shuffle을 추가한 것.</li>
  <li>Stride unit 에선 element-wise addition이 아닌 concatenation으로 대체.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_1.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_1.png" /></p>

<h2 id="network-architecture">Network Architecture</h2>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_2.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_2.png" /></p>

<h1 id="result">Result</h1>

<h2 id="ablation-study">Ablation Study</h2>

<h3 id="pointwise-group-convolutions">Pointwise Group Convolutions</h3>

<ul>
  <li>Groups 에 따른 성능 비교.</li>
  <li>
    <p>ShuffleNet s$\times$ 에서 s는 필터 개수에 대한 scaling factor.</p>
  </li>
  <li>무조건 많이 나눈다고 좋은 것은 아님.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_3.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_3.png" /></p>

<h3 id="channel-shuffle-vs-no-shuffle">Channel Shuffle vs. No Shuffle</h3>

<ul>
  <li>Channel Shuffle 여부에 따른 성능 비교.</li>
  <li>Shuffle 적용시 성능이 뚜렷하게 증가한 것을 확인.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_4.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_4.png" /></p>

<h2 id="comparison-with-other-sturcture-units">Comparison with Other Sturcture Units</h2>

<ul>
  <li>제한된 연산량 내에서 다른 Network 들과 성능 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_5.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_5.png" /></p>

<ul>
  <li>기존에 비슷한 성능의 Network들과 연산량 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_6.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_6.png" /></p>

<h2 id="comparison-with-mobilenets-and-other-frameworks">Comparison with MobileNets and Other Frameworks</h2>

<ul>
  <li>Mobile devices에 특화된 MobileNet과 성능 비교</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_7.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_7.png" /></p>

<h2 id="generalization-ability">Generalization Ability</h2>

<ul>
  <li>MS COCO Data를 사용하여 Object detection 성능 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_8.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_8.png" /></p>

<h2 id="actual-speedup-evaluation">Actual Speedup Evaluation</h2>

<ul>
  <li>Mobile device에서 Inference 속도 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_9.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_9.png" /></p>

<h2 id="ps">P.S</h2>
<ul>
  <li>GPU가 부족해서 했다던 Group Convolution의 부활..?</li>
</ul>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/05/07/ShuffleNetV1/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/05/07/ShuffleNetV1/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/05/06/CutMix/">
        Review: CutMix
      </a>
    </h1>

    <span class="post-date">06 May 2020</span>
     | 
    
    <a href="/blog/tags/#paper" class="post-tag">Paper</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <h1 id="cutmix-regularization-strategy-to-train-strong-classifiers-with-localizable-features">CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features</h1>

<p>Author: Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun, Junsuk Choe, Youngjoon Yoo<br />
Date: May 13, 2019<br />
URL: https://arxiv.org/abs/1905.04899</p>

<h1 id="introduction">Introduction</h1>

<ul>
  <li>CNN 은 computer vision 문제에 많이 사용되고 있음.</li>
  <li>효율적이고 높은 성능을 위해 data augmentation, regularization 등 기법을 적용.</li>
  <li>특정 부분에 overfitting(?) 되는 것을 방지하기 위해 dropout, regional dropout 과 같은 방법 사용.</li>
  <li>그 외에도 일부분을 0으로 채운다거나 노이즈로 채우는 방법, 정보가 있는 부분의 pixel을 줄이는 방법 등이 성능 향상을 보였으나 CNN은 데이터가 많이 고픈데….데이터를 없앤다..? 라는 부분에서 의문을 가짐.</li>
  <li>영상의 일부를 자르고 다른 영상으로 대체하는 CutMix 를 제안.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled.png" /></p>

<h1 id="cutmix">CutMix</h1>

<h2 id="algorithm">Algorithm</h2>

<ul>
  <li>A, B 두개의 클래스만 존재.</li>
</ul>

<p>[(x, y): \text{Training image, label} \ (A, B): \text{Training class} \ (x_A, y_A), (x_B, y_B): \text{Training sample}]</p>

<ul>
  <li>어느 부분을 섞을 것인지 binary mask (M) 생성</li>
  <li>생성된 mask를 통해 섞을 비율 lambda 추출.</li>
  <li>Label의 경우 비율에 One-hot encoding이 합친 후 영상에서의 각 클래스의 비율로 변경.</li>
</ul>

<p>[\mathrm{M}: \text{Binary mask where to drop out and fill} \ \lambda: \text{Combination ratio} \ \tilde{x} = \mathrm{M} \bigodot x_A + (1 - \mathrm{M}) \bigodot x_B \ \tilde{y} = \lambda{y_A} + (1 - \lambda)y_B]</p>

<ul>
  <li>M에서 bounding box 좌표 (B) 추출.</li>
  <li>x, y 좌표는 Uniform distribution.</li>
  <li>$x_B$에서 B 를 매칭시켜서 crop 후 B에 매칭되는 $x_A$ 의 부분에 paste.</li>
</ul>

<p>[\mathrm{B}: \text{Bounding box coordinates }  (r_x, r_y, r_w, r_h) \ r_x \sim \text{Unif }(0, W), r_w = W\sqrt{1-\lambda}, \ r_y \sim \text{Unif } (0, H), r_h = H\sqrt{1-\lambda}]</p>

<h2 id="discussion">Discussion</h2>

<ul>
  <li>CutMix를 이용했을 때 CNN이 어느 부분을 학습하는지 확인.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_1.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_1.png" /></p>

<ul>
  <li>다른 method와 비교하여 CutMix의 주요 차이점.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_2.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_2.png" /></p>

<ul>
  <li>Validation Error를 비교했을 때 기존의 모델에 비해 CutMix 적용시 Error가 낮음.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_3.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_3.png" /></p>

<h1 id="experiments">Experiments</h1>

<h2 id="image-classification">Image Classification</h2>

<h3 id="imagenet-classification">ImageNet Classification</h3>

<ul>
  <li>Baseline, 다른 augmentation method와 비교</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_4.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_4.png" /></p>

<ul>
  <li>두 Model에 CutMix를 적용하여 성능 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_5.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_5.png" /></p>

<h3 id="cifar-classification">CIFAR Classification</h3>

<ul>
  <li>다른 Regularization 들과 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_6.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_6.png" /></p>

<ul>
  <li>가벼운 Model 에 적용하여 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_7.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_7.png" /></p>

<ul>
  <li>CIFAR-10에 적용한 결과.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_8.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_8.png" /></p>

<h3 id="ablation-studies">Ablation Studies</h3>

<ul>
  <li><strong>CutMix 에서 alpha가 뭐지…….</strong></li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_9.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_9.png" /></p>

<ul>
  <li>CutMix하는 방법을 다양하게 적용했을 때 성능 비교</li>
  <li>Center Gaussian: Uniform distribution → Gaussian distribution</li>
  <li>Fixed-size: 16 x 16 ( $\lambda = 0.75$ )로 고정</li>
  <li>Scheduled: 학습이 진행될 수록 CutMix 확률을 0부터 1까지 증가</li>
  <li>One-hot: 패치 비율에 따라 Portion label이 아닌 One-hot encoding으로 적용</li>
  <li>Complete-label: lambda 를 고려하지 않고 $y = 0.5y_A + 0.5y_B$로 적용</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_10.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_10.png" /></p>

<h2 id="weakly-supervised-object-localization">Weakly Supervised Object Localization</h2>

<ul>
  <li>Localization 부분에 대해 다른 방법들과 비교.</li>
  <li>학습 후 CAM을 이용해서 bounding box를 그린 것으로 보임.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_11.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_11.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_12.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_12.png" /></p>

<h2 id="transfer-learning-of-pretrained-model">Transfer Learning of Pretrained Model</h2>

<ul>
  <li>Object detection, Image captioning 에 적용하여 성능 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_13.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_13.png" /></p>

<h2 id="robustness-and-uncertainty">Robustness and Uncertainty</h2>

<ul>
  <li>Adversarial attack 에 대해 Accuracy 비교.</li>
  <li><a href="https://arxiv.org/abs/1412.6572">Fast Gradient Sign Method (FGSM)</a>을 이용하여 adversarial perturbation 생성.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_14.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_14.png" /></p>

<ul>
  <li>Occlusion 상황에 대해서 성능 비교.</li>
  <li>가운데 부분 혹은 Boundary 에 0~224 크기 사이의 hole을 생성.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_15.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_15.png" /></p>

<ul>
  <li>Uncertainty</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_16.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_16.png" /></p>

<h2 id="cutmix-algorithm">CutMix Algorithm</h2>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_17.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_17.png" /></p>

<h2 id="ps">P.S</h2>

<ul>
  <li>Appendix에 내용이 더 있지만… 간단히 정리하려니 넣기 좀 힘듦.</li>
  <li>당연한 얘기지만 모든 데이터에 적용하기엔 어려움이 있을 것으로 보임.</li>
</ul>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/05/06/CutMix/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/05/06/CutMix/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/living/2020/05/05/dockerfile/">
        개인적인 도커 파일
      </a>
    </h1>

    <span class="post-date">05 May 2020</span>
     | 
    
    <a href="/blog/tags/#docker" class="post-tag">Docker</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <h1 id="지극히-개인이-사용하기-위한-dockerfile">지극히 개인이 사용하기 위한 Dockerfile</h1>

<hr />

<ul>
  <li>환경을 만들 때마다 추가될 예정입니다.</li>
  <li>마음껏 편하신대로 Copy &amp; Paste 하세요!</li>
</ul>

<h2 id="tensorflow">TensorFlow</h2>
<pre><code class="language-Dockerfile">FROM nvidia/cuda:10.1-cudnn7-runtime-ubuntu18.04
LABEL maintainer "Jerry Kim &lt;jaeyeol2931@gmail.com&gt;"
ARG PYTHON_VERSION=3.7
RUN apt-get update
RUN apt-get install -y \
        build-essential \
        cmake \
        git \
        curl \
        wget \
        ca-certificates \
        libjpeg-dev \
        libpng-dev

RUN apt-get update &amp;&amp; apt-get -y upgrade

RUN rm -rf /var/lib/apt/lists/*

RUN curl https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -o ~/miniconda.sh

RUN chmod +x ~/miniconda.sh &amp;&amp; \
    ~/miniconda.sh -b -p /opt/conda &amp;&amp; \
    rm ~/miniconda.sh

RUN /opt/conda/bin/conda install -y python=$PYTHON_VERSION numpy pyyaml scipy ipython mkl mkl-include ninja cython typing opencv matplotlib tqdm &amp;&amp; \
    /opt/conda/bin/conda install -y jupyter jupyterlab seaborn pillow pandas pylint scikit-learn scikit-image tensorflow-gpu &amp;&amp; \
    /opt/conda/bin/conda update -y --all &amp;&amp; \
    /opt/conda/bin/conda clean -ya

ENV PATH /opt/conda/bin:$PATH

</code></pre>

    <article></h4>
    <div class="post-more">
      
      <a href="/living/2020/05/05/dockerfile/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/living/2020/05/05/dockerfile/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/05/02/EfficientNet/">
        Review: EfficientNet
      </a>
    </h1>

    <span class="post-date">02 May 2020</span>
     | 
    
    <a href="/blog/tags/#paper" class="post-tag">Paper</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <h1 id="efficientnet-rethinking-model-scaling-for-convolutional-neural-networks">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</h1>

<p>Author: Mingxing Tan, Quoc V. Le<br />
Date: May 28, 2019<br />
URL: https://arxiv.org/abs/1905.11946</p>

<h1 id="introduction">Introduction</h1>

<ul>
  <li>ConvNet 의 성능을 높이는데 Depth, Width, Image size 중 하나를 증가 시키는게 일반적인 방법.</li>
  <li>본 논문에서는 ConvNet의 성능과 효율성을 증가시키기 위한 원론적인 방법에 대한 연구.</li>
  <li>실험의 결과로 <strong><em>Compound scaling method</em></strong> 를 제안.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled.png" /></p>

<h1 id="compound-model-scaling">Compound Model Scaling</h1>

<ul>
  <li>Scaling 문제에 대한 정의, Approache 별 연구, 새로운 방법에 대한  내용 서술.</li>
</ul>

<h2 id="problem-formulation">Problem Formulation</h2>

<ul>
  <li>Model scaling은 Baseline 에서 Length(Depth), Width, Resolution 를 확장.</li>
  <li>하지만 실제론 리소스에 제약이 있으니 이에 맞춰 문제를 새롭게, 단순하게 정의.</li>
  <li>Design space를 줄이기 위해 모든 레이어는 상수 값을 이용하여 규칙적으로 변화하도록 함.</li>
  <li>최종 목적은 제한된 리소스에서 성능을 최대화하는 것.</li>
</ul>

<p>[\mathcal{N}: \text{ConvNet} \ \mathcal{F}_i: \text{Layer architecture} \ L_i: \text{Network length} \ C_i: \text{Width} \ H_i, W_i: \text{Input resolution}]</p>

<p>[{max}<em>{d, w, r} Accuracy(\mathcal{N}(d, w, r)) \ s.t. \mathcal{N}(d, w, r) = \bigodot</em>{i=1…s}\hat{\mathcal{F}}<em>i^{d \cdot \hat{L}_i}(X</em>{\langle r\cdot \hat{H}_i, r \cdot \hat{W}_i, w\cdot \hat{C}_i \rangle} ) \ Memory(\mathcal{N}) \leq \text{target memory} \FLOPS(\mathcal{N}) \leq \text{target flops}]</p>

<h2 id="scaling-dimensions">Scaling Dimensions</h2>

<ul>
  <li>두번째 문제는 d, w, r 이 서로 dependent 하고 제한된 리소스에 따라 값이 변화.</li>
  <li>그래서 기존에는 다음 세 개의 요소 중 하나를 변경함.</li>
</ul>

<h3 id="depth-d">Depth (d)</h3>

<ul>
  <li>VGGNet, GoogLeNet, ResNet 등등 레이어를 많이 많이 !</li>
</ul>

<h3 id="width-w">Width (w)</h3>

<ul>
  <li>채널 수를 늘리고 깊이를 줄이는 방식.</li>
  <li>하지만 <strong>higher level feature를 잡기 힘들 수 있음.</strong></li>
</ul>

<h3 id="resolution-r">Resolution (r)</h3>

<ul>
  <li>클수록 더 양질의 패턴을 찾을 수 있음.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_1.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_1.png" /></p>

<ul>
  <li>Observation 1: 이를 통해서 어떤 요소를 증가시키던 성능이 오르는 것을 확인 하지만 Model이 무거워짐.</li>
</ul>

<h2 id="compound-scaling">Compound Scaling</h2>

<ul>
  <li>경험적으로 세 요소가 dependent 하다는 것을 이미 알고 있음.</li>
  <li>다른 depth, resolution 을 이용하여 성능 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_2.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_2.png" /></p>

<ul>
  <li>Observation 2: 세 요소의 balance가 매우 중요..</li>
  <li>다음과 같은 compound scaling method 제안.</li>
</ul>

<p>[\phi: \text{Compound Coefficient} \ depth: d = \alpha^\phi \ width: w = \beta^\phi \ resolution: r = \gamma^\phi \ \text{s.t. }\alpha \cdot \beta^2 \cdot \gamma^2 \approx 2 \ \alpha \ge 1, \beta \ge 1, \gamma \ge 1]</p>

<ul>
  <li>각 값은 small grid search로 결정된 상수 값.</li>
</ul>

<h1 id="efficientnet-architecture">EfficientNet Architecture</h1>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_3.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_3.png" /></p>

<ul>
  <li>EfficientNet-B0 를 baseline network로 하여  Accuracy, FLOPS 둘 다 최적화하도록 multi-objective neural architecture search 적용.
    <ul>
      <li>Step 1
        <ul>
          <li>$\phi$ =1 로 고정</li>
          <li>식 2, 3을 기반으로 하여 small grid search</li>
          <li>EfficientNet-B0에 가장 적합한 값을 $\alpha$=1.2, $\beta$=1.1, $\gamma$=1.15</li>
        </ul>
      </li>
      <li>Step 2
        <ul>
          <li>$\alpha$, $\beta$, $\gamma$를 고정하고 $\phi$를 변경하여 실험.</li>
          <li>Result (ImageNet Result for EfficientNet) 참고</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h1 id="result">Result</h1>

<h2 id="scaling-up-mobilenets-and-resnets">Scaling Up MobileNets and ResNets</h2>

<ul>
  <li>Compound scale 을 증명하기 위해 MobileNet과 ResNet을 이용하여 비교.</li>
  <li>기존의 방법들은 3개중 1개의 요소만 scaling.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_4.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_4.png" /></p>

<h2 id="imagenet-result-for-efficientnet">ImageNet Result for EfficientNet</h2>

<ul>
  <li>Training Setting
    <ul>
      <li>Optimization
        <ul>
          <li>RMSProp</li>
          <li>Decay: 0.9</li>
          <li>Momentum: 0.9</li>
        </ul>
      </li>
      <li>Batch normalization
        <ul>
          <li>Momentum: 0.99</li>
        </ul>
      </li>
      <li>Weight decay: 1e-5</li>
      <li>Initial learning rate: 0.256
        <ul>
          <li>Decay: 0.97 (every 2.4 epochs)</li>
        </ul>
      </li>
      <li>Swish Activation</li>
      <li><a href="https://arxiv.org/abs/1805.09501">AutoAugmentation</a>: 뭔지 모르겠군 1</li>
      <li><a href="https://arxiv.org/abs/1603.09382">Stochastic depth</a>: 뭔지 모르겠군 2
        <ul>
          <li>Drop connect ratio: 0.2</li>
        </ul>
      </li>
      <li>Dropout
        <ul>
          <li>0.2 ~ 0.5 (B0 ~ B7)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>B0부터 B7 까지 성능 비교.</li>
  <li>GPipe에 비해 <strong>8.4배 적고 좋은 성능.</strong></li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_5.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_5.png" /></p>

<ul>
  <li>CPU를 이용한 Inference 속도 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_6.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_6.png" /></p>

<ul>
  <li>모델별 FLOPS-Accuracy curve</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_7.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_7.png" /></p>

<h2 id="transfer-learning-result-for-efficientnet">Transfer Learning Result for EfficientNet</h2>

<ul>
  <li>ImageNet pretrained model 을 이용하여 각종 Dataset을 Transfer learning 한 성능 비교</li>
  <li>사용한 Dataset</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_8.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_8.png" /></p>

<ul>
  <li>Transfer learning 결과</li>
  <li>전체적으로 모델이 가벼움.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_9.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_9.png" /></p>

<ul>
  <li>기존의 모델들과 비교하여 가볍지만 뛰어난 성능을 보임.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_10.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_10.png" /></p>

<h1 id="discussion">Discussion</h1>

<ul>
  <li>EfficientNet-B0 를 이용하여 각기 다른 scaling method를 이용하여 성능 비교</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_11.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_11.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_12.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_12.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_13.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_13.png" /></p>

<h2 id="ps">P.S</h2>

<ul>
  <li>이런 연구는..NAS(Network Architecture Search)가 답..인건가</li>
  <li>근데 이것도 하드웨어가 빵빵해야….. 크흡</li>
</ul>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/05/02/EfficientNet/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/05/02/EfficientNet/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/blog/page5">Older</a>
  
  
    
      <a class="pagination-item newer" href="/blog/page3">Newer</a>
    
  
</div>


        </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <!-- Modal -->
  <div class="modal fade" id="myModal" role="dialog">
    <div class="modal-dialog">

      <!-- Modal content-->
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal">&times;</button>
          <h4 class="modal-title">Search</h4>
        </div>
        <div class="modal-body">

    <h4><div id="search-container">
      <input type="text" id="search-input" placeholder="검색어 입력" class="input" style="font-size: 1rem; width: 100%; padding: 10px; border: 0px; outline: none; float: left; background: #cecece;" autofocus>
    </div></h4><br>

      <div id="results">
        <h1></h1>
      <ul class="results"></ul>
      </div>
      <br><ul id="results-container"></ul>
    </div>

<!-- Script pointing to jekyll-search.js -->


<script type="text/javascript">
      SimpleJekyllSearch({
        searchInput: document.getElementById('search-input'),
        resultsContainer: document.getElementById('results-container'),
        json: '/dest/search.json',
        searchResultTemplate: '<h4 style="margin-bottom:-0.5rem;"><a class="post-title" style="color:#ac4142;" href="{url}" title="{desc}">{title}</a> <small>{category}</small></h4>',
        noResultsText: '<h4><br>문서가 존재하지 않습니다.</h4>',
        limit: 15,
        fuzzy: false,
        exclude: ['Welcome']
      })
</script>
        </div>
      </div>

    </div>
  </div>

</div>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');
        document.addEventListener('click', function(e) {
          var target = e.target;
          if (target === toggle) {
            checkbox.checked = !checkbox.checked;
            e.preventDefault();
          } else if (checkbox.checked && !sidebar.contains(target)) {
            /* click outside the sidebar when sidebar is open */
            checkbox.checked = false;
          }
        }, false);
      })(document);
    </script>

    
      <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-126636477-1', 'auto');
        ga('send', 'pageview');
      </script>
    

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (absbygoogle = window.adsbygoogle || []).push({
          google_ad_client: "ca-pub-1054696837285307",
          enable_page_level_ads: true
      });
    </script>
  </body>
  
  <script id="dsq-count-scr" src="//jerry.disqus.com/count.js" async></script>
  
</html>
