<!DOCTYPE html>
<html lang="en-us">
  <head>
  <head>
    <link href="http://gmpg.org/xfn/11" rel="profile">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
  
    <!-- Enable responsiveness on mobile devices-->
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  
    <title>
      
        Blog &middot; Jerry's Blog
      
    </title>
  
    <!-- CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">
    <link rel="stylesheet" href="/public/css/main.css">
  
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png">
    <link rel="shortcut icon" href="/public/favicon.ico">
  
    <!-- RSS -->
    <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
  
    <!-- scroll -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    <script>
      $( window ).scroll( function() {
        if ( $( this ).scrollTop() > 500 ) {
          $( '.top' ).fadeIn();
        } else {
          $( '.top' ).fadeOut();
        }
      } );
      $( '.top' ).click( function() {
        $( 'html, body' ).stop().animate( { scrollTop : 0 }, 100);
        return false;
      } );
    </script>
    
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (absbygoogle = window.adsbygoogle || []).push({
          google_ad_client: "ca-pub-1054696837285307",
          enable_page_level_ads: true
      });
    </script>
    
    <!-- 
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        //jax: ["input/TeX", "output/HTML-CSS"],
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
          inlineMath: [ ['$', '$'] ],
          displayMath: [ ['$$', '$$'] ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
        //,
        //displayAlign: "left",
        //displayIndent: "2em"
      });
      MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
        alert("Math Processing Error: "+message[1]);
      });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
        alert("Math Processing Error: "+message[1]);
      });
    </script>
    <script type="text/javascript" async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript">
    </script>
     -->
    
    
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      //jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$'] ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
      //,
      //displayAlign: "left",
      //displayIndent: "2em"
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
  

    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script src="/dest/simple-jekyll-search.js" type="text/javascript"></script>
    <script type="text/javascript">
    $(document).ready(function(){
      document.search.searchinput.focus();
    });
    </script>
  </head>
  
  <style>blockquote {font-size: 1em; line-height: 1.4}</style>
  
  <!-- New line Start-->
  <!--  -->
  <!-- New line End -->
  </head>
  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <div class="sidebar-personal-info">
      <div class="sidebar-personal-info-section">
        <a href="https://gravatar.com/22a6447c0c965de55f4ce9691aed2af4">
          <img src="https://www.gravatar.com/avatar/22a6447c0c965de55f4ce9691aed2af4?s=350" title="View on Gravatar" alt="View on Gravatar" />
        </a>
      </div>
      <div class="sidebar-personal-info-section">
        <p></p>
      </div>
      
      
      
      <div class="sidebar-personal-info-section">
        <p> Follow me  :  
        
        
        
        <a href="https://github.com/jjerry-k">
          <i class="fa fa-github" aria-hidden="true"></i>
        </a>
        
        |
        
        
        
        <a href="https://www.facebook.com/jerry.kim.566">
          <i class="fa fa-facebook" aria-hidden="true"></i>
        </a>
        
        |
        
        
        
        <a href="mailto:jaeyeol2931@gmail.com">
          <i class="fa fa-envelope" aria-hidden="true"></i>
        </a>
        
        
        
        </p>
      </div>
      
    </div>
  </div>

  <nav class="sidebar-nav">
    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/">
          Home
        </a>

        
      </span>

    
      
      
      

      

      <span class="foldable">
        <a class="sidebar-nav-item " href="/blog/">
          Contents
        </a>

        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/blog/">
                Blog
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/python/">
                Python
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/ubuntu/">
                Ubuntu
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/living/">
                Living
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/deeplearning/">
                Deep Learning
              </a>
          
        
      </span>

    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/about/">
          About
        </a>

        
      </span>

    

  </nav>

  <div class="sidebar-item">
    <p>
    &copy; 2020 Jerry. This work is liscensed under <a href="http://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a>.
    </p>
  </div>

  <div class="sidebar-item">
    <p>
    Powered by <a href="http://jekyllrb.com">jekyll</a>
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
          <div class="top" style="position:fixed; right:10%; bottom:15px; display:none; z-index:9999;">
            <a href="#">
              <img src="https://jjerry-k.github.io/public/top.png" width="40" height="40" class="top" style="border-radius:5px; background-color: #000; margin-bottom:0; margin-right:7px; float:left;">
            </a>
            
            <a href="/blog//">
              <img src="https://jjerry-k.github.io/public/contents.png" width="40" height="40" class="top" style="border-radius:5px; background-color: #000; margin-bottom:0; float:left;">
            </a>
          </div>
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title" align="center">
            <a href="/" title="Home" title="Jerry's Blog">
              <img class="masthead-logo" src="/public/logo.png"/>
            </a>
            <small></small>
            <a href="https://donaricano.com/mypage/1391188679_guPzXC" target="_blank">
              <img src="https://d1u4yishnma8v5.cloudfront.net/mobile-gift.png" width="60" height="60" style="position:absolute; top:0.25rem; right:4rem" alt="donaricano-btn" style="height: 130px !important;width: 130px !important;" />
            </a>
            <img src="http://jjerry-k.github.io/public/search.png" width="20" height="20" style="position:absolute; top:1.3rem; right:1.5rem" data-toggle="modal" data-target="#myModal">
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/living/2020/05/31/Dlink_ddns/">
        D-Link ddns 서비스 종료
      </a>
    </h1>

    <span class="post-date">31 May 2020</span>
     | 
    
    <a href="/blog/tags/#hardware" class="post-tag">Hardware</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <p><a href="https://eu.dlink.com/uk/en/products/dir-850l-wireless-ac1200-dual-band-gigabit-cloud-router">D-Link의 DIR-815L</a> 을 잘 쓰고 있었습니다…<br />
라즈베리파이와 연결하여 DDNS 도해놓고..<br />
근데 어느 날 다음과 같은 글이 메일, 공지로 올라오더군요.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>안녕하세요. D-Link Korea 입니다. 저희 dlink 제품군에서 제공되었던 무료 dlinkddns 서비스 종료에 관한 안내 말씀드립니다. 죄송합니다만, dlinkddns 무료 서비스는 기존에 오라클사의 dyn ddns 와의 계약만료일인 2020년 7월 2일 종료될 예정입니다. 이후에는 정상적인 무료 ddns서비스 이용이 불가하니 계속해서 dlinkddns 서비스를 이용하기를 원하실 경우에는 유료상품으로 전환하시기 바랍니다. ■ 유료전환 http://dlinkddns.com 사이트 접속시 유료전환은 안내 팝업과 함께 결재시 50% 할인 메뉴 클릭하여 진행합니다. 이외에 관련해서 궁금한 점이 있으신 분은 D-Link Korea 고객센터(1899-3540)로 문의하시기 바랍니다. 기존 무료로 지원되던 dlinkddns 서비스 종료에, 앞으로 더욱 나은 서비스로 보답하겠습니다. 감사합니다.
</code></pre></div></div>

<p>What the…?<br />
후… 공유기를 새로 사던 DDNS 서비스를 이용하던 해야겠네요.<br />
디자인이랑 DDNS 때문에 샀는데.. 젠장.. 앞으론 그냥 Iptime 쓸래요.</p>

    <article></h4>
    <div class="post-more">
      
      <a href="/living/2020/05/31/Dlink_ddns/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/living/2020/05/31/Dlink_ddns/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/05/09/ShuffleNetV2/">
        Review: ShuffleNetV2
      </a>
    </h1>

    <span class="post-date">09 May 2020</span>
     | 
    
    <a href="/blog/tags/#paper" class="post-tag">Paper</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <h1 id="shufflenet-v2-practical-guidelines-for-efficient-cnn-architecture-design">ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design</h1>

<p>Author: Ningning Ma, Xiangyu Zhang, Hai-Tao Zheng, Jian Sun<br />
Date: Jul 30, 2018<br />
URL: https://arxiv.org/abs/1807.11164</p>

<h1 id="introduction">Introduction</h1>

<ul>
  <li>CNN 계열이 AlexNet 부터 정확도, 속도가 많이 발전하고 있음.</li>
  <li>실제로는 제한된 컴퓨팅 파워에서(Mobile과 같은) 최고의 성능을 내는데 목표로 하고 있음.</li>
  <li>이로 인해 Xception, MobileNet, ShuffleNet 등이 개발 되었음.</li>
  <li>지금까지는 모델의 연산량을 이용하여 모델의 효율성을 판단하였으나 적합한 지표가 아님을 주장.</li>
  <li>FLOPs와 speed 간의 성능 비교가 옳지 않은 주요 이유가 두 가지.
    <ul>
      <li>memory access cost(MAC): 메모리 접근량(사용량)</li>
      <li>depending on the platform</li>
    </ul>
  </li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled.png" /></p>

<h1 id="practical-guidelines-for-ecient-network-design">Practical Guidelines for Ecient Network Design</h1>

<ul>
  <li>본 연구는 GPU 하드웨어(1080ti), ARM 하드웨어(Snapdragon 810) 이 두 가지 환경에서 실험.</li>
  <li>모델의 Runtime을 쪼개보면 다음과 같은 차트가 그려짐.</li>
  <li>FLOPs는 Convolution 에 대해 설명하기 떄문에 비교 지표로 적절하지 못함을 강조.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_1.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_1.png" /></p>

<ul>
  <li>위 문제를 근거로 다음과 같이 여러 개의 가이드 라인을 제시.</li>
</ul>

<h2 id="g1-equal-channel-width-minimizes-memory-access-cost-mac">G1) Equal channel width minimizes memory access cost (MAC)</h2>

<ul>
  <li>근래에 많이 사용되는 depthwise separable convoltuion에서 연산량의 대부분은 pointwise convolution 이 차지.</li>
  <li>1x1 convolution 이 차지하는 연산량은 다음과 같음.</li>
</ul>

<p>[h, w: \text{the spatial size of the input feature map} \ c_1, c_2: \text{Number of channels about input and output } \ B=hwc_1c_2, \text{ FLOPs of the }1 \times 1 \text{ convolution}]</p>

<ul>
  <li>현 상황에서 MAC의 수식은 다음과 같음.</li>
</ul>

<p>[MAC = hw(c_1+c_2) +c_1c_2 = hwc_1 + hwc_2 + c_1c_2 \ hwc_1: \text{Number of input feature map’s element} \ hwc_2: \text{Number of output feature map’s element} \ c_1c_2: \text{Number of filter’s element}]</p>

<ul>
  <li>MAC의 lower bound 는 다음과 같음.</li>
</ul>

<p>[MAC \ge 2\sqrt{hwB} + \frac{B}{hw} \to 2hw\sqrt{c_1c_2} + c_1c_2]</p>

<ul>
  <li>$c_1 = c_2$ 이면 MAC가 최소.</li>
  <li>전체 연산량은 고정해놓고 $c_1:c_2$의 비율을 바꿔가면서 runtime 비교.</li>
  <li>1:1일때가 가장 빠른 성능을 보임.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_2.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_2.png" /></p>

<blockquote>
  <p><em>It reaches the lower bound when the numbers of input and output channels are equal.</em></p>
</blockquote>

<h2 id="g2-excessive-group-convolution-increases-mac">G2) Excessive group convolution increases MAC</h2>

<ul>
  <li>Group convolution 이 많은 네트워크의 핵심이지만 Groups가 커지면 MAC을 증가시킴. → 안쓸 수는 없으니 적당히 쓰는게 좋다.</li>
  <li>그룹에 따라 연산량이 줄어들기 때문에 B는 다음과 같음.</li>
</ul>

<p>[B=hwc_1c_2/g]</p>

<p>[MAC = hw(c_1+c_2) + \frac{c_1c_2}{g} \ = hwc_1 + hwc_2 + \frac{c_1c_2}{g} \ = hwc_1 + \frac{Bg}{c_1} + \frac{B}{hw}]</p>

<ul>
  <li>Groups 에 따라 runtime 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_3.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_3.png" /></p>

<blockquote>
  <p><em>The group number should be carefully chosen based on the target platform and task. It is unwise to use a large group number simply because this may enable using more channels, because the benet of accuracy increase can easily be outweighed by the rapidly increasing computational cost.</em></p>
</blockquote>

<h2 id="g3-network-fragmentation-reduces-degree-of-parallelism">G3) Network fragmentation reduces degree of parallelism</h2>

<ul>
  <li>Inception 과 같이 여러 branch를 parallel하게 구성할 경우 성능은 좋아졌지만 효율성은 감소시킴. → GPU 같은 자원에는 어울리지 않음.</li>
  <li>Fragmentation 에 따른 runtime 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_4.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_4.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_5.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_5.png" /></p>

<blockquote>
  <p><em>Fragmented structure has been shown benecial for accuracy, it could decrease eciency because it is unfriendly for devices with strong parallel computing powers like GPU. It also introduces extra overheads such as kernel launching and synchronization.</em></p>
</blockquote>

<h2 id="g4-element-wise-operations-are-non-negligible">G4) Element-wise operations are non-negligible</h2>

<ul>
  <li>Activation, Add 와 같은 Element-wise operation들의 비율이 꽤 존재. Figure 2 참고</li>
  <li>이 연산은 FLOPs는 적지만 상대적으로 MAC은 큼.</li>
  <li>
    <p>Depthwise convolution 또한 element-wise 여서 MAC/FLOPs 가 클 것이라 생각.</p>
  </li>
  <li>각 상황에 대한 runtime 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_6.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_6.png" /></p>

<blockquote>
  <p><em>We observe around 20% speedup is obtained on both GPU and ARM, after ReLU and shortcut are removed.</em></p>
</blockquote>

<h2 id="conclusion-and-discussions">Conclusion and Discussions</h2>

<ol>
  <li>use “balanced convolutions (equal channel width);</li>
  <li>be aware of the cost of using group convolution;</li>
  <li>reduce the degree of fragmentation;</li>
  <li>reduce element-wise operations.</li>
</ol>

<ul>
  <li>다른 네트워크들에 대한 고찰
    <ul>
      <li>ShuffleNet V1
        <ul>
          <li>Heavily group convolutions → G2</li>
          <li>Bottleneck-like building blocks → G1</li>
          <li>Residual Block → G3</li>
          <li>Element-wise operation→ G4</li>
        </ul>
      </li>
      <li>MobileNet V2
        <ul>
          <li>Inverted bottleneck structure → G1</li>
        </ul>
      </li>
      <li>Depthwise convolution &amp; ReLU
        <ul>
          <li>Element-wise operation → G4</li>
        </ul>
      </li>
      <li>NAS
        <ul>
          <li>Highly fragmentation → G3</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h1 id="shuenet-v2-an-ecient-architecture">ShueNet V2: an Ecient Architecture</h1>

<h2 id="review-of-shuenet-v1">Review of ShueNet v1</h2>

<ul>
  <li>G1, G2, G3, G4 모두 지키지 않음.</li>
  <li>이를 해결한 구조가 ShuffleNet V2 의 유닛 (Fig 3 (c), Fig 3 (d))</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_7.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_7.png" /></p>

<h2 id="channel-split-and-shuenet-v2">Channel Split and ShueNet V2</h2>

<ul>
  <li>Fig 3 (c)
    <ul>
      <li>Input feature 을 절반으로 나눠 두개의 branch 생성.</li>
      <li>Left branch는 아무 연산도 진행 X. → G3 에 대한 회피법.</li>
      <li>Right branch는 동일한 Number of filter로 1x1 Conv → 3x3 DWConv → 1x1 Conv 수행. → G1에 대한 회피법.</li>
      <li>1x1 Conv 는 Group 을 나누지 않음 → G2에 대한 회피법.</li>
      <li>Residual Block의 Add operation 을 Concatenate 로 변경 → G4에 대한 회피법.</li>
    </ul>
  </li>
  <li>Fig 3 (d)
    <ul>
      <li>Downsampling block</li>
      <li>Input feature 그대로 두개의 branch 생성.</li>
      <li>Number of filter는 모두 동일</li>
    </ul>
  </li>
  <li>네트워크 구조</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_8.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_8.png" /></p>

<h2 id="analysis-of-network-accuracy">Analysis of Network Accuracy</h2>

<ul>
  <li>ShuffleNet V2는 효율적이며 성능도 좋음.
    <ul>
      <li>더 많은 channel, 더 큰 network를 만들 수 있음.</li>
      <li>DenseNet 이나 CondenseNet 처럼 feature reuse 과 매우 유사함.</li>
    </ul>
  </li>
  <li>DenseNet의 feature reuse 패턴과 ShuffleNet V2의 feature reuse 패턴 비교.</li>
  <li>붉을 수록 Source layer와 Target layer의 연결성이 강하다는 의미.</li>
  <li>DenseNet과 같이 ShuffleNet V2에서도 Target layer가 멀어질 수록 연결성이 약함.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_9.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_9.png" /></p>

<h1 id="experiment">Experiment</h1>

<ul>
  <li>총 4개의 모델과 비교.
    <ul>
      <li>ShuffleNet V1</li>
      <li>MobileNet V2</li>
      <li>Xception</li>
      <li>DenseNet</li>
    </ul>
  </li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_10.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_10.png" /></p>

<h3 id="accuracy-vs-flops">Accuracy vs. FLOPs</h3>

<ul>
  <li>연산량을 40 MFLOPs 로 고정시키고 Network 를 구성한 후 성능 비교. (Table 8 상단)</li>
</ul>

<h3 id="inference-speed-vs-flopsaccuracy">Inference Speed vs. FLOPs/Accuracy</h3>

<ul>
  <li>연산량을 특정 값 범위로 고정시키고 runtime 비교. (Fig 1 참조)</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_11.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_11.png" /></p>

<h3 id="compared-with-mobilenet-v1">Compared with MobileNet v1</h3>

<ul>
  <li>MobileNet V1의 경우 Accuracy가 좋지 않으나  GPU runtime은 가장 빠름.</li>
  <li>이는 위에서 제시한 가이드 라인을 어느 정도 가장 잘 만족하기 때문.</li>
</ul>

<h3 id="compared-automatic-model-search">Compared automatic model search</h3>

<ul>
  <li>NAS 는 매우 느리지만 제시한 가이드 라인을 만족하고 speed에 대한 metric을 사용한다면 충분히 좋은 성능을 보일 것.</li>
</ul>

<h3 id="compatibility-with-other-methods">Compatibility with other methods</h3>

<ul>
  <li>Squeeze-and-excitation 과 같은 module과 같이 사용할 수 있음.</li>
  <li>속도는 떨어지나 정확도는 상승. (Table 8 하단)</li>
</ul>

<h3 id="generalization-to-large-models">Generalization to Large Models</h3>

<ul>
  <li>2GFLOPs 이상의 큰 모델을 생성할 수 있음.</li>
  <li>50개의 레이어를 가진 모델을 생성해도 ResNet-50 과 비교하여 적은 연산량, 뛰어난 성능을 보임. (Table 6 상단)</li>
  <li>SE module, residual block을 사용하여 더욱 깊게 만들어도 상대적으로 연산량이 적으면서 뛰어난 성능을 보임. (Table 6 하단)</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_12.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_12.png" /></p>

<h3 id="object-detection">Object Detection</h3>

<ul>
  <li><a href="https://arxiv.org/abs/1711.07264">Light-Head RCNN</a> 사용.</li>
  <li>Classification 에서 성능이 별로였던 Xception 이 Detection 에선 성능이 좋음. → Receptive Field가 크기 때문이라고 생각.</li>
  <li>3x3 depthwise convolution 을 추가하여 Receptive Field를 키워보니 (ShuffleNet V2*) runtime은 늘었으나 성능이 증가함.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_13.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_13.png" /></p>

<h2 id="ps">P.S</h2>

<ul>
  <li>어려웠다.</li>
  <li>항상 가이드 라인을 지키면서 모델을 설계할 수 있을까?</li>
</ul>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/05/09/ShuffleNetV2/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/05/09/ShuffleNetV2/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/05/08/ResNeXt/">
        Review: ResNeXt
      </a>
    </h1>

    <span class="post-date">08 May 2020</span>
     | 
    
    <a href="/blog/tags/#paper" class="post-tag">Paper</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <h1 id="aggregated-residual-transformations-for-deep-neural-networks">Aggregated Residual Transformations for Deep Neural Networks</h1>

<p>Author: Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, Kaiming He<br />
Date: Nov 16, 2016<br />
URL: https://arxiv.org/abs/1611.05431</p>

<h1 id="introduction">Introduction</h1>

<ul>
  <li>Network desine 에 고려해야할 hyper-parameter가 너무 많음. (Width, filter size, Height, ….)</li>
  <li>VGG, ResNet은 비슷한 구조의 레이어를 계속 쌓는 방법을 사용.</li>
  <li>Inception 은 성능은 이전보다 뛰어나지만 이전 방법들과 다르게 복잡한 구조를 쌓는 방법 사용.</li>
  <li>본 논문에서는 VGG/ResNet과 같이 비슷한 레이어를 반복하지만 AlexNet 에서 나온 처음 제안된 Group Convolution 을 적용하여 split-transform-merge stretegy 를 도입.</li>
  <li>일반적인 Reidual Block과 ResNeXt의 Residual Block 비교.</li>
  <li>Cardinality = Number of Groups,</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled.png" /></p>

<h1 id="method">Method</h1>

<h2 id="template">Template</h2>

<ul>
  <li>전체적인 구조는 기존의 VGG/ResNet과 같이 일정 Block 을 반복하여 쌓는 구조.</li>
  <li>반복되는 블럭은 동일한 hyper parameter 사용.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_1.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_1.png" /></p>

<h2 id="revisiting-simple-neurons">Revisiting Simple Neurons</h2>

<ul>
  <li>가장 기본적인 뉴런의 구조</li>
</ul>

<p>[\sum_{i=1}^Dw_ix_i]</p>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_2.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_2.png" /></p>

<ul>
  <li>기본 뉴런 또한 split-transform-merge (Splitting, Transforming, Aggregating)의 구조를 가짐.</li>
  <li>Vector X 가 $x_i$로 Splitting, $x_iw_i$로 Transforming, $\sum_{i=1}^D$ 로 Aggregating</li>
</ul>

<h2 id="aggregated-transformations">Aggregated Transformations</h2>

<ul>
  <li>Networt-in-Network와 다르게 Network-in-Neuron이라는 컨셉으로 차원 확장</li>
</ul>

<p>[\mathcal{F}(x) = \sum_{i=1}^C\mathcal{T}_i(\mathrm{x})]</p>

<ul>
  <li>다른 방식이지만 동일하다는 것을 설명</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_3.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_3.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_4.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_4.png" /></p>

<h2 id="model-capacity">Model Capacity</h2>

<ul>
  <li>Complexity, Number of parameter 를 유지하면서 실험.</li>
  <li>다른 Hyper parameter는 수정하고 싶지 않기 때문에 Residual Block의 Cardinality C와 bottleneck d를 수정</li>
  <li>Cardinality와 bottleneck d의 관계</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_5.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_5.png" /></p>

<h1 id="result">Result</h1>

<h2 id="on-imagenet-1k">On ImageNet-1K</h2>

<ul>
  <li>Cardinality를 1~32 씩 증가시키되 complexity 는 유지하도록 설정하고 실험.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_6.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_6.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_7.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_7.png" /></p>

<ul>
  <li>Increasing Cardinality 와  Increasing depth or width 비교</li>
  <li>Cardinality 의 성능이 더 좋음.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_8.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_8.png" /></p>

<ul>
  <li>Residual connections 여부에 따른 비교</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_9.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_9.png" /></p>

<ul>
  <li>State-of-the-art model 과 비교</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_10.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_10.png" /></p>

<h2 id="on-imagenet-5k">On ImageNet-5K</h2>

<ul>
  <li>5000개 클래스에서도 잘 되더라.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_11.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_11.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_12.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_12.png" /></p>

<h2 id="on-cifar">On CIFAR</h2>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_13.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_13.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_14.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_14.png" /></p>

<h2 id="on-coco-object-detection">On COCO object detection</h2>

<ul>
  <li>Faster RCNN에 적용.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_15.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_15.png" /></p>

<h2 id="ps">P.S</h2>

<ul>
  <li>AlexNet의 선견지명.</li>
  <li>하긴 안좋으면 논문으로 쓸리가 없지.</li>
</ul>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/05/08/ResNeXt/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/05/08/ResNeXt/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/05/07/ShuffleNetV1/">
        Review: ShuffleNetV1
      </a>
    </h1>

    <span class="post-date">07 May 2020</span>
     | 
    
    <a href="/blog/tags/#paper" class="post-tag">Paper</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <h1 id="shufflenet-an-extremely-efficient-convolutional-neural-network-for-mobile-devices">ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices</h1>

<p>Author: Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, Jian Sun<br />
Date: Jul 04, 2017<br />
URL: https://arxiv.org/abs/1707.01083</p>

<h1 id="introduction">Introduction</h1>

<ul>
  <li>Visual recognition 에서 deeper, larger CNN을 설계하는 것이 트렌드.</li>
  <li>하지만 이는 매우 많은 연산량을 필요로함.</li>
  <li>본 논문은 정해놓은 범위의 연산량에서 최고로 효율적인 구조는 찾아내는 것을 목표로 함.</li>
  <li>Xception, ResNeXt 에서 1x1 Convolution 을 사용하는데 두 네트워크에서 대부분의 연산량이 1x1 Convolution 이 차지하고 있어 비효율적.</li>
  <li>이를 보완하기 위해 AlexNet에서 처음 제안한 group convolution 적용.</li>
  <li>Group convolution 의 단점을 보완하기 위해 channel shuffle operation 또한 제안.</li>
</ul>

<h1 id="method">Method</h1>

<h2 id="channel-shuffle-for-group-convolutions">Channel Shuffle for Group Convolutions</h2>

<ul>
  <li>상대적으로 연산량이 많은 1x1 Convolution을 ResNeXt 에서 사용한 Group Convolution 으로 적용.</li>
  <li>하지만 Group으로 계속 진행하다보면 특정 채널에 편향된 결과를 보이는 문제가 생길 것이므로 channel을 shuffle 해줌.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled.png" /></p>

<h2 id="shufflenet-unit">ShuffleNet Unit</h2>

<ul>
  <li>ShuffleNet에서 사용된 Bottle unit은 Xception과 MobileNet에서 사용된 Residual Block에서 1x1 Convolution을 Group Convolution으로 변경하고 Channel Shuffle을 추가한 것.</li>
  <li>Stride unit 에선 element-wise addition이 아닌 concatenation으로 대체.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_1.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_1.png" /></p>

<h2 id="network-architecture">Network Architecture</h2>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_2.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_2.png" /></p>

<h1 id="result">Result</h1>

<h2 id="ablation-study">Ablation Study</h2>

<h3 id="pointwise-group-convolutions">Pointwise Group Convolutions</h3>

<ul>
  <li>Groups 에 따른 성능 비교.</li>
  <li>
    <p>ShuffleNet s$\times$ 에서 s는 필터 개수에 대한 scaling factor.</p>
  </li>
  <li>무조건 많이 나눈다고 좋은 것은 아님.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_3.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_3.png" /></p>

<h3 id="channel-shuffle-vs-no-shuffle">Channel Shuffle vs. No Shuffle</h3>

<ul>
  <li>Channel Shuffle 여부에 따른 성능 비교.</li>
  <li>Shuffle 적용시 성능이 뚜렷하게 증가한 것을 확인.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_4.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_4.png" /></p>

<h2 id="comparison-with-other-sturcture-units">Comparison with Other Sturcture Units</h2>

<ul>
  <li>제한된 연산량 내에서 다른 Network 들과 성능 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_5.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_5.png" /></p>

<ul>
  <li>기존에 비슷한 성능의 Network들과 연산량 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_6.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_6.png" /></p>

<h2 id="comparison-with-mobilenets-and-other-frameworks">Comparison with MobileNets and Other Frameworks</h2>

<ul>
  <li>Mobile devices에 특화된 MobileNet과 성능 비교</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_7.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_7.png" /></p>

<h2 id="generalization-ability">Generalization Ability</h2>

<ul>
  <li>MS COCO Data를 사용하여 Object detection 성능 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_8.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_8.png" /></p>

<h2 id="actual-speedup-evaluation">Actual Speedup Evaluation</h2>

<ul>
  <li>Mobile device에서 Inference 속도 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_9.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_9.png" /></p>

<h2 id="ps">P.S</h2>
<ul>
  <li>GPU가 부족해서 했다던 Group Convolution의 부활..?</li>
</ul>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/05/07/ShuffleNetV1/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/05/07/ShuffleNetV1/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/05/06/CutMix/">
        Review: CutMix
      </a>
    </h1>

    <span class="post-date">06 May 2020</span>
     | 
    
    <a href="/blog/tags/#paper" class="post-tag">Paper</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <h1 id="cutmix-regularization-strategy-to-train-strong-classifiers-with-localizable-features">CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features</h1>

<p>Author: Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun, Junsuk Choe, Youngjoon Yoo<br />
Date: May 13, 2019<br />
URL: https://arxiv.org/abs/1905.04899</p>

<h1 id="introduction">Introduction</h1>

<ul>
  <li>CNN 은 computer vision 문제에 많이 사용되고 있음.</li>
  <li>효율적이고 높은 성능을 위해 data augmentation, regularization 등 기법을 적용.</li>
  <li>특정 부분에 overfitting(?) 되는 것을 방지하기 위해 dropout, regional dropout 과 같은 방법 사용.</li>
  <li>그 외에도 일부분을 0으로 채운다거나 노이즈로 채우는 방법, 정보가 있는 부분의 pixel을 줄이는 방법 등이 성능 향상을 보였으나 CNN은 데이터가 많이 고픈데….데이터를 없앤다..? 라는 부분에서 의문을 가짐.</li>
  <li>영상의 일부를 자르고 다른 영상으로 대체하는 CutMix 를 제안.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled.png" /></p>

<h1 id="cutmix">CutMix</h1>

<h2 id="algorithm">Algorithm</h2>

<ul>
  <li>A, B 두개의 클래스만 존재.</li>
</ul>

<p>[(x, y): \text{Training image, label} \ (A, B): \text{Training class} \ (x_A, y_A), (x_B, y_B): \text{Training sample}]</p>

<ul>
  <li>어느 부분을 섞을 것인지 binary mask (M) 생성</li>
  <li>생성된 mask를 통해 섞을 비율 lambda 추출.</li>
  <li>Label의 경우 비율에 One-hot encoding이 합친 후 영상에서의 각 클래스의 비율로 변경.</li>
</ul>

<p>[\mathrm{M}: \text{Binary mask where to drop out and fill} \ \lambda: \text{Combination ratio} \ \tilde{x} = \mathrm{M} \bigodot x_A + (1 - \mathrm{M}) \bigodot x_B \ \tilde{y} = \lambda{y_A} + (1 - \lambda)y_B]</p>

<ul>
  <li>M에서 bounding box 좌표 (B) 추출.</li>
  <li>x, y 좌표는 Uniform distribution.</li>
  <li>$x_B$에서 B 를 매칭시켜서 crop 후 B에 매칭되는 $x_A$ 의 부분에 paste.</li>
</ul>

<p>[\mathrm{B}: \text{Bounding box coordinates }  (r_x, r_y, r_w, r_h) \ r_x \sim \text{Unif }(0, W), r_w = W\sqrt{1-\lambda}, \ r_y \sim \text{Unif } (0, H), r_h = H\sqrt{1-\lambda}]</p>

<h2 id="discussion">Discussion</h2>

<ul>
  <li>CutMix를 이용했을 때 CNN이 어느 부분을 학습하는지 확인.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_1.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_1.png" /></p>

<ul>
  <li>다른 method와 비교하여 CutMix의 주요 차이점.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_2.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_2.png" /></p>

<ul>
  <li>Validation Error를 비교했을 때 기존의 모델에 비해 CutMix 적용시 Error가 낮음.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_3.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_3.png" /></p>

<h1 id="experiments">Experiments</h1>

<h2 id="image-classification">Image Classification</h2>

<h3 id="imagenet-classification">ImageNet Classification</h3>

<ul>
  <li>Baseline, 다른 augmentation method와 비교</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_4.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_4.png" /></p>

<ul>
  <li>두 Model에 CutMix를 적용하여 성능 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_5.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_5.png" /></p>

<h3 id="cifar-classification">CIFAR Classification</h3>

<ul>
  <li>다른 Regularization 들과 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_6.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_6.png" /></p>

<ul>
  <li>가벼운 Model 에 적용하여 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_7.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_7.png" /></p>

<ul>
  <li>CIFAR-10에 적용한 결과.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_8.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_8.png" /></p>

<h3 id="ablation-studies">Ablation Studies</h3>

<ul>
  <li><strong>CutMix 에서 alpha가 뭐지…….</strong></li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_9.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_9.png" /></p>

<ul>
  <li>CutMix하는 방법을 다양하게 적용했을 때 성능 비교</li>
  <li>Center Gaussian: Uniform distribution → Gaussian distribution</li>
  <li>Fixed-size: 16 x 16 ( $\lambda = 0.75$ )로 고정</li>
  <li>Scheduled: 학습이 진행될 수록 CutMix 확률을 0부터 1까지 증가</li>
  <li>One-hot: 패치 비율에 따라 Portion label이 아닌 One-hot encoding으로 적용</li>
  <li>Complete-label: lambda 를 고려하지 않고 $y = 0.5y_A + 0.5y_B$로 적용</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_10.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_10.png" /></p>

<h2 id="weakly-supervised-object-localization">Weakly Supervised Object Localization</h2>

<ul>
  <li>Localization 부분에 대해 다른 방법들과 비교.</li>
  <li>학습 후 CAM을 이용해서 bounding box를 그린 것으로 보임.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_11.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_11.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_12.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_12.png" /></p>

<h2 id="transfer-learning-of-pretrained-model">Transfer Learning of Pretrained Model</h2>

<ul>
  <li>Object detection, Image captioning 에 적용하여 성능 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_13.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_13.png" /></p>

<h2 id="robustness-and-uncertainty">Robustness and Uncertainty</h2>

<ul>
  <li>Adversarial attack 에 대해 Accuracy 비교.</li>
  <li><a href="https://arxiv.org/abs/1412.6572">Fast Gradient Sign Method (FGSM)</a>을 이용하여 adversarial perturbation 생성.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_14.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_14.png" /></p>

<ul>
  <li>Occlusion 상황에 대해서 성능 비교.</li>
  <li>가운데 부분 혹은 Boundary 에 0~224 크기 사이의 hole을 생성.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_15.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_15.png" /></p>

<ul>
  <li>Uncertainty</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_16.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_16.png" /></p>

<h2 id="cutmix-algorithm">CutMix Algorithm</h2>

<p><img src="https://jjerry-k.github.io/public/img/cutmix/Untitled_17.png" alt="https://jjerry-k.github.io/public/img/cutmix/Untitled_17.png" /></p>

<h2 id="ps">P.S</h2>

<ul>
  <li>Appendix에 내용이 더 있지만… 간단히 정리하려니 넣기 좀 힘듦.</li>
  <li>당연한 얘기지만 모든 데이터에 적용하기엔 어려움이 있을 것으로 보임.</li>
</ul>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/05/06/CutMix/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/05/06/CutMix/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/blog/page5">Older</a>
  
  
    
      <a class="pagination-item newer" href="/blog/page3">Newer</a>
    
  
</div>


        </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <!-- Modal -->
  <div class="modal fade" id="myModal" role="dialog">
    <div class="modal-dialog">

      <!-- Modal content-->
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal">&times;</button>
          <h4 class="modal-title">Search</h4>
        </div>
        <div class="modal-body">

    <h4><div id="search-container">
      <input type="text" id="search-input" placeholder="검색어 입력" class="input" style="font-size: 1rem; width: 100%; padding: 10px; border: 0px; outline: none; float: left; background: #cecece;" autofocus>
    </div></h4><br>

      <div id="results">
        <h1></h1>
      <ul class="results"></ul>
      </div>
      <br><ul id="results-container"></ul>
    </div>

<!-- Script pointing to jekyll-search.js -->


<script type="text/javascript">
      SimpleJekyllSearch({
        searchInput: document.getElementById('search-input'),
        resultsContainer: document.getElementById('results-container'),
        json: '/dest/search.json',
        searchResultTemplate: '<h4 style="margin-bottom:-0.5rem;"><a class="post-title" style="color:#ac4142;" href="{url}" title="{desc}">{title}</a> <small>{category}</small></h4>',
        noResultsText: '<h4><br>문서가 존재하지 않습니다.</h4>',
        limit: 15,
        fuzzy: false,
        exclude: ['Welcome']
      })
</script>
        </div>
      </div>

    </div>
  </div>

</div>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');
        document.addEventListener('click', function(e) {
          var target = e.target;
          if (target === toggle) {
            checkbox.checked = !checkbox.checked;
            e.preventDefault();
          } else if (checkbox.checked && !sidebar.contains(target)) {
            /* click outside the sidebar when sidebar is open */
            checkbox.checked = false;
          }
        }, false);
      })(document);
    </script>

    
      <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-126636477-1', 'auto');
        ga('send', 'pageview');
      </script>
    

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (absbygoogle = window.adsbygoogle || []).push({
          google_ad_client: "ca-pub-1054696837285307",
          enable_page_level_ads: true
      });
    </script>
  </body>
  
  <script id="dsq-count-scr" src="//jerry.disqus.com/count.js" async></script>
  
</html>
