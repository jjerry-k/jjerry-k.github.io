<!DOCTYPE html>
<html lang="en-us">
  <head>
  <head>
    <link href="http://gmpg.org/xfn/11" rel="profile">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
  
    <!-- Enable responsiveness on mobile devices-->
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  
    <title>
      
        Blog &middot; Jerry's Blog
      
    </title>
  
    <!-- CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">
    <link rel="stylesheet" href="/public/css/main.css">
  
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png">
    <link rel="shortcut icon" href="/public/favicon.ico">
  
    <!-- RSS -->
    <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
  
    <!-- scroll -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    <script>
      $( window ).scroll( function() {
        if ( $( this ).scrollTop() > 500 ) {
          $( '.top' ).fadeIn();
        } else {
          $( '.top' ).fadeOut();
        }
      } );
      $( '.top' ).click( function() {
        $( 'html, body' ).stop().animate( { scrollTop : 0 }, 100);
        return false;
      } );
    </script>
    
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (absbygoogle = window.adsbygoogle || []).push({
          google_ad_client: "ca-pub-1054696837285307",
          enable_page_level_ads: true
      });
    </script>
    
    <!-- 
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        //jax: ["input/TeX", "output/HTML-CSS"],
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
          inlineMath: [ ['$', '$'] ],
          displayMath: [ ['$$', '$$'] ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
        //,
        //displayAlign: "left",
        //displayIndent: "2em"
      });
      MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
        alert("Math Processing Error: "+message[1]);
      });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
        alert("Math Processing Error: "+message[1]);
      });
    </script>
    <script type="text/javascript" async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript">
    </script>
     -->
    
    
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      //jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$'] ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
      //,
      //displayAlign: "left",
      //displayIndent: "2em"
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
  

    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script src="/dest/simple-jekyll-search.js" type="text/javascript"></script>
    <script type="text/javascript">
    $(document).ready(function(){
      document.search.searchinput.focus();
    });
    </script>
  </head>
  
  <style>blockquote {font-size: 1em; line-height: 1.4}</style>
  
  <!-- New line Start-->
  <!--  -->
  <!-- New line End -->
  </head>
  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <div class="sidebar-personal-info">
      <div class="sidebar-personal-info-section">
        <a href="https://gravatar.com/22a6447c0c965de55f4ce9691aed2af4">
          <img src="https://www.gravatar.com/avatar/22a6447c0c965de55f4ce9691aed2af4?s=350" title="View on Gravatar" alt="View on Gravatar" />
        </a>
      </div>
      <div class="sidebar-personal-info-section">
        <p></p>
      </div>
      
      
      
      <div class="sidebar-personal-info-section">
        <p> Follow me  :  
        
        
        
        <a href="https://github.com/jjerry-k">
          <i class="fa fa-github" aria-hidden="true"></i>
        </a>
        
        |
        
        
        
        <a href="https://www.facebook.com/jerry.kim.566">
          <i class="fa fa-facebook" aria-hidden="true"></i>
        </a>
        
        |
        
        
        
        <a href="mailto:jaeyeol2931@gmail.com">
          <i class="fa fa-envelope" aria-hidden="true"></i>
        </a>
        
        
        
        </p>
      </div>
      
    </div>
  </div>

  <nav class="sidebar-nav">
    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/">
          Home
        </a>

        
      </span>

    
      
      
      

      

      <span class="foldable">
        <a class="sidebar-nav-item " href="/blog/">
          Contents
        </a>

        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/blog/">
                Blog
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/python/">
                Python
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/ubuntu/">
                Ubuntu
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/living/">
                Living
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/deeplearning/">
                Deep Learning
              </a>
          
        
      </span>

    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/about/">
          About
        </a>

        
      </span>

    

  </nav>

  <div class="sidebar-item">
    <p>
    &copy; 2020 Jerry. This work is liscensed under <a href="http://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a>.
    </p>
  </div>

  <div class="sidebar-item">
    <p>
    Powered by <a href="http://jekyllrb.com">jekyll</a>
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
          <div class="top" style="position:fixed; right:10%; bottom:15px; display:none; z-index:9999;">
            <a href="#">
              <img src="https://jjerry-k.github.io/public/top.png" width="40" height="40" class="top" style="border-radius:5px; background-color: #000; margin-bottom:0; margin-right:7px; float:left;">
            </a>
            
            <a href="/blog//">
              <img src="https://jjerry-k.github.io/public/contents.png" width="40" height="40" class="top" style="border-radius:5px; background-color: #000; margin-bottom:0; float:left;">
            </a>
          </div>
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title" align="center">
            <a href="/" title="Home" title="Jerry's Blog">
              <img class="masthead-logo" src="/public/logo.png"/>
            </a>
            <small></small>
            <a href="https://donaricano.com/mypage/1391188679_guPzXC" target="_blank">
              <img src="https://d1u4yishnma8v5.cloudfront.net/mobile-gift.png" width="60" height="60" style="position:absolute; top:0.25rem; right:4rem" alt="donaricano-btn" style="height: 130px !important;width: 130px !important;" />
            </a>
            <img src="http://jjerry-k.github.io/public/search.png" width="20" height="20" style="position:absolute; top:1.3rem; right:1.5rem" data-toggle="modal" data-target="#myModal">
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/06/26/nipa_intro/">
        NIPA...NIPA가 뭐죠..
      </a>
    </h1>

    <span class="post-date">26 Jun 2020</span>
     | 
    
    <a href="/blog/tags/#tools" class="post-tag">Tools</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <p>요즘 커뮤니티(V-AIS) 에선 NIPA에 대한 얘기가 많이 나옵니다.<br />
NIPA는 <a href="https://www.nipa.kr/"><strong>정보통신산업진흥원</strong></a> 의 약자인데 <code class="language-plaintext highlighter-rouge">근데 그래서 이게 왜..?</code> 라는 의문을 가지실 겁니다. <br />
지금 AI Hub에서 지원하는 <a href="http://www.aihub.or.kr/node/223"><strong>AI 컴퓨팅 자원 지원 사업</strong></a>을 하고 있는데요.<br />
그 사업에서 컴퓨팅 자원을 관리하는게 NIPA 입니다. 그래서 NIPA, NIPA 하죠..</p>

<p>간단하게 그림으로 보여드리면 이렇습니다.</p>

<p><img src="https://jjerry-k.github.io/public/img/nipa_intro/Untitled.png" alt="Untitled.png" /></p>

<p>더 간단하게 설명드리면 <strong><code class="language-plaintext highlighter-rouge">GPU서버 지원해드림 ㅇㅇ</code></strong> 이겁니다.</p>

<p>어느 정도 사양이냐…</p>

<p><img src="https://jjerry-k.github.io/public/img/nipa_intro/Untitled_1.png" alt="Untitled_1.png" /></p>

<p><strong>일반 사용자</strong>와 <strong>수시 사용자</strong>로 나뉘는데요. 그 차이는 사이트에서 확인하시길..</p>

<p>이렇게 보면 GPU로 뭐 쓰는지 잘 모르시겠죠. 그래서 가져왔습니다.</p>

<p>제가 포스팅, 환경구축과 같은 자료를 만들기 위해 신청한 서버입니다.</p>

<p><img src="https://jjerry-k.github.io/public/img/nipa_intro/Untitled_2.png" alt="Untitled_2.png" /></p>

<p>위 GPU 사진은 <strong>수시 사용자</strong> 기준입니다. 일반 사용자면 V100 두개겠네요.</p>

<p>뭐 이런 서버를 <strong>공짜</strong>로 제공을 해줍니다.</p>

<p>집에 서버가 따로 없는 분들이라면 이보다 좋은 건 없겠죠. (게다가 VRAM이 32기가임….)</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center"><strong>헤헿 겁나 좋군</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="https://jjerry-k.github.io/public/img/nipa_intro/good.png" alt="good.png" /></td>
    </tr>
  </tbody>
</table>

<p>다음엔 NIPA 신청 방법에 대한 포스팅은 간단히 해보겠습니다.</p>

<p>그럼 모두 즐거운 딥러닝 공부, 연구하세요.</p>

<h2 id="ps">P.S.</h2>
<ul>
  <li>수시 사용자의 경우 기본 10일 사용, 10일마다 사용 연장신청을 해야함.</li>
  <li>당연하지만 신청해놓고 사용안하면 검열 후 강제 반납.</li>
</ul>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/06/26/nipa_intro/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/06/26/nipa_intro/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/06/14/tf2_multi_gpu/">
        TensorFlow Multi GPU 사용법
      </a>
    </h1>

    <span class="post-date">14 Jun 2020</span>
     | 
    
    <a href="/blog/tags/#tensorflow" class="post-tag">TensorFlow</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <p>이번 포스팅은 Multi GPU 시스템에서 Google의 머신러닝 오픈 소스 플랫폼인 <a href="https://www.tensorflow.org/">TensorFlow</a>사용법에 관한 것입니다!<br />
거두절미하고 바로 코딩으로 들어가겠습니다!</p>

<h2 id="single-gpu-예시">Single GPU 예시</h2>
<ul>
  <li>다음 코드는 Single GPU를 이용하여 mnist data를 분류하는 코드입니다.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Import Package
</span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">optimizers</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">utils</span>

<span class="c1"># Data Prepare
</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">),</span> <span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">)</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">mnist</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">train_x</span><span class="p">,</span> <span class="n">test_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">train_x</span><span class="o">/</span><span class="mf">255.</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">test_x</span><span class="o">/</span><span class="mf">255.</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Train Data's Shape : "</span><span class="p">,</span> <span class="n">train_x</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">train_y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Test Data's Shape : "</span><span class="p">,</span> <span class="n">test_x</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test_y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Build Network
</span><span class="n">cnn</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">,)))</span>
<span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">())</span>
<span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">())</span>
<span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">))</span>

<span class="n">cnn</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">(),</span> <span class="n">loss</span><span class="o">=</span><span class="n">losses</span><span class="p">.</span><span class="n">sparse_categorical_crossentropy</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>                
<span class="k">print</span><span class="p">(</span><span class="s">"Network Built!"</span><span class="p">)</span>

<span class="c1"># Training Network
</span><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">cnn</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="multi-gpu-예시">Multi GPU 예시</h2>
<ul>
  <li>다음 코드는 Multi GPU를 이용한 코드입니다.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Import Package
</span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">optimizers</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">utils</span>

<span class="c1"># Data Prepare
</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">),</span> <span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">)</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">mnist</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">train_x</span><span class="p">,</span> <span class="n">test_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">train_x</span><span class="o">/</span><span class="mf">255.</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">test_x</span><span class="o">/</span><span class="mf">255.</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Train Data's Shape : "</span><span class="p">,</span> <span class="n">train_x</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">train_y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Test Data's Shape : "</span><span class="p">,</span> <span class="n">test_x</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test_y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Build Network
</span><span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">distribute</span><span class="p">.</span><span class="n">MirroredStrategy</span><span class="p">()</span>
<span class="k">with</span> <span class="n">strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">():</span>
    <span class="n">cnn</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">,)))</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">())</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">())</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">())</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">))</span>

    <span class="n">cnn</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">(),</span> <span class="n">loss</span><span class="o">=</span><span class="n">losses</span><span class="p">.</span><span class="n">sparse_categorical_crossentropy</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>                
<span class="k">print</span><span class="p">(</span><span class="s">"Network Built!"</span><span class="p">)</span>

<span class="c1"># Training Network
</span><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span>
<span class="n">batch_size_each_gpu</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size_each_gpu</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">gpus</span><span class="p">)</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">cnn</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">))</span>
</code></pre></div></div>

<p>어렵지 않습니다. <code class="language-plaintext highlighter-rouge">Build Network</code> 주석 부분과 <code class="language-plaintext highlighter-rouge">Training Network</code> 부분에 <code class="language-plaintext highlighter-rouge">batch_size</code>만 조금 수정해주시면 끝납니다!<br />
<img src="https://jjerry-k.github.io/public/img/tf_multi_gpu/bob.png" alt="img" /></p>

<p>하지만 이렇게 하면 무식하게 GPU의 모든 메모리를 할당합니다.<br />
그렇기 떄문에 다음과 같이 코드를 추가하여 <code class="language-plaintext highlighter-rouge">필요한 만큼</code> 할당하도록 합니다.</p>

<h2 id="필요한-만큼의-gpu-메모리만-사용하기">필요한 만큼의 GPU 메모리만 사용하기</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Import Package
</span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">optimizers</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">utils</span>

<span class="c1"># Data Prepare
</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">),</span> <span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">)</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">mnist</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">train_x</span><span class="p">,</span> <span class="n">test_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">train_x</span><span class="o">/</span><span class="mf">255.</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">test_x</span><span class="o">/</span><span class="mf">255.</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Train Data's Shape : "</span><span class="p">,</span> <span class="n">train_x</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">train_y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Test Data's Shape : "</span><span class="p">,</span> <span class="n">test_x</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test_y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># For Efficiency
</span><span class="n">gpus</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s">'GPU'</span><span class="p">)</span>
<span class="k">if</span> <span class="n">gpus</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">gpu</span> <span class="ow">in</span> <span class="n">gpus</span><span class="p">:</span>
            <span class="n">tf</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">set_memory_growth</span><span class="p">(</span><span class="n">gpu</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
        <span class="n">logical_gpus</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">list_logical_devices</span><span class="p">(</span><span class="s">'GPU'</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">gpus</span><span class="p">),</span> <span class="s">"Physical GPUs,"</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">logical_gpus</span><span class="p">),</span> <span class="s">"Logical GPUs"</span><span class="p">)</span>
    <span class="k">except</span> <span class="nb">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>

<span class="c1"># Build Network
</span><span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">distribute</span><span class="p">.</span><span class="n">MirroredStrategy</span><span class="p">()</span>
<span class="k">with</span> <span class="n">strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">():</span>
    <span class="n">cnn</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">,)))</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">())</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">())</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">())</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">))</span>

    <span class="n">cnn</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">(),</span> <span class="n">loss</span><span class="o">=</span><span class="n">losses</span><span class="p">.</span><span class="n">sparse_categorical_crossentropy</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>                
<span class="k">print</span><span class="p">(</span><span class="s">"Network Built!"</span><span class="p">)</span>

<span class="c1"># Training Network
</span><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span>
<span class="n">batch_size_each_gpu</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size_each_gpu</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">gpus</span><span class="p">)</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">cnn</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">))</span>
</code></pre></div></div>

<p>기존 Multi GPU 코드와 달라진 점은</p>
<ol>
  <li><code class="language-plaintext highlighter-rouge">For Efficiency</code>라는 부분이 추가.</li>
  <li><code class="language-plaintext highlighter-rouge">strategy = tf.distribute.MirroredStrategy()</code>을 <code class="language-plaintext highlighter-rouge">Build Network</code>에서 <code class="language-plaintext highlighter-rouge">For Efficiency</code>의 가장 첫번째 라인으로 이동.</li>
</ol>

<p>이렇게 변경 후 실행 후 nvidia-smi와 같은 모니터링 툴을 확인해보시면 이전과는 다르게 GPU 메모리를 필요한 만큼만 사용하는걸 보실 수 있습니다!</p>

<h2 id="ps">P.S</h2>
<ul>
  <li>다음은 뭘로 포스팅하지…</li>
</ul>

<h2 id="번외편-using-gradient-tape">번외편 (Using gradient tape)</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># %%
# Import Package
</span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">optimizers</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">utils</span>

<span class="n">gpus</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s">'GPU'</span><span class="p">)</span>
<span class="k">if</span> <span class="n">gpus</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Currently, memory growth needs to be the same across GPUs
</span>        <span class="k">for</span> <span class="n">gpu</span> <span class="ow">in</span> <span class="n">gpus</span><span class="p">:</span>
            <span class="n">tf</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">set_memory_growth</span><span class="p">(</span><span class="n">gpu</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
        <span class="n">logical_gpus</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">list_logical_devices</span><span class="p">(</span><span class="s">'GPU'</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">gpus</span><span class="p">),</span> <span class="s">"Physical GPUs,"</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">logical_gpus</span><span class="p">),</span> <span class="s">"Logical GPUs"</span><span class="p">)</span>
    <span class="k">except</span> <span class="nb">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="c1"># Memory growth must be set before GPUs have been initialized
</span>        <span class="k">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>

<span class="c1"># %%
# Data Prepare
</span><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span>
<span class="n">batch_size_each_gpu</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size_each_gpu</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">gpus</span><span class="p">)</span>

<span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">),</span> <span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">)</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">mnist</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">train_x</span><span class="p">,</span> <span class="n">test_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">train_x</span><span class="o">/</span><span class="mf">255.</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">test_x</span><span class="o">/</span><span class="mf">255.</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Train Data's Shape : "</span><span class="p">,</span> <span class="n">train_x</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">train_y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Test Data's Shape : "</span><span class="p">,</span> <span class="n">test_x</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test_y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># %%
# Build Network
</span><span class="k">class</span> <span class="nc">build_model</span><span class="p">(</span><span class="n">models</span><span class="p">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">build_model</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">pool1</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">pool2</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">pool1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">pool2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">dense</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Network Built!"</span><span class="p">)</span>

<span class="c1"># Set mirrored Strategy
</span><span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">distribute</span><span class="p">.</span><span class="n">MirroredStrategy</span><span class="p">()</span>

<span class="k">with</span> <span class="n">strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">():</span>
    
    <span class="c1"># Prepare dataset 
</span>    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)).</span><span class="n">shuffle</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_x</span><span class="p">)).</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> 
    <span class="n">train_dist_dataset</span> <span class="o">=</span> <span class="n">strategy</span><span class="p">.</span><span class="n">experimental_distribute_dataset</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
    
    <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">)).</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> 
    <span class="n">test_dist_dataset</span> <span class="o">=</span> <span class="n">strategy</span><span class="p">.</span><span class="n">experimental_distribute_dataset</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>

    <span class="c1"># Make Network
</span>    <span class="n">cnn</span> <span class="o">=</span> <span class="n">build_model</span><span class="p">()</span>

    <span class="c1"># Set Loss &amp; Metric function
</span>    <span class="n">loss_object</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">Reduction</span><span class="p">.</span><span class="n">NONE</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">):</span>
        <span class="n">per_example_loss</span> <span class="o">=</span> <span class="n">loss_object</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">compute_average_loss</span><span class="p">(</span><span class="n">per_example_loss</span><span class="p">,</span> <span class="n">global_batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
        
    <span class="n">test_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">'test_loss'</span><span class="p">)</span>

    <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">'train_accuracy'</span><span class="p">)</span>
    <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">'test_accuracy'</span><span class="p">)</span>

    <span class="c1"># Set optimizer
</span>    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">()</span>

    <span class="c1"># Define taining, test function
</span>    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
        <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span>

        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">cnn</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">compute_loss</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>

        <span class="n">gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">cnn</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">cnn</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">))</span>

        <span class="n">train_accuracy</span><span class="p">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span> 
    
    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
        <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span>

        <span class="n">predictions</span> <span class="o">=</span> <span class="n">cnn</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">t_loss</span> <span class="o">=</span> <span class="n">loss_object</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>

        <span class="n">test_loss</span><span class="p">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">t_loss</span><span class="p">)</span>
        <span class="n">test_accuracy</span><span class="p">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>

    <span class="c1"># Define training, test function suitable for Mirrored Strategy 
</span>    <span class="o">@</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">distributed_train_step</span><span class="p">(</span><span class="n">dataset_inputs</span><span class="p">):</span>
        <span class="n">per_replica_losses</span> <span class="o">=</span> <span class="n">strategy</span><span class="p">.</span><span class="n">experimental_run_v2</span><span class="p">(</span><span class="n">train_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">dataset_inputs</span><span class="p">,))</span>
        <span class="k">return</span> <span class="n">strategy</span><span class="p">.</span><span class="nb">reduce</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">distribute</span><span class="p">.</span><span class="n">ReduceOp</span><span class="p">.</span><span class="n">SUM</span><span class="p">,</span> <span class="n">per_replica_losses</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
 
    <span class="o">@</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">distributed_test_step</span><span class="p">(</span><span class="n">dataset_inputs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">strategy</span><span class="p">.</span><span class="n">experimental_run_v2</span><span class="p">(</span><span class="n">test_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">dataset_inputs</span><span class="p">,))</span>

    <span class="c1"># Train Network
</span>    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    
        <span class="c1"># Training Loop
</span>        <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">num_batches</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">train_dist_dataset</span><span class="p">:</span>
            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">distributed_train_step</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">num_batches</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">num_batches</span>

        <span class="c1"># Test Loop
</span>        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">test_dist_dataset</span><span class="p">:</span>
            <span class="n">distributed_test_step</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">template</span> <span class="o">=</span> <span class="p">(</span><span class="s">"에포크 {}, 손실: {}, 정확도: {}, 테스트 손실: {}, 테스트 정확도: {}"</span><span class="p">)</span>
        <span class="k">print</span> <span class="p">(</span><span class="n">template</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_accuracy</span><span class="p">.</span><span class="n">result</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="n">test_loss</span><span class="p">.</span><span class="n">result</span><span class="p">(),</span> <span class="n">test_accuracy</span><span class="p">.</span><span class="n">result</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>

        <span class="n">test_loss</span><span class="p">.</span><span class="n">reset_states</span><span class="p">()</span>
        <span class="n">train_accuracy</span><span class="p">.</span><span class="n">reset_states</span><span class="p">()</span>
        <span class="n">test_accuracy</span><span class="p">.</span><span class="n">reset_states</span><span class="p">()</span>
</code></pre></div></div>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/06/14/tf2_multi_gpu/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/06/14/tf2_multi_gpu/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/06/13/DETR/">
        Review: DETR
      </a>
    </h1>

    <span class="post-date">13 Jun 2020</span>
     | 
    
    <a href="/blog/tags/#paper" class="post-tag">Paper</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <h1 id="end-to-end-object-detection-with-transformers">End-to-End Object Detection with Transformers</h1>

<p>Author: Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, and Sergey Zagoruyko
Date: May 27, 2020
URL: https://ai.facebook.com/research/publications/end-to-end-object-detection-with-transformers</p>

<h1 id="introduction">Introduction</h1>

<ul>
  <li>현재 Object detection model들은 Input부터 Output (bounding bos, category label) 까지 Direct 하지 못함.  Post processing 이 영향을 끼치기 때문에…</li>
  <li>본 논문에선 Direct prediction approach 제안.</li>
  <li>이전에도 몇몇 실험이 있었으나 그 당시에는 prior knowledge를 준다거나 성능이 별로 좋지 못했음.</li>
  <li><a href="https://arxiv.org/abs/1706.03762">Transformer</a> 를 사용.</li>
  <li>새로운 Loss function 도입.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/DETR/Untitled.png" alt="jjerry-k.github.io/public/img/DETR/Untitled.png" /></p>

<h1 id="related-works">Related Works</h1>

<h2 id="set-prediction">Set Prediction</h2>

<ul>
  <li>현재까지 Direct로 set(box, class)을 prediction 하는 방법이 없음.</li>
  <li>Post processing 이 없는 model 제안.</li>
  <li>이를 위해 Hungarian algorithm 기반의 loss 설계.</li>
</ul>

<h2 id="transformers-and-parallel-decoding">Transformers and Parallel Decoding</h2>

<ul>
  <li>다른 RNN 계열보다 Long sequence 에 적합한 model</li>
  <li>auto-regressive model</li>
</ul>

<h2 id="object-detection">Object detection</h2>

<h3 id="set-based-loss">Set-based loss</h3>

<ul>
  <li>기존에 bipatite matching loss 를 사용했지만  NMS 를 사용해야 성능이 향상되었음.</li>
  <li>그 후 Learnable NMS 를 사용한 방법이 제시 되었으나 hand-crafted context feature 를 사용 하기에 효율적이지 못함.</li>
</ul>

<h3 id="recurrent-detectors">Recurrent detectors</h3>

<ul>
  <li>이름에서 알 수 있듯 RNN 계열을 도입한 Object detection</li>
  <li>기존 방법에선 Small dataset을 이용했고 RNN 계열을 이용했기에 parallel 구조를 가져가지 못했음.</li>
</ul>

<h1 id="the-detr-model">The DETR model</h1>

<ul>
  <li>DETR은 크게 두 개의 장점이 있음. → a set prediction loss, a architecture</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/DETR/Untitled_1.png" alt="jjerry-k.github.io/public/img/DETR/Untitled_1.png" /></p>

<h2 id="object-detection-set-prediction-loss">Object detection set prediction loss</h2>

<p>[\hat{\sigma} = {argmin}<em>{\sigma \in \mathfrak{S}_N} \sum^N_i \mathcal{L}</em>{match}(y_i, \hat{y}_{\sigma(i)})]</p>

<p>[\mathcal{L}<em>{match}(y_i, \hat{y}</em>{\sigma(i)}) = -1<em>{c_i \neq \phi}\hat{p}</em>{\sigma(i)}(c_i) +1<em>{c_i \neq \phi}\mathcal{L}</em>{box}(b_i, \hat{b}_{\sigma(i)})]</p>

<p>[\mathcal{L}<em>{Hungarian}(y, \hat{y}) = \sum^N_i[-\log\hat{p}</em>{\hat{\sigma}(i)}(c_i) +1<em>{c_i \neq \phi}\mathcal{L}</em>{box}(b_i, \hat{b}_{\hat{\sigma}(i)})]]</p>

<h3 id="bounding-box-loss">Bounding box loss</h3>

<p>[\lambda_{iou}\mathcal{L}<em>{iou}(b_i, \hat{b}</em>{\sigma(i)}) + \lambda_{\mathrm{L}1}|b_i - \hat{b}_{\sigma(i)}|_1]</p>

<h2 id="detr-architecture">DETR architecture</h2>

<h3 id="backbone">Backbone</h3>

<ul>
  <li>일반적인 Backbone 사용.</li>
  <li>마지막 feataure map은 원본 사이즈 H, W 에 비해 32분의 1 downsampling, C는 2048</li>
</ul>

<h3 id="transformer-encoder">Transformer encoder</h3>

<ul>
  <li>Attention is all you need의 Transformer의 encoder와 동일한 구조.</li>
  <li>Fixed positional encodings 으로 인하여 permutation-invariant 한 구조!</li>
</ul>

<h3 id="transformer-decoder">Transformer decoder</h3>

<ul>
  <li>Attention is all you need의 Transformer의 decoder와 동일한 구조.</li>
  <li>기존 Transformer와 차이는</li>
</ul>

<h3 id="prediction-feed-forward-networks-ffns">Prediction feed-forward networks (FFNs)</h3>

<ul>
  <li>ReLU를 사용하는 d dimension의 linear layer 3 개 사용.</li>
  <li>한 branch 에서는 Normalized center coordinate, height, width 를 예측.</li>
  <li>다른 하나의 branch는 class label을 softmax를 이용하여 예측.</li>
  <li>DETR은 항상 N개의 box에 대해 예측. 하지만 실제 object 수가 적을때는 나머지 box들을 no object 로 처리.</li>
</ul>

<h3 id="auxiliary-decoding-losses">Auxiliary decoding losses</h3>

<ul>
  <li>Transformer decoder에  Auxiliary loss 를 추가.</li>
</ul>

<h1 id="experiment">Experiment</h1>

<h2 id="comparison-with-faster-r-cnn">Comparison with Faster R-CNN</h2>

<p><img src="https://jjerry-k.github.io/public/img/DETR/Untitled_2.png" alt="jjerry-k.github.io/public/img/DETR/Untitled_2.png" /></p>

<h2 id="ablations">Ablations</h2>

<p><img src="https://jjerry-k.github.io/public/img/DETR/Untitled_3.png" alt="jjerry-k.github.io/public/img/DETR/Untitled_3.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/DETR/Untitled_4.png" alt="jjerry-k.github.io/public/img/DETR/Untitled_4.png" /></p>

<h2 id="panoptic-segmentation">Panoptic segmentation</h2>

<p><img src="https://jjerry-k.github.io/public/img/DETR/Untitled_5.png" alt="jjerry-k.github.io/public/img/DETR/Untitled_5.png" /></p>

<h2 id="ps">P.S</h2>
<ul>
  <li>내용 보충 예정.</li>
  <li>신박한 컨셉.</li>
</ul>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/06/13/DETR/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/06/13/DETR/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/living/2020/05/31/Dlink_ddns/">
        D-Link ddns 서비스 종료
      </a>
    </h1>

    <span class="post-date">31 May 2020</span>
     | 
    
    <a href="/blog/tags/#hardware" class="post-tag">Hardware</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <p><a href="https://eu.dlink.com/uk/en/products/dir-850l-wireless-ac1200-dual-band-gigabit-cloud-router">D-Link의 DIR-815L</a> 을 잘 쓰고 있었습니다…<br />
라즈베리파이와 연결하여 DDNS 도해놓고..<br />
근데 어느 날 다음과 같은 글이 메일, 공지로 올라오더군요.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>안녕하세요. D-Link Korea 입니다. 저희 dlink 제품군에서 제공되었던 무료 dlinkddns 서비스 종료에 관한 안내 말씀드립니다. 죄송합니다만, dlinkddns 무료 서비스는 기존에 오라클사의 dyn ddns 와의 계약만료일인 2020년 7월 2일 종료될 예정입니다. 이후에는 정상적인 무료 ddns서비스 이용이 불가하니 계속해서 dlinkddns 서비스를 이용하기를 원하실 경우에는 유료상품으로 전환하시기 바랍니다. ■ 유료전환 http://dlinkddns.com 사이트 접속시 유료전환은 안내 팝업과 함께 결재시 50% 할인 메뉴 클릭하여 진행합니다. 이외에 관련해서 궁금한 점이 있으신 분은 D-Link Korea 고객센터(1899-3540)로 문의하시기 바랍니다. 기존 무료로 지원되던 dlinkddns 서비스 종료에, 앞으로 더욱 나은 서비스로 보답하겠습니다. 감사합니다.
</code></pre></div></div>

<p>What the…?<br />
후… 공유기를 새로 사던 DDNS 서비스를 이용하던 해야겠네요.<br />
디자인이랑 DDNS 때문에 샀는데.. 젠장.. 앞으론 그냥 Iptime 쓸래요.</p>

    <article></h4>
    <div class="post-more">
      
      <a href="/living/2020/05/31/Dlink_ddns/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/living/2020/05/31/Dlink_ddns/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/05/09/ShuffleNetV2/">
        Review: ShuffleNetV2
      </a>
    </h1>

    <span class="post-date">09 May 2020</span>
     | 
    
    <a href="/blog/tags/#paper" class="post-tag">Paper</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <h1 id="shufflenet-v2-practical-guidelines-for-efficient-cnn-architecture-design">ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design</h1>

<p>Author: Ningning Ma, Xiangyu Zhang, Hai-Tao Zheng, Jian Sun<br />
Date: Jul 30, 2018<br />
URL: https://arxiv.org/abs/1807.11164</p>

<h1 id="introduction">Introduction</h1>

<ul>
  <li>CNN 계열이 AlexNet 부터 정확도, 속도가 많이 발전하고 있음.</li>
  <li>실제로는 제한된 컴퓨팅 파워에서(Mobile과 같은) 최고의 성능을 내는데 목표로 하고 있음.</li>
  <li>이로 인해 Xception, MobileNet, ShuffleNet 등이 개발 되었음.</li>
  <li>지금까지는 모델의 연산량을 이용하여 모델의 효율성을 판단하였으나 적합한 지표가 아님을 주장.</li>
  <li>FLOPs와 speed 간의 성능 비교가 옳지 않은 주요 이유가 두 가지.
    <ul>
      <li>memory access cost(MAC): 메모리 접근량(사용량)</li>
      <li>depending on the platform</li>
    </ul>
  </li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled.png" /></p>

<h1 id="practical-guidelines-for-ecient-network-design">Practical Guidelines for Ecient Network Design</h1>

<ul>
  <li>본 연구는 GPU 하드웨어(1080ti), ARM 하드웨어(Snapdragon 810) 이 두 가지 환경에서 실험.</li>
  <li>모델의 Runtime을 쪼개보면 다음과 같은 차트가 그려짐.</li>
  <li>FLOPs는 Convolution 에 대해 설명하기 떄문에 비교 지표로 적절하지 못함을 강조.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_1.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_1.png" /></p>

<ul>
  <li>위 문제를 근거로 다음과 같이 여러 개의 가이드 라인을 제시.</li>
</ul>

<h2 id="g1-equal-channel-width-minimizes-memory-access-cost-mac">G1) Equal channel width minimizes memory access cost (MAC)</h2>

<ul>
  <li>근래에 많이 사용되는 depthwise separable convoltuion에서 연산량의 대부분은 pointwise convolution 이 차지.</li>
  <li>1x1 convolution 이 차지하는 연산량은 다음과 같음.</li>
</ul>

<p>[h, w: \text{the spatial size of the input feature map} \ c_1, c_2: \text{Number of channels about input and output } \ B=hwc_1c_2, \text{ FLOPs of the }1 \times 1 \text{ convolution}]</p>

<ul>
  <li>현 상황에서 MAC의 수식은 다음과 같음.</li>
</ul>

<p>[MAC = hw(c_1+c_2) +c_1c_2 = hwc_1 + hwc_2 + c_1c_2 \ hwc_1: \text{Number of input feature map’s element} \ hwc_2: \text{Number of output feature map’s element} \ c_1c_2: \text{Number of filter’s element}]</p>

<ul>
  <li>MAC의 lower bound 는 다음과 같음.</li>
</ul>

<p>[MAC \ge 2\sqrt{hwB} + \frac{B}{hw} \to 2hw\sqrt{c_1c_2} + c_1c_2]</p>

<ul>
  <li>$c_1 = c_2$ 이면 MAC가 최소.</li>
  <li>전체 연산량은 고정해놓고 $c_1:c_2$의 비율을 바꿔가면서 runtime 비교.</li>
  <li>1:1일때가 가장 빠른 성능을 보임.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_2.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_2.png" /></p>

<blockquote>
  <p><em>It reaches the lower bound when the numbers of input and output channels are equal.</em></p>
</blockquote>

<h2 id="g2-excessive-group-convolution-increases-mac">G2) Excessive group convolution increases MAC</h2>

<ul>
  <li>Group convolution 이 많은 네트워크의 핵심이지만 Groups가 커지면 MAC을 증가시킴. → 안쓸 수는 없으니 적당히 쓰는게 좋다.</li>
  <li>그룹에 따라 연산량이 줄어들기 때문에 B는 다음과 같음.</li>
</ul>

<p>[B=hwc_1c_2/g]</p>

<p>[MAC = hw(c_1+c_2) + \frac{c_1c_2}{g} \ = hwc_1 + hwc_2 + \frac{c_1c_2}{g} \ = hwc_1 + \frac{Bg}{c_1} + \frac{B}{hw}]</p>

<ul>
  <li>Groups 에 따라 runtime 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_3.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_3.png" /></p>

<blockquote>
  <p><em>The group number should be carefully chosen based on the target platform and task. It is unwise to use a large group number simply because this may enable using more channels, because the benet of accuracy increase can easily be outweighed by the rapidly increasing computational cost.</em></p>
</blockquote>

<h2 id="g3-network-fragmentation-reduces-degree-of-parallelism">G3) Network fragmentation reduces degree of parallelism</h2>

<ul>
  <li>Inception 과 같이 여러 branch를 parallel하게 구성할 경우 성능은 좋아졌지만 효율성은 감소시킴. → GPU 같은 자원에는 어울리지 않음.</li>
  <li>Fragmentation 에 따른 runtime 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_4.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_4.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_5.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_5.png" /></p>

<blockquote>
  <p><em>Fragmented structure has been shown benecial for accuracy, it could decrease eciency because it is unfriendly for devices with strong parallel computing powers like GPU. It also introduces extra overheads such as kernel launching and synchronization.</em></p>
</blockquote>

<h2 id="g4-element-wise-operations-are-non-negligible">G4) Element-wise operations are non-negligible</h2>

<ul>
  <li>Activation, Add 와 같은 Element-wise operation들의 비율이 꽤 존재. Figure 2 참고</li>
  <li>이 연산은 FLOPs는 적지만 상대적으로 MAC은 큼.</li>
  <li>
    <p>Depthwise convolution 또한 element-wise 여서 MAC/FLOPs 가 클 것이라 생각.</p>
  </li>
  <li>각 상황에 대한 runtime 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_6.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_6.png" /></p>

<blockquote>
  <p><em>We observe around 20% speedup is obtained on both GPU and ARM, after ReLU and shortcut are removed.</em></p>
</blockquote>

<h2 id="conclusion-and-discussions">Conclusion and Discussions</h2>

<ol>
  <li>use “balanced convolutions (equal channel width);</li>
  <li>be aware of the cost of using group convolution;</li>
  <li>reduce the degree of fragmentation;</li>
  <li>reduce element-wise operations.</li>
</ol>

<ul>
  <li>다른 네트워크들에 대한 고찰
    <ul>
      <li>ShuffleNet V1
        <ul>
          <li>Heavily group convolutions → G2</li>
          <li>Bottleneck-like building blocks → G1</li>
          <li>Residual Block → G3</li>
          <li>Element-wise operation→ G4</li>
        </ul>
      </li>
      <li>MobileNet V2
        <ul>
          <li>Inverted bottleneck structure → G1</li>
        </ul>
      </li>
      <li>Depthwise convolution &amp; ReLU
        <ul>
          <li>Element-wise operation → G4</li>
        </ul>
      </li>
      <li>NAS
        <ul>
          <li>Highly fragmentation → G3</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h1 id="shuenet-v2-an-ecient-architecture">ShueNet V2: an Ecient Architecture</h1>

<h2 id="review-of-shuenet-v1">Review of ShueNet v1</h2>

<ul>
  <li>G1, G2, G3, G4 모두 지키지 않음.</li>
  <li>이를 해결한 구조가 ShuffleNet V2 의 유닛 (Fig 3 (c), Fig 3 (d))</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_7.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_7.png" /></p>

<h2 id="channel-split-and-shuenet-v2">Channel Split and ShueNet V2</h2>

<ul>
  <li>Fig 3 (c)
    <ul>
      <li>Input feature 을 절반으로 나눠 두개의 branch 생성.</li>
      <li>Left branch는 아무 연산도 진행 X. → G3 에 대한 회피법.</li>
      <li>Right branch는 동일한 Number of filter로 1x1 Conv → 3x3 DWConv → 1x1 Conv 수행. → G1에 대한 회피법.</li>
      <li>1x1 Conv 는 Group 을 나누지 않음 → G2에 대한 회피법.</li>
      <li>Residual Block의 Add operation 을 Concatenate 로 변경 → G4에 대한 회피법.</li>
    </ul>
  </li>
  <li>Fig 3 (d)
    <ul>
      <li>Downsampling block</li>
      <li>Input feature 그대로 두개의 branch 생성.</li>
      <li>Number of filter는 모두 동일</li>
    </ul>
  </li>
  <li>네트워크 구조</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_8.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_8.png" /></p>

<h2 id="analysis-of-network-accuracy">Analysis of Network Accuracy</h2>

<ul>
  <li>ShuffleNet V2는 효율적이며 성능도 좋음.
    <ul>
      <li>더 많은 channel, 더 큰 network를 만들 수 있음.</li>
      <li>DenseNet 이나 CondenseNet 처럼 feature reuse 과 매우 유사함.</li>
    </ul>
  </li>
  <li>DenseNet의 feature reuse 패턴과 ShuffleNet V2의 feature reuse 패턴 비교.</li>
  <li>붉을 수록 Source layer와 Target layer의 연결성이 강하다는 의미.</li>
  <li>DenseNet과 같이 ShuffleNet V2에서도 Target layer가 멀어질 수록 연결성이 약함.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_9.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_9.png" /></p>

<h1 id="experiment">Experiment</h1>

<ul>
  <li>총 4개의 모델과 비교.
    <ul>
      <li>ShuffleNet V1</li>
      <li>MobileNet V2</li>
      <li>Xception</li>
      <li>DenseNet</li>
    </ul>
  </li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_10.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_10.png" /></p>

<h3 id="accuracy-vs-flops">Accuracy vs. FLOPs</h3>

<ul>
  <li>연산량을 40 MFLOPs 로 고정시키고 Network 를 구성한 후 성능 비교. (Table 8 상단)</li>
</ul>

<h3 id="inference-speed-vs-flopsaccuracy">Inference Speed vs. FLOPs/Accuracy</h3>

<ul>
  <li>연산량을 특정 값 범위로 고정시키고 runtime 비교. (Fig 1 참조)</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_11.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_11.png" /></p>

<h3 id="compared-with-mobilenet-v1">Compared with MobileNet v1</h3>

<ul>
  <li>MobileNet V1의 경우 Accuracy가 좋지 않으나  GPU runtime은 가장 빠름.</li>
  <li>이는 위에서 제시한 가이드 라인을 어느 정도 가장 잘 만족하기 때문.</li>
</ul>

<h3 id="compared-automatic-model-search">Compared automatic model search</h3>

<ul>
  <li>NAS 는 매우 느리지만 제시한 가이드 라인을 만족하고 speed에 대한 metric을 사용한다면 충분히 좋은 성능을 보일 것.</li>
</ul>

<h3 id="compatibility-with-other-methods">Compatibility with other methods</h3>

<ul>
  <li>Squeeze-and-excitation 과 같은 module과 같이 사용할 수 있음.</li>
  <li>속도는 떨어지나 정확도는 상승. (Table 8 하단)</li>
</ul>

<h3 id="generalization-to-large-models">Generalization to Large Models</h3>

<ul>
  <li>2GFLOPs 이상의 큰 모델을 생성할 수 있음.</li>
  <li>50개의 레이어를 가진 모델을 생성해도 ResNet-50 과 비교하여 적은 연산량, 뛰어난 성능을 보임. (Table 6 상단)</li>
  <li>SE module, residual block을 사용하여 더욱 깊게 만들어도 상대적으로 연산량이 적으면서 뛰어난 성능을 보임. (Table 6 하단)</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_12.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_12.png" /></p>

<h3 id="object-detection">Object Detection</h3>

<ul>
  <li><a href="https://arxiv.org/abs/1711.07264">Light-Head RCNN</a> 사용.</li>
  <li>Classification 에서 성능이 별로였던 Xception 이 Detection 에선 성능이 좋음. → Receptive Field가 크기 때문이라고 생각.</li>
  <li>3x3 depthwise convolution 을 추가하여 Receptive Field를 키워보니 (ShuffleNet V2*) runtime은 늘었으나 성능이 증가함.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_13.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_13.png" /></p>

<h2 id="ps">P.S</h2>

<ul>
  <li>어려웠다.</li>
  <li>항상 가이드 라인을 지키면서 모델을 설계할 수 있을까?</li>
</ul>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/05/09/ShuffleNetV2/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/05/09/ShuffleNetV2/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/blog/page4">Older</a>
  
  
    
      <a class="pagination-item newer" href="/blog/page2">Newer</a>
    
  
</div>


        </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <!-- Modal -->
  <div class="modal fade" id="myModal" role="dialog">
    <div class="modal-dialog">

      <!-- Modal content-->
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal">&times;</button>
          <h4 class="modal-title">Search</h4>
        </div>
        <div class="modal-body">

    <h4><div id="search-container">
      <input type="text" id="search-input" placeholder="검색어 입력" class="input" style="font-size: 1rem; width: 100%; padding: 10px; border: 0px; outline: none; float: left; background: #cecece;" autofocus>
    </div></h4><br>

      <div id="results">
        <h1></h1>
      <ul class="results"></ul>
      </div>
      <br><ul id="results-container"></ul>
    </div>

<!-- Script pointing to jekyll-search.js -->


<script type="text/javascript">
      SimpleJekyllSearch({
        searchInput: document.getElementById('search-input'),
        resultsContainer: document.getElementById('results-container'),
        json: '/dest/search.json',
        searchResultTemplate: '<h4 style="margin-bottom:-0.5rem;"><a class="post-title" style="color:#ac4142;" href="{url}" title="{desc}">{title}</a> <small>{category}</small></h4>',
        noResultsText: '<h4><br>문서가 존재하지 않습니다.</h4>',
        limit: 15,
        fuzzy: false,
        exclude: ['Welcome']
      })
</script>
        </div>
      </div>

    </div>
  </div>

</div>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');
        document.addEventListener('click', function(e) {
          var target = e.target;
          if (target === toggle) {
            checkbox.checked = !checkbox.checked;
            e.preventDefault();
          } else if (checkbox.checked && !sidebar.contains(target)) {
            /* click outside the sidebar when sidebar is open */
            checkbox.checked = false;
          }
        }, false);
      })(document);
    </script>

    
      <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-126636477-1', 'auto');
        ga('send', 'pageview');
      </script>
    

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (absbygoogle = window.adsbygoogle || []).push({
          google_ad_client: "ca-pub-1054696837285307",
          enable_page_level_ads: true
      });
    </script>
  </body>
  
  <script id="dsq-count-scr" src="//jerry.disqus.com/count.js" async></script>
  
</html>
