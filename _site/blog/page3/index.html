<!DOCTYPE html>
<html lang="en-us">
  <head>
  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Blog &middot; Jerry's Blog
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">
  <link rel="stylesheet" href="/public/css/main.css">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <!-- scroll -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script>
    $( window ).scroll( function() {
      if ( $( this ).scrollTop() > 500 ) {
        $( '.top' ).fadeIn();
      } else {
        $( '.top' ).fadeOut();
      }
    } );
    $( '.top' ).click( function() {
      $( 'html, body' ).stop().animate( { scrollTop : 0 }, 100);
      return false;
    } );
  </script>
  
  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
    (absbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-1054696837285307",
        enable_page_level_ads: true
    });
  </script>
  
  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      //jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$'] ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
      //,
      //displayAlign: "left",
      //displayIndent: "2em"
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
  
  
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
  <script src="/dest/simple-jekyll-search.js" type="text/javascript"></script>
  <script type="text/javascript">
  $(document).ready(function(){
    document.search.searchinput.focus();
  });
  </script>
</head>

  <style>blockquote {font-size: 1em; line-height: 1.4}</style>
  </head>
  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <div class="sidebar-personal-info">
      <div class="sidebar-personal-info-section">
        <a href="https://gravatar.com/22a6447c0c965de55f4ce9691aed2af4">
          <img src="https://www.gravatar.com/avatar/22a6447c0c965de55f4ce9691aed2af4?s=350" title="View on Gravatar" alt="View on Gravatar" />
        </a>
      </div>
      <div class="sidebar-personal-info-section">
        <p></p>
      </div>
      
      
      
      <div class="sidebar-personal-info-section">
        <p> Follow me  :  
        
        
        
        <a href="https://github.com/jjerry-k">
          <i class="fa fa-github" aria-hidden="true"></i>
        </a>
        
        |
        
        
        
        <a href="https://www.facebook.com/jerry.kim.566">
          <i class="fa fa-facebook" aria-hidden="true"></i>
        </a>
        
        |
        
        
        
        <a href="mailto:jaeyeol2931@gmail.com">
          <i class="fa fa-envelope" aria-hidden="true"></i>
        </a>
        
        
        
        </p>
      </div>
      
    </div>
  </div>

  <nav class="sidebar-nav">
    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/">
          Home
        </a>

        
      </span>

    
      
      
      

      

      <span class="foldable">
        <a class="sidebar-nav-item " href="/blog/">
          Contents
        </a>

        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/blog/">
                Blog
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/python/">
                Python
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/ubuntu/">
                Ubuntu
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/living/">
                Living
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/deeplearning/">
                Deep Learning
              </a>
          
        
      </span>

    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/about/">
          About
        </a>

        
      </span>

    

  </nav>

  <div class="sidebar-item">
    <p>
    &copy; 2020 Jerry. This work is liscensed under <a href="http://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a>.
    </p>
  </div>

  <div class="sidebar-item">
    <p>
    Powered by <a href="http://jekyllrb.com">jekyll</a>
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
          <div class="top" style="position:fixed; right:10%; bottom:15px; display:none; z-index:9999;">
            <a href="#">
              <img src="https://jjerry-k.github.io/public/top.png" width="40" height="40" class="top" style="border-radius:5px; background-color: #000; margin-bottom:0; margin-right:7px; float:left;">
            </a>
            
            <a href="/blog//">
              <img src="https://jjerry-k.github.io/public/contents.png" width="40" height="40" class="top" style="border-radius:5px; background-color: #000; margin-bottom:0; float:left;">
            </a>
          </div>
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title" align="center">
            <a href="/" title="Home" title="Jerry's Blog">
              <img class="masthead-logo" src="/public/logo.png"/>
            </a>
            <small></small>
            <a href="https://donaricano.com/mypage/1391188679_guPzXC" target="_blank">
              <img src="https://d1u4yishnma8v5.cloudfront.net/mobile-gift.png" width="60" height="60" style="position:absolute; top:0.25rem; right:4rem" alt="donaricano-btn" style="height: 130px !important;width: 130px !important;" />
            </a>
            <img src="http://jjerry-k.github.io/public/search.png" width="20" height="20" style="position:absolute; top:1.3rem; right:1.5rem" data-toggle="modal" data-target="#myModal">
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/06/13/DETR/">
        Review: DETR
      </a>
    </h1>

    <span class="post-date">13 Jun 2020</span>
     | 
    
    <a href="/blog/tags/#paper" class="post-tag">Paper</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <h1 id="end-to-end-object-detection-with-transformers">End-to-End Object Detection with Transformers</h1>

<p>Author: Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, and Sergey Zagoruyko
Date: May 27, 2020
URL: https://ai.facebook.com/research/publications/end-to-end-object-detection-with-transformers</p>

<h1 id="introduction">Introduction</h1>

<ul>
  <li>현재 Object detection model들은 Input부터 Output (bounding bos, category label) 까지 Direct 하지 못함.  Post processing 이 영향을 끼치기 때문에…</li>
  <li>본 논문에선 Direct prediction approach 제안.</li>
  <li>이전에도 몇몇 실험이 있었으나 그 당시에는 prior knowledge를 준다거나 성능이 별로 좋지 못했음.</li>
  <li><a href="https://arxiv.org/abs/1706.03762">Transformer</a> 를 사용.</li>
  <li>새로운 Loss function 도입.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/DETR/Untitled.png" alt="jjerry-k.github.io/public/img/DETR/Untitled.png" /></p>

<h1 id="related-works">Related Works</h1>

<h2 id="set-prediction">Set Prediction</h2>

<ul>
  <li>현재까지 Direct로 set(box, class)을 prediction 하는 방법이 없음.</li>
  <li>Post processing 이 없는 model 제안.</li>
  <li>이를 위해 Hungarian algorithm 기반의 loss 설계.</li>
</ul>

<h2 id="transformers-and-parallel-decoding">Transformers and Parallel Decoding</h2>

<ul>
  <li>다른 RNN 계열보다 Long sequence 에 적합한 model</li>
  <li>auto-regressive model</li>
</ul>

<h2 id="object-detection">Object detection</h2>

<h3 id="set-based-loss">Set-based loss</h3>

<ul>
  <li>기존에 bipatite matching loss 를 사용했지만  NMS 를 사용해야 성능이 향상되었음.</li>
  <li>그 후 Learnable NMS 를 사용한 방법이 제시 되었으나 hand-crafted context feature 를 사용 하기에 효율적이지 못함.</li>
</ul>

<h3 id="recurrent-detectors">Recurrent detectors</h3>

<ul>
  <li>이름에서 알 수 있듯 RNN 계열을 도입한 Object detection</li>
  <li>기존 방법에선 Small dataset을 이용했고 RNN 계열을 이용했기에 parallel 구조를 가져가지 못했음.</li>
</ul>

<h1 id="the-detr-model">The DETR model</h1>

<ul>
  <li>DETR은 크게 두 개의 장점이 있음. → a set prediction loss, a architecture</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/DETR/Untitled_1.png" alt="jjerry-k.github.io/public/img/DETR/Untitled_1.png" /></p>

<h2 id="object-detection-set-prediction-loss">Object detection set prediction loss</h2>

<script type="math/tex; mode=display">\hat{\sigma} = {argmin}_{\sigma \in \mathfrak{S}_N} \sum^N_i \mathcal{L}_{match}(y_i, \hat{y}_{\sigma(i)})</script>

<script type="math/tex; mode=display">\mathcal{L}_{match}(y_i, \hat{y}_{\sigma(i)}) = -1_{c_i \neq \phi}\hat{p}_{\sigma(i)}(c_i) +1_{c_i \neq \phi}\mathcal{L}_{box}(b_i, \hat{b}_{\sigma(i)})</script>

<script type="math/tex; mode=display">\mathcal{L}_{Hungarian}(y, \hat{y}) = \sum^N_i[-\log\hat{p}_{\hat{\sigma}(i)}(c_i) +1_{c_i \neq \phi}\mathcal{L}_{box}(b_i, \hat{b}_{\hat{\sigma}(i)})]</script>

<h3 id="bounding-box-loss">Bounding box loss</h3>

<script type="math/tex; mode=display">\lambda_{iou}\mathcal{L}_{iou}(b_i, \hat{b}_{\sigma(i)}) + \lambda_{\mathrm{L}1}\|b_i - \hat{b}_{\sigma(i)}\|_1</script>

<h2 id="detr-architecture">DETR architecture</h2>

<h3 id="backbone">Backbone</h3>

<ul>
  <li>일반적인 Backbone 사용.</li>
  <li>마지막 feataure map은 원본 사이즈 H, W 에 비해 32분의 1 downsampling, C는 2048</li>
</ul>

<h3 id="transformer-encoder">Transformer encoder</h3>

<ul>
  <li>Attention is all you need의 Transformer의 encoder와 동일한 구조.</li>
  <li>Fixed positional encodings 으로 인하여 permutation-invariant 한 구조!</li>
</ul>

<h3 id="transformer-decoder">Transformer decoder</h3>

<ul>
  <li>Attention is all you need의 Transformer의 decoder와 동일한 구조.</li>
  <li>기존 Transformer와 차이는</li>
</ul>

<h3 id="prediction-feed-forward-networks-ffns">Prediction feed-forward networks (FFNs)</h3>

<ul>
  <li>ReLU를 사용하는 d dimension의 linear layer 3 개 사용.</li>
  <li>한 branch 에서는 Normalized center coordinate, height, width 를 예측.</li>
  <li>다른 하나의 branch는 class label을 softmax를 이용하여 예측.</li>
  <li>DETR은 항상 N개의 box에 대해 예측. 하지만 실제 object 수가 적을때는 나머지 box들을 no object 로 처리.</li>
</ul>

<h3 id="auxiliary-decoding-losses">Auxiliary decoding losses</h3>

<ul>
  <li>Transformer decoder에  Auxiliary loss 를 추가.</li>
</ul>

<h1 id="experiment">Experiment</h1>

<h2 id="comparison-with-faster-r-cnn">Comparison with Faster R-CNN</h2>

<p><img src="https://jjerry-k.github.io/public/img/DETR/Untitled_2.png" alt="jjerry-k.github.io/public/img/DETR/Untitled_2.png" /></p>

<h2 id="ablations">Ablations</h2>

<p><img src="https://jjerry-k.github.io/public/img/DETR/Untitled_3.png" alt="jjerry-k.github.io/public/img/DETR/Untitled_3.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/DETR/Untitled_4.png" alt="jjerry-k.github.io/public/img/DETR/Untitled_4.png" /></p>

<h2 id="panoptic-segmentation">Panoptic segmentation</h2>

<p><img src="https://jjerry-k.github.io/public/img/DETR/Untitled_5.png" alt="jjerry-k.github.io/public/img/DETR/Untitled_5.png" /></p>

<h2 id="ps">P.S</h2>
<ul>
  <li>내용 보충 예정.</li>
  <li>신박한 컨셉.</li>
</ul>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/06/13/DETR/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/06/13/DETR/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/living/2020/05/31/Dlink_ddns/">
        D-Link ddns 서비스 종료
      </a>
    </h1>

    <span class="post-date">31 May 2020</span>
     | 
    
    <a href="/blog/tags/#hardware" class="post-tag">Hardware</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <p><a href="https://eu.dlink.com/uk/en/products/dir-850l-wireless-ac1200-dual-band-gigabit-cloud-router">D-Link의 DIR-815L</a> 을 잘 쓰고 있었습니다…<br />
라즈베리파이와 연결하여 DDNS 도해놓고..<br />
근데 어느 날 다음과 같은 글이 메일, 공지로 올라오더군요.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>안녕하세요. D-Link Korea 입니다. 저희 dlink 제품군에서 제공되었던 무료 dlinkddns 서비스 종료에 관한 안내 말씀드립니다. 죄송합니다만, dlinkddns 무료 서비스는 기존에 오라클사의 dyn ddns 와의 계약만료일인 2020년 7월 2일 종료될 예정입니다. 이후에는 정상적인 무료 ddns서비스 이용이 불가하니 계속해서 dlinkddns 서비스를 이용하기를 원하실 경우에는 유료상품으로 전환하시기 바랍니다. ■ 유료전환 http://dlinkddns.com 사이트 접속시 유료전환은 안내 팝업과 함께 결재시 50% 할인 메뉴 클릭하여 진행합니다. 이외에 관련해서 궁금한 점이 있으신 분은 D-Link Korea 고객센터(1899-3540)로 문의하시기 바랍니다. 기존 무료로 지원되던 dlinkddns 서비스 종료에, 앞으로 더욱 나은 서비스로 보답하겠습니다. 감사합니다.
</code></pre></div></div>

<p>What the…?<br />
후… 공유기를 새로 사던 DDNS 서비스를 이용하던 해야겠네요.<br />
디자인이랑 DDNS 때문에 샀는데.. 젠장.. 앞으론 그냥 Iptime 쓸래요.</p>

    <article></h4>
    <div class="post-more">
      
      <a href="/living/2020/05/31/Dlink_ddns/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/living/2020/05/31/Dlink_ddns/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/05/09/ShuffleNetV2/">
        Review: ShuffleNetV2
      </a>
    </h1>

    <span class="post-date">09 May 2020</span>
     | 
    
    <a href="/blog/tags/#paper" class="post-tag">Paper</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <h1 id="shufflenet-v2-practical-guidelines-for-efficient-cnn-architecture-design">ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design</h1>

<p>Author: Ningning Ma, Xiangyu Zhang, Hai-Tao Zheng, Jian Sun<br />
Date: Jul 30, 2018<br />
URL: https://arxiv.org/abs/1807.11164</p>

<h1 id="introduction">Introduction</h1>

<ul>
  <li>CNN 계열이 AlexNet 부터 정확도, 속도가 많이 발전하고 있음.</li>
  <li>실제로는 제한된 컴퓨팅 파워에서(Mobile과 같은) 최고의 성능을 내는데 목표로 하고 있음.</li>
  <li>이로 인해 Xception, MobileNet, ShuffleNet 등이 개발 되었음.</li>
  <li>지금까지는 모델의 연산량을 이용하여 모델의 효율성을 판단하였으나 적합한 지표가 아님을 주장.</li>
  <li>FLOPs와 speed 간의 성능 비교가 옳지 않은 주요 이유가 두 가지.
    <ul>
      <li>memory access cost(MAC): 메모리 접근량(사용량)</li>
      <li>depending on the platform</li>
    </ul>
  </li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled.png" /></p>

<h1 id="practical-guidelines-for-ecient-network-design">Practical Guidelines for Ecient Network Design</h1>

<ul>
  <li>본 연구는 GPU 하드웨어(1080ti), ARM 하드웨어(Snapdragon 810) 이 두 가지 환경에서 실험.</li>
  <li>모델의 Runtime을 쪼개보면 다음과 같은 차트가 그려짐.</li>
  <li>FLOPs는 Convolution 에 대해 설명하기 떄문에 비교 지표로 적절하지 못함을 강조.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_1.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_1.png" /></p>

<ul>
  <li>위 문제를 근거로 다음과 같이 여러 개의 가이드 라인을 제시.</li>
</ul>

<h2 id="g1-equal-channel-width-minimizes-memory-access-cost-mac">G1) Equal channel width minimizes memory access cost (MAC)</h2>

<ul>
  <li>근래에 많이 사용되는 depthwise separable convoltuion에서 연산량의 대부분은 pointwise convolution 이 차지.</li>
  <li>1x1 convolution 이 차지하는 연산량은 다음과 같음.</li>
</ul>

<script type="math/tex; mode=display">h, w: \text{the spatial size of the input feature map} \\ c_1, c_2: \text{Number of channels about input and output } \\ B=hwc_1c_2, \text{ FLOPs of the }1 \times 1 \text{ convolution}</script>

<ul>
  <li>현 상황에서 MAC의 수식은 다음과 같음.</li>
</ul>

<script type="math/tex; mode=display">MAC = hw(c_1+c_2) +c_1c_2 = hwc_1 + hwc_2 + c_1c_2 \\ hwc_1: \text{Number of input feature map's element} \\ hwc_2: \text{Number of output feature map's element} \\ c_1c_2: \text{Number of filter's element}</script>

<ul>
  <li>MAC의 lower bound 는 다음과 같음.</li>
</ul>

<script type="math/tex; mode=display">MAC \ge 2\sqrt{hwB} + \frac{B}{hw} \to 2hw\sqrt{c_1c_2} + c_1c_2</script>

<ul>
  <li>$c_1 = c_2$ 이면 MAC가 최소.</li>
  <li>전체 연산량은 고정해놓고 $c_1:c_2$의 비율을 바꿔가면서 runtime 비교.</li>
  <li>1:1일때가 가장 빠른 성능을 보임.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_2.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_2.png" /></p>

<blockquote>
  <p><em>It reaches the lower bound when the numbers of input and output channels are equal.</em></p>
</blockquote>

<h2 id="g2-excessive-group-convolution-increases-mac">G2) Excessive group convolution increases MAC</h2>

<ul>
  <li>Group convolution 이 많은 네트워크의 핵심이지만 Groups가 커지면 MAC을 증가시킴. → 안쓸 수는 없으니 적당히 쓰는게 좋다.</li>
  <li>그룹에 따라 연산량이 줄어들기 때문에 B는 다음과 같음.</li>
</ul>

<script type="math/tex; mode=display">B=hwc_1c_2/g</script>

<script type="math/tex; mode=display">MAC = hw(c_1+c_2) + \frac{c_1c_2}{g} \\ = hwc_1 + hwc_2 + \frac{c_1c_2}{g} \\ = hwc_1 + \frac{Bg}{c_1} + \frac{B}{hw}</script>

<ul>
  <li>Groups 에 따라 runtime 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_3.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_3.png" /></p>

<blockquote>
  <p><em>The group number should be carefully chosen based on the target platform and task. It is unwise to use a large group number simply because this may enable using more channels, because the benet of accuracy increase can easily be outweighed by the rapidly increasing computational cost.</em></p>
</blockquote>

<h2 id="g3-network-fragmentation-reduces-degree-of-parallelism">G3) Network fragmentation reduces degree of parallelism</h2>

<ul>
  <li>Inception 과 같이 여러 branch를 parallel하게 구성할 경우 성능은 좋아졌지만 효율성은 감소시킴. → GPU 같은 자원에는 어울리지 않음.</li>
  <li>Fragmentation 에 따른 runtime 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_4.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_4.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_5.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_5.png" /></p>

<blockquote>
  <p><em>Fragmented structure has been shown benecial for accuracy, it could decrease eciency because it is unfriendly for devices with strong parallel computing powers like GPU. It also introduces extra overheads such as kernel launching and synchronization.</em></p>
</blockquote>

<h2 id="g4-element-wise-operations-are-non-negligible">G4) Element-wise operations are non-negligible</h2>

<ul>
  <li>Activation, Add 와 같은 Element-wise operation들의 비율이 꽤 존재. Figure 2 참고</li>
  <li>이 연산은 FLOPs는 적지만 상대적으로 MAC은 큼.</li>
  <li>
    <p>Depthwise convolution 또한 element-wise 여서 MAC/FLOPs 가 클 것이라 생각.</p>
  </li>
  <li>각 상황에 대한 runtime 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_6.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_6.png" /></p>

<blockquote>
  <p><em>We observe around 20% speedup is obtained on both GPU and ARM, after ReLU and shortcut are removed.</em></p>
</blockquote>

<h2 id="conclusion-and-discussions">Conclusion and Discussions</h2>

<ol>
  <li>use “balanced convolutions (equal channel width);</li>
  <li>be aware of the cost of using group convolution;</li>
  <li>reduce the degree of fragmentation;</li>
  <li>reduce element-wise operations.</li>
</ol>

<ul>
  <li>다른 네트워크들에 대한 고찰
    <ul>
      <li>ShuffleNet V1
        <ul>
          <li>Heavily group convolutions → G2</li>
          <li>Bottleneck-like building blocks → G1</li>
          <li>Residual Block → G3</li>
          <li>Element-wise operation→ G4</li>
        </ul>
      </li>
      <li>MobileNet V2
        <ul>
          <li>Inverted bottleneck structure → G1</li>
        </ul>
      </li>
      <li>Depthwise convolution &amp; ReLU
        <ul>
          <li>Element-wise operation → G4</li>
        </ul>
      </li>
      <li>NAS
        <ul>
          <li>Highly fragmentation → G3</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h1 id="shuenet-v2-an-ecient-architecture">ShueNet V2: an Ecient Architecture</h1>

<h2 id="review-of-shuenet-v1">Review of ShueNet v1</h2>

<ul>
  <li>G1, G2, G3, G4 모두 지키지 않음.</li>
  <li>이를 해결한 구조가 ShuffleNet V2 의 유닛 (Fig 3 (c), Fig 3 (d))</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_7.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_7.png" /></p>

<h2 id="channel-split-and-shuenet-v2">Channel Split and ShueNet V2</h2>

<ul>
  <li>Fig 3 (c)
    <ul>
      <li>Input feature 을 절반으로 나눠 두개의 branch 생성.</li>
      <li>Left branch는 아무 연산도 진행 X. → G3 에 대한 회피법.</li>
      <li>Right branch는 동일한 Number of filter로 1x1 Conv → 3x3 DWConv → 1x1 Conv 수행. → G1에 대한 회피법.</li>
      <li>1x1 Conv 는 Group 을 나누지 않음 → G2에 대한 회피법.</li>
      <li>Residual Block의 Add operation 을 Concatenate 로 변경 → G4에 대한 회피법.</li>
    </ul>
  </li>
  <li>Fig 3 (d)
    <ul>
      <li>Downsampling block</li>
      <li>Input feature 그대로 두개의 branch 생성.</li>
      <li>Number of filter는 모두 동일</li>
    </ul>
  </li>
  <li>네트워크 구조</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_8.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_8.png" /></p>

<h2 id="analysis-of-network-accuracy">Analysis of Network Accuracy</h2>

<ul>
  <li>ShuffleNet V2는 효율적이며 성능도 좋음.
    <ul>
      <li>더 많은 channel, 더 큰 network를 만들 수 있음.</li>
      <li>DenseNet 이나 CondenseNet 처럼 feature reuse 과 매우 유사함.</li>
    </ul>
  </li>
  <li>DenseNet의 feature reuse 패턴과 ShuffleNet V2의 feature reuse 패턴 비교.</li>
  <li>붉을 수록 Source layer와 Target layer의 연결성이 강하다는 의미.</li>
  <li>DenseNet과 같이 ShuffleNet V2에서도 Target layer가 멀어질 수록 연결성이 약함.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_9.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_9.png" /></p>

<h1 id="experiment">Experiment</h1>

<ul>
  <li>총 4개의 모델과 비교.
    <ul>
      <li>ShuffleNet V1</li>
      <li>MobileNet V2</li>
      <li>Xception</li>
      <li>DenseNet</li>
    </ul>
  </li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_10.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_10.png" /></p>

<h3 id="accuracy-vs-flops">Accuracy vs. FLOPs</h3>

<ul>
  <li>연산량을 40 MFLOPs 로 고정시키고 Network 를 구성한 후 성능 비교. (Table 8 상단)</li>
</ul>

<h3 id="inference-speed-vs-flopsaccuracy">Inference Speed vs. FLOPs/Accuracy</h3>

<ul>
  <li>연산량을 특정 값 범위로 고정시키고 runtime 비교. (Fig 1 참조)</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_11.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_11.png" /></p>

<h3 id="compared-with-mobilenet-v1">Compared with MobileNet v1</h3>

<ul>
  <li>MobileNet V1의 경우 Accuracy가 좋지 않으나  GPU runtime은 가장 빠름.</li>
  <li>이는 위에서 제시한 가이드 라인을 어느 정도 가장 잘 만족하기 때문.</li>
</ul>

<h3 id="compared-automatic-model-search">Compared automatic model search</h3>

<ul>
  <li>NAS 는 매우 느리지만 제시한 가이드 라인을 만족하고 speed에 대한 metric을 사용한다면 충분히 좋은 성능을 보일 것.</li>
</ul>

<h3 id="compatibility-with-other-methods">Compatibility with other methods</h3>

<ul>
  <li>Squeeze-and-excitation 과 같은 module과 같이 사용할 수 있음.</li>
  <li>속도는 떨어지나 정확도는 상승. (Table 8 하단)</li>
</ul>

<h3 id="generalization-to-large-models">Generalization to Large Models</h3>

<ul>
  <li>2GFLOPs 이상의 큰 모델을 생성할 수 있음.</li>
  <li>50개의 레이어를 가진 모델을 생성해도 ResNet-50 과 비교하여 적은 연산량, 뛰어난 성능을 보임. (Table 6 상단)</li>
  <li>SE module, residual block을 사용하여 더욱 깊게 만들어도 상대적으로 연산량이 적으면서 뛰어난 성능을 보임. (Table 6 하단)</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_12.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_12.png" /></p>

<h3 id="object-detection">Object Detection</h3>

<ul>
  <li><a href="https://arxiv.org/abs/1711.07264">Light-Head RCNN</a> 사용.</li>
  <li>Classification 에서 성능이 별로였던 Xception 이 Detection 에선 성능이 좋음. → Receptive Field가 크기 때문이라고 생각.</li>
  <li>3x3 depthwise convolution 을 추가하여 Receptive Field를 키워보니 (ShuffleNet V2*) runtime은 늘었으나 성능이 증가함.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_13.png" alt="https://jjerry-k.github.io/public/img/shufflenetv2/Untitled_13.png" /></p>

<h2 id="ps">P.S</h2>

<ul>
  <li>어려웠다.</li>
  <li>항상 가이드 라인을 지키면서 모델을 설계할 수 있을까?</li>
</ul>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/05/09/ShuffleNetV2/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/05/09/ShuffleNetV2/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/05/08/ResNeXt/">
        Review: ResNeXt
      </a>
    </h1>

    <span class="post-date">08 May 2020</span>
     | 
    
    <a href="/blog/tags/#paper" class="post-tag">Paper</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <h1 id="aggregated-residual-transformations-for-deep-neural-networks">Aggregated Residual Transformations for Deep Neural Networks</h1>

<p>Author: Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, Kaiming He<br />
Date: Nov 16, 2016<br />
URL: https://arxiv.org/abs/1611.05431</p>

<h1 id="introduction">Introduction</h1>

<ul>
  <li>Network desine 에 고려해야할 hyper-parameter가 너무 많음. (Width, filter size, Height, ….)</li>
  <li>VGG, ResNet은 비슷한 구조의 레이어를 계속 쌓는 방법을 사용.</li>
  <li>Inception 은 성능은 이전보다 뛰어나지만 이전 방법들과 다르게 복잡한 구조를 쌓는 방법 사용.</li>
  <li>본 논문에서는 VGG/ResNet과 같이 비슷한 레이어를 반복하지만 AlexNet 에서 나온 처음 제안된 Group Convolution 을 적용하여 split-transform-merge stretegy 를 도입.</li>
  <li>일반적인 Reidual Block과 ResNeXt의 Residual Block 비교.</li>
  <li>Cardinality = Number of Groups,</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled.png" /></p>

<h1 id="method">Method</h1>

<h2 id="template">Template</h2>

<ul>
  <li>전체적인 구조는 기존의 VGG/ResNet과 같이 일정 Block 을 반복하여 쌓는 구조.</li>
  <li>반복되는 블럭은 동일한 hyper parameter 사용.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_1.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_1.png" /></p>

<h2 id="revisiting-simple-neurons">Revisiting Simple Neurons</h2>

<ul>
  <li>가장 기본적인 뉴런의 구조</li>
</ul>

<script type="math/tex; mode=display">\sum_{i=1}^Dw_ix_i</script>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_2.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_2.png" /></p>

<ul>
  <li>기본 뉴런 또한 split-transform-merge (Splitting, Transforming, Aggregating)의 구조를 가짐.</li>
  <li>Vector X 가 $x_i$로 Splitting, $x_iw_i$로 Transforming, $\sum_{i=1}^D$ 로 Aggregating</li>
</ul>

<h2 id="aggregated-transformations">Aggregated Transformations</h2>

<ul>
  <li>Networt-in-Network와 다르게 Network-in-Neuron이라는 컨셉으로 차원 확장</li>
</ul>

<script type="math/tex; mode=display">\mathcal{F}(x) = \sum_{i=1}^C\mathcal{T}_i(\mathrm{x})</script>

<ul>
  <li>다른 방식이지만 동일하다는 것을 설명</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_3.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_3.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_4.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_4.png" /></p>

<h2 id="model-capacity">Model Capacity</h2>

<ul>
  <li>Complexity, Number of parameter 를 유지하면서 실험.</li>
  <li>다른 Hyper parameter는 수정하고 싶지 않기 때문에 Residual Block의 Cardinality C와 bottleneck d를 수정</li>
  <li>Cardinality와 bottleneck d의 관계</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_5.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_5.png" /></p>

<h1 id="result">Result</h1>

<h2 id="on-imagenet-1k">On ImageNet-1K</h2>

<ul>
  <li>Cardinality를 1~32 씩 증가시키되 complexity 는 유지하도록 설정하고 실험.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_6.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_6.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_7.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_7.png" /></p>

<ul>
  <li>Increasing Cardinality 와  Increasing depth or width 비교</li>
  <li>Cardinality 의 성능이 더 좋음.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_8.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_8.png" /></p>

<ul>
  <li>Residual connections 여부에 따른 비교</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_9.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_9.png" /></p>

<ul>
  <li>State-of-the-art model 과 비교</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_10.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_10.png" /></p>

<h2 id="on-imagenet-5k">On ImageNet-5K</h2>

<ul>
  <li>5000개 클래스에서도 잘 되더라.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_11.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_11.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_12.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_12.png" /></p>

<h2 id="on-cifar">On CIFAR</h2>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_13.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_13.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_14.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_14.png" /></p>

<h2 id="on-coco-object-detection">On COCO object detection</h2>

<ul>
  <li>Faster RCNN에 적용.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/resnext/Untitled_15.png" alt="https://jjerry-k.github.io/public/img/resnext/Untitled_15.png" /></p>

<h2 id="ps">P.S</h2>

<ul>
  <li>AlexNet의 선견지명.</li>
  <li>하긴 안좋으면 논문으로 쓸리가 없지.</li>
</ul>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/05/08/ResNeXt/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/05/08/ResNeXt/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/05/07/ShuffleNetV1/">
        Review: ShuffleNetV1
      </a>
    </h1>

    <span class="post-date">07 May 2020</span>
     | 
    
    <a href="/blog/tags/#paper" class="post-tag">Paper</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <h1 id="shufflenet-an-extremely-efficient-convolutional-neural-network-for-mobile-devices">ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices</h1>

<p>Author: Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, Jian Sun<br />
Date: Jul 04, 2017<br />
URL: https://arxiv.org/abs/1707.01083</p>

<h1 id="introduction">Introduction</h1>

<ul>
  <li>Visual recognition 에서 deeper, larger CNN을 설계하는 것이 트렌드.</li>
  <li>하지만 이는 매우 많은 연산량을 필요로함.</li>
  <li>본 논문은 정해놓은 범위의 연산량에서 최고로 효율적인 구조는 찾아내는 것을 목표로 함.</li>
  <li>Xception, ResNeXt 에서 1x1 Convolution 을 사용하는데 두 네트워크에서 대부분의 연산량이 1x1 Convolution 이 차지하고 있어 비효율적.</li>
  <li>이를 보완하기 위해 AlexNet에서 처음 제안한 group convolution 적용.</li>
  <li>Group convolution 의 단점을 보완하기 위해 channel shuffle operation 또한 제안.</li>
</ul>

<h1 id="method">Method</h1>

<h2 id="channel-shuffle-for-group-convolutions">Channel Shuffle for Group Convolutions</h2>

<ul>
  <li>상대적으로 연산량이 많은 1x1 Convolution을 ResNeXt 에서 사용한 Group Convolution 으로 적용.</li>
  <li>하지만 Group으로 계속 진행하다보면 특정 채널에 편향된 결과를 보이는 문제가 생길 것이므로 channel을 shuffle 해줌.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled.png" /></p>

<h2 id="shufflenet-unit">ShuffleNet Unit</h2>

<ul>
  <li>ShuffleNet에서 사용된 Bottle unit은 Xception과 MobileNet에서 사용된 Residual Block에서 1x1 Convolution을 Group Convolution으로 변경하고 Channel Shuffle을 추가한 것.</li>
  <li>Stride unit 에선 element-wise addition이 아닌 concatenation으로 대체.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_1.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_1.png" /></p>

<h2 id="network-architecture">Network Architecture</h2>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_2.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_2.png" /></p>

<h1 id="result">Result</h1>

<h2 id="ablation-study">Ablation Study</h2>

<h3 id="pointwise-group-convolutions">Pointwise Group Convolutions</h3>

<ul>
  <li>Groups 에 따른 성능 비교.</li>
  <li>
    <p>ShuffleNet s$\times$ 에서 s는 필터 개수에 대한 scaling factor.</p>
  </li>
  <li>무조건 많이 나눈다고 좋은 것은 아님.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_3.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_3.png" /></p>

<h3 id="channel-shuffle-vs-no-shuffle">Channel Shuffle vs. No Shuffle</h3>

<ul>
  <li>Channel Shuffle 여부에 따른 성능 비교.</li>
  <li>Shuffle 적용시 성능이 뚜렷하게 증가한 것을 확인.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_4.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_4.png" /></p>

<h2 id="comparison-with-other-sturcture-units">Comparison with Other Sturcture Units</h2>

<ul>
  <li>제한된 연산량 내에서 다른 Network 들과 성능 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_5.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_5.png" /></p>

<ul>
  <li>기존에 비슷한 성능의 Network들과 연산량 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_6.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_6.png" /></p>

<h2 id="comparison-with-mobilenets-and-other-frameworks">Comparison with MobileNets and Other Frameworks</h2>

<ul>
  <li>Mobile devices에 특화된 MobileNet과 성능 비교</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_7.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_7.png" /></p>

<h2 id="generalization-ability">Generalization Ability</h2>

<ul>
  <li>MS COCO Data를 사용하여 Object detection 성능 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_8.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_8.png" /></p>

<h2 id="actual-speedup-evaluation">Actual Speedup Evaluation</h2>

<ul>
  <li>Mobile device에서 Inference 속도 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_9.png" alt="https://jjerry-k.github.io/public/img/shufflenetv1/Untitled_9.png" /></p>

<h2 id="ps">P.S</h2>
<ul>
  <li>GPU가 부족해서 했다던 Group Convolution의 부활..?</li>
</ul>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/05/07/ShuffleNetV1/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/05/07/ShuffleNetV1/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/blog/page4">Older</a>
  
  
    
      <a class="pagination-item newer" href="/blog/page2">Newer</a>
    
  
</div>


        </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <!-- Modal -->
  <div class="modal fade" id="myModal" role="dialog">
    <div class="modal-dialog">

      <!-- Modal content-->
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal">&times;</button>
          <h4 class="modal-title">Search</h4>
        </div>
        <div class="modal-body">

    <h4><div id="search-container">
      <input type="text" id="search-input" placeholder="검색어 입력" class="input" style="font-size: 1rem; width: 100%; padding: 10px; border: 0px; outline: none; float: left; background: #cecece;" autofocus>
    </div></h4><br>

      <div id="results">
        <h1></h1>
      <ul class="results"></ul>
      </div>
      <br><ul id="results-container"></ul>
    </div>

<!-- Script pointing to jekyll-search.js -->


<script type="text/javascript">
      SimpleJekyllSearch({
        searchInput: document.getElementById('search-input'),
        resultsContainer: document.getElementById('results-container'),
        json: '/dest/search.json',
        searchResultTemplate: '<h4 style="margin-bottom:-0.5rem;"><a class="post-title" style="color:#ac4142;" href="{url}" title="{desc}">{title}</a> <small>{category}</small></h4>',
        noResultsText: '<h4><br>문서가 존재하지 않습니다.</h4>',
        limit: 15,
        fuzzy: false,
        exclude: ['Welcome']
      })
</script>
        </div>
      </div>

    </div>
  </div>

</div>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');
        document.addEventListener('click', function(e) {
          var target = e.target;
          if (target === toggle) {
            checkbox.checked = !checkbox.checked;
            e.preventDefault();
          } else if (checkbox.checked && !sidebar.contains(target)) {
            /* click outside the sidebar when sidebar is open */
            checkbox.checked = false;
          }
        }, false);
      })(document);
    </script>

    
      <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-126636477-1', 'auto');
        ga('send', 'pageview');
      </script>
    

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (absbygoogle = window.adsbygoogle || []).push({
          google_ad_client: "ca-pub-1054696837285307",
          enable_page_level_ads: true
      });
    </script>
  </body>
  
  <script id="dsq-count-scr" src="//jerry.disqus.com/count.js" async></script>
  
</html>
