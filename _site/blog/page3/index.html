<!DOCTYPE html>
<html lang="en-us">
  <head>
  <head>
    <link href="http://gmpg.org/xfn/11" rel="profile">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="content-type" content="text/html; charset=utf-8">

    <!-- Enable responsiveness on mobile devices-->
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

    <title>
        
        Blog &middot; Jerry's Blog
        
    </title>

    <!-- CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">
    <link rel="stylesheet" href="/public/css/main.css">

    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144"
        href="/public/apple-touch-icon-precomposed.png">
    <link rel="shortcut icon" href="/public/favicon.ico">

    <!-- RSS -->
    <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

    <!-- scroll -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    <script>
        $(window).scroll(function () {
            if ($(this).scrollTop() > 500) {
                $('.top').fadeIn();
            } else {
                $('.top').fadeOut();
            }
        });
        $('.top').click(function () {
            $('html, body').stop().animate({ scrollTop: 0 }, 100);
            return false;
        });
    </script>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
        (absbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-1054696837285307",
            enable_page_level_ads: true
        });
    </script>

    
    <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
              //jax: ["input/TeX", "output/HTML-CSS"],
              tex2jax: {
                inlineMath: [ ['$', '$'] ],
                displayMath: [ ['$$', '$$'] ],
                processEscapes: true,
                skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
              }
              //,
              //displayAlign: "left",
              //displayIndent: "2em"
            });
          </script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
    

    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script src="/dest/simple-jekyll-search.js" type="text/javascript"></script>
    <script type="text/javascript">
        $(document).ready(function () {
            document.search.searchinput.focus();
        });
    </script>
</head>

  <style>blockquote {font-size: 1em; line-height: 1.4}</style>
  </head>
  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <div class="sidebar-personal-info">
      <div class="sidebar-personal-info-section">
        <a href="https://gravatar.com/22a6447c0c965de55f4ce9691aed2af4">
          <img src="https://www.gravatar.com/avatar/22a6447c0c965de55f4ce9691aed2af4?s=350" title="View on Gravatar" alt="View on Gravatar" />
        </a>
      </div>
      <div class="sidebar-personal-info-section">
        <p></p>
      </div>
      
      
      
      <div class="sidebar-personal-info-section">
        <p> Follow me  :  
        
        
        
        <a href="https://github.com/jjerry-k">
          <i class="fa fa-github" aria-hidden="true"></i>
        </a>
        
        |
        
        
        
        <a href="https://www.facebook.com/jerry.kim.566">
          <i class="fa fa-facebook" aria-hidden="true"></i>
        </a>
        
        |
        
        
        
        <a href="mailto:jaeyeol2931@gmail.com">
          <i class="fa fa-envelope" aria-hidden="true"></i>
        </a>
        
        
        
        </p>
      </div>
      
    </div>
  </div>

  <nav class="sidebar-nav">
    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/">
          Home
        </a>

        
      </span>

    
      
      
      

      

      <span class="foldable">
        <a class="sidebar-nav-item " href="/blog/">
          Contents
        </a>

        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/blog/">
                Blog
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/python/">
                Python
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/ubuntu/">
                Ubuntu
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/living/">
                Living
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/deeplearning/">
                Deep Learning
              </a>
          
        
      </span>

    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/about/">
          About
        </a>

        
      </span>

    

  </nav>

  <div class="sidebar-item">
    <p>
    &copy; 2020 Jerry. This work is liscensed under <a href="http://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a>.
    </p>
  </div>

  <div class="sidebar-item">
    <p>
    Powered by <a href="http://jekyllrb.com">jekyll</a>
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
          <div class="top" style="position:fixed; right:10%; bottom:15px; display:none; z-index:9999;">
            <a href="#">
              <img src="https://jjerry-k.github.io/public/top.png" width="40" height="40" class="top" style="border-radius:5px; background-color: #000; margin-bottom:0; margin-right:7px; float:left;">
            </a>
            
            <a href="/blog//">
              <img src="https://jjerry-k.github.io/public/contents.png" width="40" height="40" class="top" style="border-radius:5px; background-color: #000; margin-bottom:0; float:left;">
            </a>
          </div>
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title" align="center">
            <a href="/" title="Home" title="Jerry's Blog">
              <img class="masthead-logo" src="/public/logo.png"/>
            </a>
            <small></small>
            <a href="https://donaricano.com/mypage/1391188679_guPzXC" target="_blank">
              <img src="https://d1u4yishnma8v5.cloudfront.net/mobile-gift.png" width="60" height="60" style="position:absolute; top:0.25rem; right:4rem" alt="donaricano-btn" style="height: 130px !important;width: 130px !important;" />
            </a>
            <img src="http://jjerry-k.github.io/public/search.png" width="20" height="20" style="position:absolute; top:1.3rem; right:1.5rem" data-toggle="modal" data-target="#myModal">
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/07/13/colab_vscode/">
        Colab x VSCode !
      </a>
    </h1>

    <span class="post-date">13 Jul 2020</span>
     | 
    
    <a href="/blog/tags/#tools" class="post-tag">Tools</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <blockquote>
  <p>본 포스팅은 <a href="https://towardsdatascience.com/colab-free-gpu-ssh-visual-studio-code-server-36fe1d3c5243">Colab on steroids: free GPU instances with SSH access and Visual Studio Code Server</a> 내용을 (많이) 참고하여 작성하였습니다.</p>
</blockquote>

<p>많은 분들이 Google Colaboratory (코랩) 를 사용하실겁니다. (무료니까…)</p>

<p>무료로 고성능(?)의 하드웨어를 쓸 수 있다는 건 참 좋은 것입니다!</p>

<p>하지만…문제는 Jupyter Notebook 형식으로 써야한다는거…아 물론 편하신 분들도 있겠죠!?</p>

<p>전 개인적으로 별로 안좋아합니다. (물론 애초에 안쓰기도 함.)</p>

<p>근데 SSH, VSCode Server를 이용해서 Colab에 접속을…하는 포스팅이 있더군요.</p>

<p>갑자기 실험쥐 정신이 튀어나와서 진행을 해봤습니다.</p>

<p>뻘소리 그만하고 간단 간단 설명 시작하겠습니다.</p>

<h2 id="1-ngrok으로-token-만들기">1. ngrok으로 token 만들기</h2>

<p>ngrok은 대충 로컬 웹 서버를 SSH 접속이나 모바일 테스트 할 수 있도록 공공 URL로 접근 가능토록 해주는 것입니다.  가격은 걱정하지 마세요. 1개는 무료거든요.</p>

<p><img src="https://jjerry-k.github.io/public/img/colab_vscode/Untitled.png" alt="https://jjerry-k.github.io/public/img/colab_vscode/Untitled.png" /></p>

<p>어쨌든 가입을 하고 token을 생성 해줍니다.</p>

<p><img src="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_1.png" alt="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_1.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_2.png" alt="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_2.png" /></p>

<h2 id="2-colab에-ngrok-설치-및-실행">2. Colab에 ngrok 설치 및 실행</h2>

<p>노트북 설정을 먼저 해주세요. (ex) CPU, GPU, TPU</p>

<p><img src="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_3.png" alt="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_3.png" /></p>

<p>그리고 셀에 다음과 같이 코드를 실행합니다.</p>

<p>아래 authtoken 에는 ngrok의 Authtoken을 적어주세요. (당연하지만 스트링으로)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Install useful stuff
</span><span class="err">!</span> <span class="n">apt</span> <span class="n">install</span> <span class="o">--</span><span class="n">yes</span> <span class="n">ssh</span> <span class="n">screen</span> <span class="n">nano</span> <span class="n">htop</span> <span class="n">ranger</span> <span class="n">git</span> <span class="o">&gt;</span> <span class="o">/</span><span class="n">dev</span><span class="o">/</span><span class="n">null</span>
<span class="c1"># SSH setting
</span><span class="err">!</span> <span class="n">echo</span> <span class="s">"root:carbonara"</span> <span class="o">|</span> <span class="n">chpasswd</span>
<span class="err">!</span> <span class="n">echo</span> <span class="s">"PasswordAuthentication yes"</span> <span class="o">&gt;</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">ssh</span><span class="o">/</span><span class="n">sshd_config</span>
<span class="err">!</span> <span class="n">echo</span> <span class="s">"PermitUserEnvironment yes"</span> <span class="o">&gt;&gt;</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">ssh</span><span class="o">/</span><span class="n">sshd_config</span>
<span class="err">!</span> <span class="n">echo</span> <span class="s">"PermitRootLogin yes"</span> <span class="o">&gt;&gt;</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">ssh</span><span class="o">/</span><span class="n">sshd_config</span>
<span class="err">!</span> <span class="n">service</span> <span class="n">ssh</span> <span class="n">restart</span> <span class="o">&gt;</span> <span class="o">/</span><span class="n">dev</span><span class="o">/</span><span class="n">null</span>
<span class="c1"># Download ngrok
</span><span class="err">!</span> <span class="n">wget</span> <span class="o">-</span><span class="n">q</span> <span class="o">-</span><span class="n">c</span> <span class="o">-</span><span class="n">nc</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="nb">bin</span><span class="p">.</span><span class="n">equinox</span><span class="p">.</span><span class="n">io</span><span class="o">/</span><span class="n">c</span><span class="o">/</span><span class="mi">4</span><span class="n">VmDzA7iaHb</span><span class="o">/</span><span class="n">ngrok</span><span class="o">-</span><span class="n">stable</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">amd64</span><span class="p">.</span><span class="nb">zip</span>
<span class="err">!</span> <span class="n">unzip</span> <span class="o">-</span><span class="n">qq</span> <span class="o">-</span><span class="n">n</span> <span class="n">ngrok</span><span class="o">-</span><span class="n">stable</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">amd64</span><span class="p">.</span><span class="nb">zip</span>
<span class="c1"># Run ngrok
</span><span class="n">authtoken</span> <span class="o">=</span> <span class="o">**</span><span class="s">"PUT_YOUR_TOKEN_HERE"</span><span class="o">**</span>
<span class="n">get_ipython</span><span class="p">().</span><span class="n">system_raw</span><span class="p">(</span><span class="s">'./ngrok authtoken $authtoken &amp;&amp; ./ngrok tcp 22 &amp;'</span><span class="p">)</span>
<span class="err">!</span> <span class="n">sleep</span> <span class="mi">3</span>
<span class="c1"># Get the address for SSH
</span><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">re</span> <span class="kn">import</span> <span class="n">sub</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">'http://localhost:4040/api/tunnels'</span><span class="p">)</span>
<span class="n">str_ssh</span> <span class="o">=</span> <span class="n">r</span><span class="p">.</span><span class="n">json</span><span class="p">()[</span><span class="s">'tunnels'</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s">'public_url'</span><span class="p">]</span>
<span class="n">str_ssh</span> <span class="o">=</span> <span class="n">sub</span><span class="p">(</span><span class="s">"tcp://"</span><span class="p">,</span> <span class="s">""</span><span class="p">,</span> <span class="n">str_ssh</span><span class="p">)</span>
<span class="n">str_ssh</span> <span class="o">=</span> <span class="n">sub</span><span class="p">(</span><span class="s">":"</span><span class="p">,</span> <span class="s">" -p "</span><span class="p">,</span> <span class="n">str_ssh</span><span class="p">)</span>
<span class="n">str_ssh</span> <span class="o">=</span> <span class="s">"ssh root@"</span> <span class="o">+</span> <span class="n">str_ssh</span>
<span class="k">print</span><span class="p">(</span><span class="n">str_ssh</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_4.png" alt="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_4.png" /></p>

<p>출력으로 나온 커맨드를 이용하여 한번 터미널에서 테스트를 해봅니다. 비밀번호는 <code class="language-plaintext highlighter-rouge">carbonara</code> 입니다.</p>

<p><img src="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_5.png" alt="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_5.png" /></p>

<h2 id="3-vscode에서-실행하기">3. VSCode에서 실행하기</h2>

<p>먼저 Colab 화면에서 다음 코드를 실행해서 Google Drive를 마운트 해줍니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Mount Google Drive and make some folders for vscode
</span><span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="p">.</span><span class="n">mount</span><span class="p">(</span><span class="s">'/googledrive'</span><span class="p">)</span>
<span class="err">!</span> <span class="n">mkdir</span> <span class="o">-</span><span class="n">p</span> <span class="o">/</span><span class="n">googledrive</span><span class="o">/</span><span class="n">My</span>\ <span class="n">Drive</span><span class="o">/</span><span class="n">colabdrive</span>
<span class="err">!</span> <span class="n">mkdir</span> <span class="o">-</span><span class="n">p</span> <span class="o">/</span><span class="n">googledrive</span><span class="o">/</span><span class="n">My</span>\ <span class="n">Drive</span><span class="o">/</span><span class="n">colabdrive</span><span class="o">/</span><span class="n">root</span><span class="o">/</span><span class="p">.</span><span class="n">local</span><span class="o">/</span><span class="n">share</span><span class="o">/</span><span class="n">code</span><span class="o">-</span><span class="n">server</span>
<span class="err">!</span> <span class="n">ln</span> <span class="o">-</span><span class="n">s</span> <span class="o">/</span><span class="n">googledrive</span><span class="o">/</span><span class="n">My</span>\ <span class="n">Drive</span><span class="o">/</span><span class="n">colabdrive</span> <span class="o">/</span>
<span class="err">!</span> <span class="n">ln</span> <span class="o">-</span><span class="n">s</span> <span class="o">/</span><span class="n">googledrive</span><span class="o">/</span><span class="n">My</span>\ <span class="n">Drive</span><span class="o">/</span><span class="n">colabdrive</span><span class="o">/</span><span class="n">root</span><span class="o">/</span><span class="p">.</span><span class="n">local</span><span class="o">/</span><span class="n">share</span><span class="o">/</span><span class="n">code</span><span class="o">-</span><span class="n">server</span> <span class="o">/</span><span class="n">root</span><span class="o">/</span><span class="p">.</span><span class="n">local</span><span class="o">/</span><span class="n">share</span><span class="o">/</span>
</code></pre></div></div>

<p><img src="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_6.png" alt="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_6.png" /></p>

<p>VSCode를 켜고 ssh로 접속을 해봅니다.</p>

<p><img src="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_7.png" alt="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_7.png" /></p>

<p>접속해서 Colab Notebooks 디렉토리에 접근한 화면입니다. Google Drive랑 동일한 것을 확인할 수 있죠!</p>

<p><img src="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_8.png" alt="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_8.png" /></p>

<h2 id="4-코드-작성-및-실행">4. 코드 작성 및 실행</h2>

<p>코드 실행 여부를 테스트 해보겠습니다.</p>

<p>일단 Colab 에는 VSCode 플러그인이 설치 되어 있지 않기 때문에 python이나 개인적으로 필요한 플러그인들을 설치해줍니다.</p>

<p>저는 테스트이니 아래 세 가지만 설치했습니다.</p>

<p><img src="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_9.png" alt="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_9.png" /></p>

<p>그럼 한번 실행해보죠.</p>

<p><img src="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_10.png" alt="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_10.png" /></p>

<p>오…..신기…</p>

<p>이렇게 연결해서 사용이 가능합니다.</p>

<p><code class="language-plaintext highlighter-rouge">htop</code>를 이용해서 리소스 모니터링도 가능하죠.</p>

<p><img src="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_11.png" alt="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_11.png" /></p>

<p>여기까지 Colab x VSCode 포스팅입니다. 뭐….어떤 면에선 편할 것 같지만 막…편할 것 같진 않네요.</p>

<p>아직 이 상황을 겪지 않아서 모르겠지만 원래 코랩의 큰 문제가 있죠. Session timeout….</p>

<p>일정 시간동안 동작이 없으면 연결이 끊겨서 다시 실행을 시켜야하는….상황이 오죠.</p>

<p><img src="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_12.png" alt="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_12.png" /></p>

<p>나한테 왜 그래…</p>

<p>그 상황이 왔을 때 느낌으로는 VSCode의 SSH 접속이 끊길 것 같네요. 흠…. 실험 후에 추가로 적어 보겠습니다.</p>

<h2 id="ps">P.S</h2>

<p>끊겼습니다.</p>

<p><img src="https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/colab_vscode/Untitled_13.png?raw=true" alt="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_13.png" /></p>

<p>VSCode 를 봐도..</p>

<p><img src="https://github.com/jjerry-k/jjerry-k.github.io/blob/master/public/img/colab_vscode/Untitled_14.png?raw=true" alt="https://jjerry-k.github.io/public/img/colab_vscode/Untitled_14.png" /></p>

<p>그렇습니다. 제 생각대로 Colab의 Session time이 끝나면…끊기네요..ㅎㅎ
편하게 쓰기는 힘들 듯…</p>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/07/13/colab_vscode/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/07/13/colab_vscode/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/06/28/nipa_docker/">
        NIPA x Docker !
      </a>
    </h1>

    <span class="post-date">28 Jun 2020</span>
     | 
    
    <a href="/blog/tags/#tools" class="post-tag">Tools</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <blockquote>
  <p>원래 NIPA GPU 서버를 대여받은 후에 포트 포워딩을 먼저 해줘야 합니다.
하지만 그 부분에 대해선 보안적인 부분이 있기 때문에 생략하겠습니다.</p>
</blockquote>

<p>이번엔 NIPA 내 개인 환경 세팅에 대해 포스팅을 해보려 합니다.</p>

<p>개인마다 원하는 환경이 다르기 때문에 정말 필요하죠.</p>

<p>물론 기본적으로 설치된 Anaconda  환경으로도 충분할 수 있지만 살짝쿵 문제가 있습니다.</p>

<p>문제에 대해 살펴보겠습니다.</p>

<p>NIPA GPU 서버에 접속을 하면 다음과 같은 화면이 출력됩니다.</p>

<p><img src="https://jjerry-k.github.io/public/img/nipa_docker/Untitled.png" alt="Untitled.png" /></p>

<p>먼저 말씀드렸던 conda 환경으로 기본적으로 다양한 환경이 제공되네요.</p>

<p>저의 경우 이번에 tf-nightly가 필요했습니다.</p>

<p>그래서 TensorFlow2, python3.6 환경을 activate  한 후 설치를 시도했죠.</p>

<p><img src="https://jjerry-k.github.io/public/img/nipa_docker/Untitled_1.png" alt="NIPA%20x%20Docker%20ef94d24dfbc64a6cae24a83a59bd352f/Untitled%201.png" /></p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">what…?</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="https://jjerry-k.github.io/public/img/nipa_docker/Untitled_2.png" alt="NIPA%20x%20Docker%20ef94d24dfbc64a6cae24a83a59bd352f/Untitled%202.png" /></td>
    </tr>
  </tbody>
</table>

<p>음….conda 버전의 문제인가 싶어서 base conda를 update  하려 했습니다.</p>

<p><img src="https://jjerry-k.github.io/public/img/nipa_docker/Untitled_3.png" alt="NIPA%20x%20Docker%20ef94d24dfbc64a6cae24a83a59bd352f/Untitled%203.png" /></p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">what…?</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="https://jjerry-k.github.io/public/img/nipa_docker/Untitled_2.png" alt="NIPA%20x%20Docker%20ef94d24dfbc64a6cae24a83a59bd352f/Untitled%202.png" /></td>
    </tr>
  </tbody>
</table>

<p>뭐야..이건 또 왜 안되는거야… 짜증이 났습니다.</p>

<p>대충 <code class="language-plaintext highlighter-rouge">너무 옛날 버전의 conda니까 최소 4.8로 재설치 해주세요.</code> 라는 내용입니다.</p>

<p><code class="language-plaintext highlighter-rouge">하....이건 좀 너무한데...그냥 Docker나 설치하자..</code> 라는 생각을 하게 되었습니다.</p>

<p>그럼 Docker 설치에 대해 포스팅 해보겠습니다.</p>

<p>Docker 에 대한 자세한 설명은 하지 않을 겁니다.</p>

<p>홈페이지 혹은 Docker 에 대한 포스팅을 참고하시기 바랍니다.</p>

<p>간단히 말씀드리면 OS 단계까지 가상환경을 만드는 겁니다.</p>

<p>그럼 설치 방법에 대해 적겠습니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># SET UP THE REPOSITORY</span>
<span class="nb">sudo </span>apt-get update

<span class="nb">sudo </span>apt-get <span class="nb">install</span> <span class="se">\</span>
    apt-transport-https <span class="se">\</span>
    ca-certificates <span class="se">\</span>
    curl <span class="se">\</span>
    gnupg-agent <span class="se">\</span>
    software-properties-common

curl <span class="nt">-fsSL</span> https://download.docker.com/linux/ubuntu/gpg | <span class="nb">sudo </span>apt-key add -

<span class="nb">sudo </span>apt-key fingerprint 0EBFCD88

<span class="nb">sudo </span>add-apt-repository <span class="se">\</span>
   <span class="s2">"deb [arch=amd64] https://download.docker.com/linux/ubuntu </span><span class="se">\</span><span class="s2">
   </span><span class="si">$(</span>lsb_release <span class="nt">-cs</span><span class="si">)</span><span class="s2"> </span><span class="se">\</span><span class="s2">
   stable"</span>

<span class="c"># INSTALL DOCKER ENGINE</span>
<span class="nb">sudo </span>apt-get update
<span class="nb">sudo </span>apt-get <span class="nb">install </span>docker-ce docker-ce-cli containerd.io

<span class="c"># VERIFY THAT DOCKER ENGINE IS INSTALLED CORRECTLY</span>
<span class="nb">sudo </span>docker run hello-world
</code></pre></div></div>

<p>만약에 제대로 설치 되었다면 마지막에 다음과 같은 출력이 남습니다</p>

<p><img src="https://jjerry-k.github.io/public/img/nipa_docker/Untitled_4.png" alt="NIPA%20x%20Docker%20ef94d24dfbc64a6cae24a83a59bd352f/Untitled%204.png" /></p>

<p>여기까지 하시면 기본 Docker 설치는 끝났습니다.</p>

<p>하지만 이것만 설치하면 GPU 는 사용하지 못합니다.</p>

<p>GPU를 쓰기 위해선 <a href="https://github.com/NVIDIA/nvidia-docker">nvidia-docker</a>를 설치를 해야 합니다.</p>

<p>nvidia-docker는 간단히 말하면 docker 에서 데스크탑의 GPU를 사용할 수 있도록 nvidia에서 만든(?)것입니다.</p>

<p>설치법은 다음과 같습니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Ubuntu 16.04/18.04/20.04, Debian Jessie/Stretch/Buster</span>
<span class="c"># Add the package repositories</span>
<span class="nv">distribution</span><span class="o">=</span><span class="si">$(</span><span class="nb">.</span> /etc/os-release<span class="p">;</span><span class="nb">echo</span> <span class="nv">$ID$VERSION_ID</span><span class="si">)</span>
curl <span class="nt">-s</span> <span class="nt">-L</span> https://nvidia.github.io/nvidia-docker/gpgkey | <span class="nb">sudo </span>apt-key add -
curl <span class="nt">-s</span> <span class="nt">-L</span> https://nvidia.github.io/nvidia-docker/<span class="nv">$distribution</span>/nvidia-docker.list | <span class="nb">sudo tee</span> /etc/apt/sources.list.d/nvidia-docker.list

<span class="nb">sudo </span>apt-get update <span class="o">&amp;&amp;</span> <span class="nb">sudo </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> nvidia-container-toolkit
<span class="nb">sudo </span>systemctl restart docker

<span class="c"># Test nvidia-docker</span>
docker run <span class="nt">--gpus</span> all nvidia/cuda:10.0-base nvidia-smi
</code></pre></div></div>

<p>이 또한 설치가 제대로 되었다면 마지막에 다음과 같이 <code class="language-plaintext highlighter-rouge">nvidia-smi</code> 출력이 나올 겁니다.</p>

<p><img src="https://jjerry-k.github.io/public/img/nipa_docker/Untitled_5.png" alt="NIPA%20x%20Docker%20ef94d24dfbc64a6cae24a83a59bd352f/Untitled%205.png" /></p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">하….편안….</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="https://jjerry-k.github.io/public/img/nipa_docker/Untitled_6.png" alt="NIPA%20x%20Docker%20ef94d24dfbc64a6cae24a83a59bd352f/Untitled%206.png" /></td>
    </tr>
  </tbody>
</table>

<p>이번엔 NIPA에 Docker 설치하는 과정을 포스팅 해봤습니다.</p>

<p>공짜로 빌려주는 건 좋으나 환경 구축은 역시나….해야 하네요.</p>

<p>제가 쓰는 Docker image는 <a href="https://jjerry-k.github.io/living/2020/05/05/dockerfile/">개인적인 도커 파일</a> 에 있으니 참고하세요!</p>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/06/28/nipa_docker/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/06/28/nipa_docker/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/06/27/nipa_apply/">
        NIPA 컴퓨팅 자원 신청 방법 !
      </a>
    </h1>

    <span class="post-date">27 Jun 2020</span>
     | 
    
    <a href="/blog/tags/#tools" class="post-tag">Tools</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <p><a href="https://jjerry-k.github.io/deeplearning/2020/06/26/nipa_intro/">저번 포스팅</a>에 이어 이번엔 NIPA 컴퓨팅 자원 이용 신청에 관한 포스팅을 해보려 합니다!</p>

<p>내용 출처: <a href="http://www.aihub.or.kr/node/254">http://www.aihub.or.kr/node/254</a></p>

<h3 id="이용-절차">이용 절차</h3>

<ul>
  <li>일반 사용자
    <ul>
      <li>신청 대상: AI 제품·서비스를 연구·개발하고자 하는 국내 중소·벤처 기업, 스타트업, 공공기관, 대학교(원), 일반 협·단체</li>
      <li>신청 기간: 2020. 1. 6.(월) ∼ 2. 7.(금)※ 추가 모집 : 2020.5.25.(월) ~ 11.30.(월)</li>
      <li>신청 절차: 이용 신청서 작성 → 온라인 신청 사이트에 제출 → 서면 심사 → 선정결과 발표<br />
  ※ 선정기준 : 지원 자격요건, AI 연구‧개발대상 여부, 사용계획서(목적, 연구‧개발분야, 사용내용, 필요성 등)를 중심으로 심사‧평가<br />
  ※ 모집 규모 대비 초과 신청 시 중소·벤처기업, 공공기관, 대학교(원)에 자원이 우선 할당될 수 있음</li>
    </ul>
  </li>
  <li>수시 사용자
    <ul>
      <li>신청 대상: 일반 사용자와 개발자, 학생 등 개인</li>
      <li>신청 기간: 2020.4.10.(금) ~ 2020.12.21.(월)</li>
      <li>신청 절차: 이용신청 작성‧제출 → AI 연구‧개발대상 여부 확인 → 여유 자원 확인 → 서비스 이용</li>
    </ul>
  </li>
</ul>

<p>각각의 신청서 양식은 다음과 같습니다.</p>

<h3 id="일반-사용자용-신청서">일반 사용자용 신청서</h3>

<ul>
  <li><a href="http://www.aihub.or.kr/sites/default/files/2020-05/[일반">다운로드 링크</a></li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/nipa_apply/Untitled.png" alt="Untitled.png" /></p>

<h3 id="수시-사용자용-신청서">수시 사용자용 신청서</h3>

<ul>
  <li><a href="http://www.aihub.or.kr/sites/default/files/2020-05/[%EC%88%98%EC%8B%9C%20%EC%82%AC%EC%9A%A9%EC%9E%90%EC%9A%A9]%20%EA%B3%A0%EC%84%B1%EB%8A%A5%20%EC%BB%B4%ED%93%A8%ED%8C%85%20%EC%9E%90%EC%9B%90%20%EC%9D%B4%EC%9A%A9%20%EC%8B%A0%EC%B2%AD%EC%84%9C.hwp">다운로드 링크</a></li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/nipa_apply/Untitled_1.png" alt="Untitled_1.png" /></p>

<p>당연한거지만 일반 사용자가 수시 사용자에 비해 작성해야할 것이 많습니다.</p>

<p>신청서 작성 방법은 예시가 너무 잘 적혀있기 때문에 따로 설명을 드리지 않겠습니다. (궁금하신게 있다면 따로 댓글 남겨주세요!)</p>

<p>신청서를 작성하신 후엔 AIHub 사이트 로그인을 하신 후 <code class="language-plaintext highlighter-rouge">이용신청</code> 으로 넘어갑니다.<br />
그럼 다음과 같은 화면이 나오는데 (수시 사용자 기준) <strong>1~8번 중 해당하는 부분 선택하</strong>고 <strong>개인 정보</strong> 채워주시면 됩니다!</p>

<p><img src="https://jjerry-k.github.io/public/img/nipa_apply/Untitled_2.png" alt="Untitled_2.png" /></p>

<p>다 채운 후 이용신청을 누르시면 한…. 하루, 이틀? 정도 후에 메일과 핸드폰으로 문자 안내가 옵니다!<br />
메일에는 NIPA 서버 사용방법, 문자에는 관리 페이지 이용 안내가 옵니다. <br />
신청이 어렵지 않으니 많이 많이 신청하시고 즐거운 딥러닝 공부, 연구하세요! (홍보 아님)</p>

<p><img src="https://jjerry-k.github.io/public/img/nipa_apply/go.png" alt="go.png" /></p>

<h2 id="ps">P.S.</h2>
<ul>
  <li>중요! ! ! <strong>수시 사용자는 계속 사용하려면 10일마다 연장 신청 해야함. 꼭! 반드시!</strong></li>
  <li><strong>위 내용을 지키지 않으면 서버 초기화되서 내용들 다 사라짐!!!</strong></li>
  <li>너무 대충 포스팅을…하는걸까…</li>
</ul>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/06/27/nipa_apply/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/06/27/nipa_apply/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/06/26/nipa_intro/">
        NIPA...NIPA가 뭐죠..
      </a>
    </h1>

    <span class="post-date">26 Jun 2020</span>
     | 
    
    <a href="/blog/tags/#tools" class="post-tag">Tools</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <p>요즘 커뮤니티(V-AIS) 에선 NIPA에 대한 얘기가 많이 나옵니다.<br />
NIPA는 <a href="https://www.nipa.kr/"><strong>정보통신산업진흥원</strong></a> 의 약자인데 <code class="language-plaintext highlighter-rouge">근데 그래서 이게 왜..?</code> 라는 의문을 가지실 겁니다. <br />
지금 AI Hub에서 지원하는 <a href="http://www.aihub.or.kr/node/223"><strong>AI 컴퓨팅 자원 지원 사업</strong></a>을 하고 있는데요.<br />
그 사업에서 컴퓨팅 자원을 관리하는게 NIPA 입니다. 그래서 NIPA, NIPA 하죠..</p>

<p>간단하게 그림으로 보여드리면 이렇습니다.</p>

<p><img src="https://jjerry-k.github.io/public/img/nipa_intro/Untitled.png" alt="Untitled.png" /></p>

<p>더 간단하게 설명드리면 <strong><code class="language-plaintext highlighter-rouge">GPU서버 지원해드림 ㅇㅇ</code></strong> 이겁니다.</p>

<p>어느 정도 사양이냐…</p>

<p><img src="https://jjerry-k.github.io/public/img/nipa_intro/Untitled_1.png" alt="Untitled_1.png" /></p>

<p><strong>일반 사용자</strong>와 <strong>수시 사용자</strong>로 나뉘는데요. 그 차이는 사이트에서 확인하시길..</p>

<p>이렇게 보면 GPU로 뭐 쓰는지 잘 모르시겠죠. 그래서 가져왔습니다.</p>

<p>제가 포스팅, 환경구축과 같은 자료를 만들기 위해 신청한 서버입니다.</p>

<p><img src="https://jjerry-k.github.io/public/img/nipa_intro/Untitled_2.png" alt="Untitled_2.png" /></p>

<p>위 GPU 사진은 <strong>수시 사용자</strong> 기준입니다. 일반 사용자면 V100 두개겠네요.</p>

<p>뭐 이런 서버를 <strong>공짜</strong>로 제공을 해줍니다.</p>

<p>집에 서버가 따로 없는 분들이라면 이보다 좋은 건 없겠죠. (게다가 VRAM이 32기가임….)</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center"><strong>헤헿 겁나 좋군</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="https://jjerry-k.github.io/public/img/nipa_intro/good.png" alt="good.png" /></td>
    </tr>
  </tbody>
</table>

<p>다음엔 NIPA 신청 방법에 대한 포스팅은 간단히 해보겠습니다.</p>

<p>그럼 모두 즐거운 딥러닝 공부, 연구하세요.</p>

<h2 id="ps">P.S.</h2>
<ul>
  <li>수시 사용자의 경우 기본 10일 사용, 10일마다 사용 연장신청을 해야함.</li>
  <li>당연하지만 신청해놓고 사용안하면 검열 후 강제 반납.</li>
</ul>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/06/26/nipa_intro/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/06/26/nipa_intro/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/06/14/tf2_multi_gpu/">
        TensorFlow Multi GPU 사용법
      </a>
    </h1>

    <span class="post-date">14 Jun 2020</span>
     | 
    
    <a href="/blog/tags/#tensorflow" class="post-tag">TensorFlow</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <p>이번 포스팅은 Multi GPU 시스템에서 Google의 머신러닝 오픈 소스 플랫폼인 <a href="https://www.tensorflow.org/">TensorFlow</a>사용법에 관한 것입니다!<br />
거두절미하고 바로 코딩으로 들어가겠습니다!</p>

<h2 id="single-gpu-예시">Single GPU 예시</h2>
<ul>
  <li>다음 코드는 Single GPU를 이용하여 mnist data를 분류하는 코드입니다.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Import Package
</span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">optimizers</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">utils</span>

<span class="c1"># Data Prepare
</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">),</span> <span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">)</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">mnist</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">train_x</span><span class="p">,</span> <span class="n">test_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">train_x</span><span class="o">/</span><span class="mf">255.</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">test_x</span><span class="o">/</span><span class="mf">255.</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Train Data's Shape : "</span><span class="p">,</span> <span class="n">train_x</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">train_y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Test Data's Shape : "</span><span class="p">,</span> <span class="n">test_x</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test_y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Build Network
</span><span class="n">cnn</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">,)))</span>
<span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">())</span>
<span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">())</span>
<span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">))</span>

<span class="n">cnn</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">(),</span> <span class="n">loss</span><span class="o">=</span><span class="n">losses</span><span class="p">.</span><span class="n">sparse_categorical_crossentropy</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>                
<span class="k">print</span><span class="p">(</span><span class="s">"Network Built!"</span><span class="p">)</span>

<span class="c1"># Training Network
</span><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">cnn</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="multi-gpu-예시">Multi GPU 예시</h2>
<ul>
  <li>다음 코드는 Multi GPU를 이용한 코드입니다.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Import Package
</span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">optimizers</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">utils</span>

<span class="c1"># Data Prepare
</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">),</span> <span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">)</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">mnist</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">train_x</span><span class="p">,</span> <span class="n">test_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">train_x</span><span class="o">/</span><span class="mf">255.</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">test_x</span><span class="o">/</span><span class="mf">255.</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Train Data's Shape : "</span><span class="p">,</span> <span class="n">train_x</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">train_y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Test Data's Shape : "</span><span class="p">,</span> <span class="n">test_x</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test_y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Build Network
</span><span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">distribute</span><span class="p">.</span><span class="n">MirroredStrategy</span><span class="p">()</span>
<span class="k">with</span> <span class="n">strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">():</span>
    <span class="n">cnn</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">,)))</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">())</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">())</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">())</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">))</span>

    <span class="n">cnn</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">(),</span> <span class="n">loss</span><span class="o">=</span><span class="n">losses</span><span class="p">.</span><span class="n">sparse_categorical_crossentropy</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>                
<span class="k">print</span><span class="p">(</span><span class="s">"Network Built!"</span><span class="p">)</span>

<span class="c1"># Training Network
</span><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span>
<span class="n">batch_size_each_gpu</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size_each_gpu</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">gpus</span><span class="p">)</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">cnn</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">))</span>
</code></pre></div></div>

<p>어렵지 않습니다. <code class="language-plaintext highlighter-rouge">Build Network</code> 주석 부분과 <code class="language-plaintext highlighter-rouge">Training Network</code> 부분에 <code class="language-plaintext highlighter-rouge">batch_size</code>만 조금 수정해주시면 끝납니다!<br />
<img src="https://jjerry-k.github.io/public/img/tf_multi_gpu/bob.png" alt="img" /></p>

<p>하지만 이렇게 하면 무식하게 GPU의 모든 메모리를 할당합니다.<br />
그렇기 떄문에 다음과 같이 코드를 추가하여 <code class="language-plaintext highlighter-rouge">필요한 만큼</code> 할당하도록 합니다.</p>

<h2 id="필요한-만큼의-gpu-메모리만-사용하기">필요한 만큼의 GPU 메모리만 사용하기</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Import Package
</span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">optimizers</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">utils</span>

<span class="c1"># Data Prepare
</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">),</span> <span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">)</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">mnist</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">train_x</span><span class="p">,</span> <span class="n">test_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">train_x</span><span class="o">/</span><span class="mf">255.</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">test_x</span><span class="o">/</span><span class="mf">255.</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Train Data's Shape : "</span><span class="p">,</span> <span class="n">train_x</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">train_y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Test Data's Shape : "</span><span class="p">,</span> <span class="n">test_x</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test_y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># For Efficiency
</span><span class="n">gpus</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s">'GPU'</span><span class="p">)</span>
<span class="k">if</span> <span class="n">gpus</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">gpu</span> <span class="ow">in</span> <span class="n">gpus</span><span class="p">:</span>
            <span class="n">tf</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">set_memory_growth</span><span class="p">(</span><span class="n">gpu</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
        <span class="n">logical_gpus</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">list_logical_devices</span><span class="p">(</span><span class="s">'GPU'</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">gpus</span><span class="p">),</span> <span class="s">"Physical GPUs,"</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">logical_gpus</span><span class="p">),</span> <span class="s">"Logical GPUs"</span><span class="p">)</span>
    <span class="k">except</span> <span class="nb">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>

<span class="c1"># Build Network
</span><span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">distribute</span><span class="p">.</span><span class="n">MirroredStrategy</span><span class="p">()</span>
<span class="k">with</span> <span class="n">strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">():</span>
    <span class="n">cnn</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">,)))</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">())</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">())</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">())</span>
    <span class="n">cnn</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">))</span>

    <span class="n">cnn</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">(),</span> <span class="n">loss</span><span class="o">=</span><span class="n">losses</span><span class="p">.</span><span class="n">sparse_categorical_crossentropy</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>                
<span class="k">print</span><span class="p">(</span><span class="s">"Network Built!"</span><span class="p">)</span>

<span class="c1"># Training Network
</span><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span>
<span class="n">batch_size_each_gpu</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size_each_gpu</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">gpus</span><span class="p">)</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">cnn</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">))</span>
</code></pre></div></div>

<p>기존 Multi GPU 코드와 달라진 점은</p>
<ol>
  <li><code class="language-plaintext highlighter-rouge">For Efficiency</code>라는 부분이 추가.</li>
  <li><code class="language-plaintext highlighter-rouge">strategy = tf.distribute.MirroredStrategy()</code>을 <code class="language-plaintext highlighter-rouge">Build Network</code>에서 <code class="language-plaintext highlighter-rouge">For Efficiency</code>의 가장 첫번째 라인으로 이동.</li>
</ol>

<p>이렇게 변경 후 실행 후 nvidia-smi와 같은 모니터링 툴을 확인해보시면 이전과는 다르게 GPU 메모리를 필요한 만큼만 사용하는걸 보실 수 있습니다!</p>

<h2 id="ps">P.S</h2>
<ul>
  <li>다음은 뭘로 포스팅하지…</li>
</ul>

<h2 id="번외편-using-gradient-tape">번외편 (Using gradient tape)</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># %%
# Import Package
</span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">optimizers</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">utils</span>

<span class="n">gpus</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s">'GPU'</span><span class="p">)</span>
<span class="k">if</span> <span class="n">gpus</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Currently, memory growth needs to be the same across GPUs
</span>        <span class="k">for</span> <span class="n">gpu</span> <span class="ow">in</span> <span class="n">gpus</span><span class="p">:</span>
            <span class="n">tf</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">set_memory_growth</span><span class="p">(</span><span class="n">gpu</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
        <span class="n">logical_gpus</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">list_logical_devices</span><span class="p">(</span><span class="s">'GPU'</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">gpus</span><span class="p">),</span> <span class="s">"Physical GPUs,"</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">logical_gpus</span><span class="p">),</span> <span class="s">"Logical GPUs"</span><span class="p">)</span>
    <span class="k">except</span> <span class="nb">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="c1"># Memory growth must be set before GPUs have been initialized
</span>        <span class="k">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>

<span class="c1"># %%
# Data Prepare
</span><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span>
<span class="n">batch_size_each_gpu</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size_each_gpu</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">gpus</span><span class="p">)</span>

<span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">),</span> <span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">)</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">mnist</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">train_x</span><span class="p">,</span> <span class="n">test_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">train_x</span><span class="o">/</span><span class="mf">255.</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">test_x</span><span class="o">/</span><span class="mf">255.</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Train Data's Shape : "</span><span class="p">,</span> <span class="n">train_x</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">train_y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Test Data's Shape : "</span><span class="p">,</span> <span class="n">test_x</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test_y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># %%
# Build Network
</span><span class="k">class</span> <span class="nc">build_model</span><span class="p">(</span><span class="n">models</span><span class="p">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">build_model</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">pool1</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">pool2</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">pool1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">pool2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">dense</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Network Built!"</span><span class="p">)</span>

<span class="c1"># Set mirrored Strategy
</span><span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">distribute</span><span class="p">.</span><span class="n">MirroredStrategy</span><span class="p">()</span>

<span class="k">with</span> <span class="n">strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">():</span>
    
    <span class="c1"># Prepare dataset 
</span>    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)).</span><span class="n">shuffle</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_x</span><span class="p">)).</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> 
    <span class="n">train_dist_dataset</span> <span class="o">=</span> <span class="n">strategy</span><span class="p">.</span><span class="n">experimental_distribute_dataset</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
    
    <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">)).</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> 
    <span class="n">test_dist_dataset</span> <span class="o">=</span> <span class="n">strategy</span><span class="p">.</span><span class="n">experimental_distribute_dataset</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>

    <span class="c1"># Make Network
</span>    <span class="n">cnn</span> <span class="o">=</span> <span class="n">build_model</span><span class="p">()</span>

    <span class="c1"># Set Loss &amp; Metric function
</span>    <span class="n">loss_object</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">Reduction</span><span class="p">.</span><span class="n">NONE</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">):</span>
        <span class="n">per_example_loss</span> <span class="o">=</span> <span class="n">loss_object</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">compute_average_loss</span><span class="p">(</span><span class="n">per_example_loss</span><span class="p">,</span> <span class="n">global_batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
        
    <span class="n">test_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">'test_loss'</span><span class="p">)</span>

    <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">'train_accuracy'</span><span class="p">)</span>
    <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">'test_accuracy'</span><span class="p">)</span>

    <span class="c1"># Set optimizer
</span>    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">()</span>

    <span class="c1"># Define taining, test function
</span>    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
        <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span>

        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">cnn</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">compute_loss</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>

        <span class="n">gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">cnn</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">cnn</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">))</span>

        <span class="n">train_accuracy</span><span class="p">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span> 
    
    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
        <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span>

        <span class="n">predictions</span> <span class="o">=</span> <span class="n">cnn</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">t_loss</span> <span class="o">=</span> <span class="n">loss_object</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>

        <span class="n">test_loss</span><span class="p">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">t_loss</span><span class="p">)</span>
        <span class="n">test_accuracy</span><span class="p">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>

    <span class="c1"># Define training, test function suitable for Mirrored Strategy 
</span>    <span class="o">@</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">distributed_train_step</span><span class="p">(</span><span class="n">dataset_inputs</span><span class="p">):</span>
        <span class="n">per_replica_losses</span> <span class="o">=</span> <span class="n">strategy</span><span class="p">.</span><span class="n">experimental_run_v2</span><span class="p">(</span><span class="n">train_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">dataset_inputs</span><span class="p">,))</span>
        <span class="k">return</span> <span class="n">strategy</span><span class="p">.</span><span class="nb">reduce</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">distribute</span><span class="p">.</span><span class="n">ReduceOp</span><span class="p">.</span><span class="n">SUM</span><span class="p">,</span> <span class="n">per_replica_losses</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
 
    <span class="o">@</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">distributed_test_step</span><span class="p">(</span><span class="n">dataset_inputs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">strategy</span><span class="p">.</span><span class="n">experimental_run_v2</span><span class="p">(</span><span class="n">test_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">dataset_inputs</span><span class="p">,))</span>

    <span class="c1"># Train Network
</span>    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    
        <span class="c1"># Training Loop
</span>        <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">num_batches</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">train_dist_dataset</span><span class="p">:</span>
            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">distributed_train_step</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">num_batches</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">num_batches</span>

        <span class="c1"># Test Loop
</span>        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">test_dist_dataset</span><span class="p">:</span>
            <span class="n">distributed_test_step</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">template</span> <span class="o">=</span> <span class="p">(</span><span class="s">"에포크 {}, 손실: {}, 정확도: {}, 테스트 손실: {}, 테스트 정확도: {}"</span><span class="p">)</span>
        <span class="k">print</span> <span class="p">(</span><span class="n">template</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_accuracy</span><span class="p">.</span><span class="n">result</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="n">test_loss</span><span class="p">.</span><span class="n">result</span><span class="p">(),</span> <span class="n">test_accuracy</span><span class="p">.</span><span class="n">result</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>

        <span class="n">test_loss</span><span class="p">.</span><span class="n">reset_states</span><span class="p">()</span>
        <span class="n">train_accuracy</span><span class="p">.</span><span class="n">reset_states</span><span class="p">()</span>
        <span class="n">test_accuracy</span><span class="p">.</span><span class="n">reset_states</span><span class="p">()</span>
</code></pre></div></div>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/06/14/tf2_multi_gpu/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/06/14/tf2_multi_gpu/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/blog/page4">Older</a>
  
  
    
      <a class="pagination-item newer" href="/blog/page2">Newer</a>
    
  
</div>


        </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <!-- Modal -->
  <div class="modal fade" id="myModal" role="dialog">
    <div class="modal-dialog">

      <!-- Modal content-->
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal">&times;</button>
          <h4 class="modal-title">Search</h4>
        </div>
        <div class="modal-body">

    <h4><div id="search-container">
      <input type="text" id="search-input" placeholder="검색어 입력" class="input" style="font-size: 1rem; width: 100%; padding: 10px; border: 0px; outline: none; float: left; background: #cecece;" autofocus>
    </div></h4><br>

      <div id="results">
        <h1></h1>
      <ul class="results"></ul>
      </div>
      <br><ul id="results-container"></ul>
    </div>

<!-- Script pointing to jekyll-search.js -->


<script type="text/javascript">
      SimpleJekyllSearch({
        searchInput: document.getElementById('search-input'),
        resultsContainer: document.getElementById('results-container'),
        json: '/dest/search.json',
        searchResultTemplate: '<h4 style="margin-bottom:-0.5rem;"><a class="post-title" style="color:#ac4142;" href="{url}" title="{desc}">{title}</a> <small>{category}</small></h4>',
        noResultsText: '<h4><br>문서가 존재하지 않습니다.</h4>',
        limit: 15,
        fuzzy: false,
        exclude: ['Welcome']
      })
</script>
        </div>
      </div>

    </div>
  </div>

</div>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');
        document.addEventListener('click', function(e) {
          var target = e.target;
          if (target === toggle) {
            checkbox.checked = !checkbox.checked;
            e.preventDefault();
          } else if (checkbox.checked && !sidebar.contains(target)) {
            /* click outside the sidebar when sidebar is open */
            checkbox.checked = false;
          }
        }, false);
      })(document);
    </script>

    
      <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-126636477-1', 'auto');
        ga('send', 'pageview');
      </script>
    

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (absbygoogle = window.adsbygoogle || []).push({
          google_ad_client: "ca-pub-1054696837285307",
          enable_page_level_ads: true
      });
    </script>
  </body>
  
  <script id="dsq-count-scr" src="//jerry.disqus.com/count.js" async></script>
  
</html>
