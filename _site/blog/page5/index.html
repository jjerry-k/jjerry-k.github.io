<!DOCTYPE html>
<html lang="en-us">
  <head>
  <head>
    <link href="http://gmpg.org/xfn/11" rel="profile">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
  
    <!-- Enable responsiveness on mobile devices-->
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  
    <title>
      
        Blog &middot; Jerry's Blog
      
    </title>
  
    <!-- CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">
    <link rel="stylesheet" href="/public/css/main.css">
  
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png">
    <link rel="shortcut icon" href="/public/favicon.ico">
  
    <!-- RSS -->
    <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
  
    <!-- scroll -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    <script>
      $( window ).scroll( function() {
        if ( $( this ).scrollTop() > 500 ) {
          $( '.top' ).fadeIn();
        } else {
          $( '.top' ).fadeOut();
        }
      } );
      $( '.top' ).click( function() {
        $( 'html, body' ).stop().animate( { scrollTop : 0 }, 100);
        return false;
      } );
    </script>
    
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (absbygoogle = window.adsbygoogle || []).push({
          google_ad_client: "ca-pub-1054696837285307",
          enable_page_level_ads: true
      });
    </script>
    
    <!-- 
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        //jax: ["input/TeX", "output/HTML-CSS"],
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
          inlineMath: [ ['$', '$'] ],
          displayMath: [ ['$$', '$$'] ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
        //,
        //displayAlign: "left",
        //displayIndent: "2em"
      });
      MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
        alert("Math Processing Error: "+message[1]);
      });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
        alert("Math Processing Error: "+message[1]);
      });
    </script>
    <script type="text/javascript" async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript">
    </script>
     -->
    
    
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      //jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$'] ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
      //,
      //displayAlign: "left",
      //displayIndent: "2em"
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
  

    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script src="/dest/simple-jekyll-search.js" type="text/javascript"></script>
    <script type="text/javascript">
    $(document).ready(function(){
      document.search.searchinput.focus();
    });
    </script>
  </head>
  
  <style>blockquote {font-size: 1em; line-height: 1.4}</style>
  
  <!-- New line Start-->
  <!--  -->
  <!-- New line End -->
  </head>
  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <div class="sidebar-personal-info">
      <div class="sidebar-personal-info-section">
        <a href="https://gravatar.com/22a6447c0c965de55f4ce9691aed2af4">
          <img src="https://www.gravatar.com/avatar/22a6447c0c965de55f4ce9691aed2af4?s=350" title="View on Gravatar" alt="View on Gravatar" />
        </a>
      </div>
      <div class="sidebar-personal-info-section">
        <p></p>
      </div>
      
      
      
      <div class="sidebar-personal-info-section">
        <p> Follow me  :  
        
        
        
        <a href="https://github.com/jjerry-k">
          <i class="fa fa-github" aria-hidden="true"></i>
        </a>
        
        |
        
        
        
        <a href="https://www.facebook.com/jerry.kim.566">
          <i class="fa fa-facebook" aria-hidden="true"></i>
        </a>
        
        |
        
        
        
        <a href="mailto:jaeyeol2931@gmail.com">
          <i class="fa fa-envelope" aria-hidden="true"></i>
        </a>
        
        
        
        </p>
      </div>
      
    </div>
  </div>

  <nav class="sidebar-nav">
    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/">
          Home
        </a>

        
      </span>

    
      
      
      

      

      <span class="foldable">
        <a class="sidebar-nav-item " href="/blog/">
          Contents
        </a>

        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/blog/">
                Blog
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/python/">
                Python
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/ubuntu/">
                Ubuntu
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/living/">
                Living
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/deeplearning/">
                Deep Learning
              </a>
          
        
      </span>

    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/about/">
          About
        </a>

        
      </span>

    

  </nav>

  <div class="sidebar-item">
    <p>
    &copy; 2020 Jerry. This work is liscensed under <a href="http://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a>.
    </p>
  </div>

  <div class="sidebar-item">
    <p>
    Powered by <a href="http://jekyllrb.com">jekyll</a>
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
          <div class="top" style="position:fixed; right:10%; bottom:15px; display:none; z-index:9999;">
            <a href="#">
              <img src="https://jjerry-k.github.io/public/top.png" width="40" height="40" class="top" style="border-radius:5px; background-color: #000; margin-bottom:0; margin-right:7px; float:left;">
            </a>
            
            <a href="/blog//">
              <img src="https://jjerry-k.github.io/public/contents.png" width="40" height="40" class="top" style="border-radius:5px; background-color: #000; margin-bottom:0; float:left;">
            </a>
          </div>
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title" align="center">
            <a href="/" title="Home" title="Jerry's Blog">
              <img class="masthead-logo" src="/public/logo.png"/>
            </a>
            <small></small>
            <a href="https://donaricano.com/mypage/1391188679_guPzXC" target="_blank">
              <img src="https://d1u4yishnma8v5.cloudfront.net/mobile-gift.png" width="60" height="60" style="position:absolute; top:0.25rem; right:4rem" alt="donaricano-btn" style="height: 130px !important;width: 130px !important;" />
            </a>
            <img src="http://jjerry-k.github.io/public/search.png" width="20" height="20" style="position:absolute; top:1.3rem; right:1.5rem" data-toggle="modal" data-target="#myModal">
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/living/2020/05/05/dockerfile/">
        개인적인 도커 파일
      </a>
    </h1>

    <span class="post-date">05 May 2020</span>
     | 
    
    <a href="/blog/tags/#docker" class="post-tag">Docker</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <h1 id="지극히-개인이-사용하기-위한-dockerfile">지극히 개인이 사용하기 위한 Dockerfile</h1>

<hr />

<ul>
  <li>환경을 만들 때마다 추가될 예정입니다.</li>
  <li>마음껏 편하신대로 Copy &amp; Paste 하세요!</li>
</ul>

<h2 id="tensorflow">TensorFlow</h2>
<pre><code class="language-Dockerfile">FROM nvidia/cuda:10.1-cudnn7-runtime-ubuntu18.04
LABEL maintainer "Jerry Kim &lt;jaeyeol2931@gmail.com&gt;"
ARG PYTHON_VERSION=3.7
RUN apt-get update
RUN apt-get install -y \
        build-essential \
        cmake \
        git \
        curl \
        wget \
        ca-certificates \
        libjpeg-dev \
        libpng-dev

RUN apt-get update &amp;&amp; apt-get -y upgrade

RUN rm -rf /var/lib/apt/lists/*

RUN curl https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -o ~/miniconda.sh

RUN chmod +x ~/miniconda.sh &amp;&amp; \
    ~/miniconda.sh -b -p /opt/conda &amp;&amp; \
    rm ~/miniconda.sh

RUN /opt/conda/bin/conda install -y python=$PYTHON_VERSION numpy pyyaml scipy ipython mkl mkl-include ninja cython typing opencv matplotlib tqdm &amp;&amp; \
    /opt/conda/bin/conda install -y jupyter jupyterlab seaborn pillow pandas pylint scikit-learn scikit-image tensorflow-gpu &amp;&amp; \
    /opt/conda/bin/conda update -y --all &amp;&amp; \
    /opt/conda/bin/conda clean -ya

ENV PATH /opt/conda/bin:$PATH

</code></pre>

    <article></h4>
    <div class="post-more">
      
      <a href="/living/2020/05/05/dockerfile/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/living/2020/05/05/dockerfile/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/05/02/EfficientNet/">
        Review: EfficientNet
      </a>
    </h1>

    <span class="post-date">02 May 2020</span>
     | 
    
    <a href="/blog/tags/#paper" class="post-tag">Paper</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <h1 id="efficientnet-rethinking-model-scaling-for-convolutional-neural-networks">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</h1>

<p>Author: Mingxing Tan, Quoc V. Le<br />
Date: May 28, 2019<br />
URL: https://arxiv.org/abs/1905.11946</p>

<h1 id="introduction">Introduction</h1>

<ul>
  <li>ConvNet 의 성능을 높이는데 Depth, Width, Image size 중 하나를 증가 시키는게 일반적인 방법.</li>
  <li>본 논문에서는 ConvNet의 성능과 효율성을 증가시키기 위한 원론적인 방법에 대한 연구.</li>
  <li>실험의 결과로 <strong><em>Compound scaling method</em></strong> 를 제안.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled.png" /></p>

<h1 id="compound-model-scaling">Compound Model Scaling</h1>

<ul>
  <li>Scaling 문제에 대한 정의, Approache 별 연구, 새로운 방법에 대한  내용 서술.</li>
</ul>

<h2 id="problem-formulation">Problem Formulation</h2>

<ul>
  <li>Model scaling은 Baseline 에서 Length(Depth), Width, Resolution 를 확장.</li>
  <li>하지만 실제론 리소스에 제약이 있으니 이에 맞춰 문제를 새롭게, 단순하게 정의.</li>
  <li>Design space를 줄이기 위해 모든 레이어는 상수 값을 이용하여 규칙적으로 변화하도록 함.</li>
  <li>최종 목적은 제한된 리소스에서 성능을 최대화하는 것.</li>
</ul>

<p>[\mathcal{N}: \text{ConvNet} \ \mathcal{F}_i: \text{Layer architecture} \ L_i: \text{Network length} \ C_i: \text{Width} \ H_i, W_i: \text{Input resolution}]</p>

<p>[{max}<em>{d, w, r} Accuracy(\mathcal{N}(d, w, r)) \ s.t. \mathcal{N}(d, w, r) = \bigodot</em>{i=1…s}\hat{\mathcal{F}}<em>i^{d \cdot \hat{L}_i}(X</em>{\langle r\cdot \hat{H}_i, r \cdot \hat{W}_i, w\cdot \hat{C}_i \rangle} ) \ Memory(\mathcal{N}) \leq \text{target memory} \FLOPS(\mathcal{N}) \leq \text{target flops}]</p>

<h2 id="scaling-dimensions">Scaling Dimensions</h2>

<ul>
  <li>두번째 문제는 d, w, r 이 서로 dependent 하고 제한된 리소스에 따라 값이 변화.</li>
  <li>그래서 기존에는 다음 세 개의 요소 중 하나를 변경함.</li>
</ul>

<h3 id="depth-d">Depth (d)</h3>

<ul>
  <li>VGGNet, GoogLeNet, ResNet 등등 레이어를 많이 많이 !</li>
</ul>

<h3 id="width-w">Width (w)</h3>

<ul>
  <li>채널 수를 늘리고 깊이를 줄이는 방식.</li>
  <li>하지만 <strong>higher level feature를 잡기 힘들 수 있음.</strong></li>
</ul>

<h3 id="resolution-r">Resolution (r)</h3>

<ul>
  <li>클수록 더 양질의 패턴을 찾을 수 있음.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_1.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_1.png" /></p>

<ul>
  <li>Observation 1: 이를 통해서 어떤 요소를 증가시키던 성능이 오르는 것을 확인 하지만 Model이 무거워짐.</li>
</ul>

<h2 id="compound-scaling">Compound Scaling</h2>

<ul>
  <li>경험적으로 세 요소가 dependent 하다는 것을 이미 알고 있음.</li>
  <li>다른 depth, resolution 을 이용하여 성능 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_2.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_2.png" /></p>

<ul>
  <li>Observation 2: 세 요소의 balance가 매우 중요..</li>
  <li>다음과 같은 compound scaling method 제안.</li>
</ul>

<p>[\phi: \text{Compound Coefficient} \ depth: d = \alpha^\phi \ width: w = \beta^\phi \ resolution: r = \gamma^\phi \ \text{s.t. }\alpha \cdot \beta^2 \cdot \gamma^2 \approx 2 \ \alpha \ge 1, \beta \ge 1, \gamma \ge 1]</p>

<ul>
  <li>각 값은 small grid search로 결정된 상수 값.</li>
</ul>

<h1 id="efficientnet-architecture">EfficientNet Architecture</h1>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_3.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_3.png" /></p>

<ul>
  <li>EfficientNet-B0 를 baseline network로 하여  Accuracy, FLOPS 둘 다 최적화하도록 multi-objective neural architecture search 적용.
    <ul>
      <li>Step 1
        <ul>
          <li>$\phi$ =1 로 고정</li>
          <li>식 2, 3을 기반으로 하여 small grid search</li>
          <li>EfficientNet-B0에 가장 적합한 값을 $\alpha$=1.2, $\beta$=1.1, $\gamma$=1.15</li>
        </ul>
      </li>
      <li>Step 2
        <ul>
          <li>$\alpha$, $\beta$, $\gamma$를 고정하고 $\phi$를 변경하여 실험.</li>
          <li>Result (ImageNet Result for EfficientNet) 참고</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h1 id="result">Result</h1>

<h2 id="scaling-up-mobilenets-and-resnets">Scaling Up MobileNets and ResNets</h2>

<ul>
  <li>Compound scale 을 증명하기 위해 MobileNet과 ResNet을 이용하여 비교.</li>
  <li>기존의 방법들은 3개중 1개의 요소만 scaling.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_4.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_4.png" /></p>

<h2 id="imagenet-result-for-efficientnet">ImageNet Result for EfficientNet</h2>

<ul>
  <li>Training Setting
    <ul>
      <li>Optimization
        <ul>
          <li>RMSProp</li>
          <li>Decay: 0.9</li>
          <li>Momentum: 0.9</li>
        </ul>
      </li>
      <li>Batch normalization
        <ul>
          <li>Momentum: 0.99</li>
        </ul>
      </li>
      <li>Weight decay: 1e-5</li>
      <li>Initial learning rate: 0.256
        <ul>
          <li>Decay: 0.97 (every 2.4 epochs)</li>
        </ul>
      </li>
      <li>Swish Activation</li>
      <li><a href="https://arxiv.org/abs/1805.09501">AutoAugmentation</a>: 뭔지 모르겠군 1</li>
      <li><a href="https://arxiv.org/abs/1603.09382">Stochastic depth</a>: 뭔지 모르겠군 2
        <ul>
          <li>Drop connect ratio: 0.2</li>
        </ul>
      </li>
      <li>Dropout
        <ul>
          <li>0.2 ~ 0.5 (B0 ~ B7)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>B0부터 B7 까지 성능 비교.</li>
  <li>GPipe에 비해 <strong>8.4배 적고 좋은 성능.</strong></li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_5.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_5.png" /></p>

<ul>
  <li>CPU를 이용한 Inference 속도 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_6.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_6.png" /></p>

<ul>
  <li>모델별 FLOPS-Accuracy curve</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_7.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_7.png" /></p>

<h2 id="transfer-learning-result-for-efficientnet">Transfer Learning Result for EfficientNet</h2>

<ul>
  <li>ImageNet pretrained model 을 이용하여 각종 Dataset을 Transfer learning 한 성능 비교</li>
  <li>사용한 Dataset</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_8.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_8.png" /></p>

<ul>
  <li>Transfer learning 결과</li>
  <li>전체적으로 모델이 가벼움.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_9.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_9.png" /></p>

<ul>
  <li>기존의 모델들과 비교하여 가볍지만 뛰어난 성능을 보임.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_10.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_10.png" /></p>

<h1 id="discussion">Discussion</h1>

<ul>
  <li>EfficientNet-B0 를 이용하여 각기 다른 scaling method를 이용하여 성능 비교</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_11.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_11.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_12.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_12.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/efficientnet/Untitled_13.png" alt="https://jjerry-k.github.io/public/img/efficientnet/Untitled_13.png" /></p>

<h2 id="ps">P.S</h2>

<ul>
  <li>이런 연구는..NAS(Network Architecture Search)가 답..인건가</li>
  <li>근데 이것도 하드웨어가 빵빵해야….. 크흡</li>
</ul>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/05/02/EfficientNet/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/05/02/EfficientNet/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/04/30/CBAM/">
        Review: CBAM
      </a>
    </h1>

    <span class="post-date">30 Apr 2020</span>
     | 
    
    <a href="/blog/tags/#paper" class="post-tag">Paper</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <h1 id="cbam-convolutional-block-attention-module">CBAM: Convolutional Block Attention Module</h1>

<p>Author: Sanghyun Woo, Jongchan Park, Joon-Young Lee, In So Kweon<br />
Date: Jul 17, 2018<br />
URL: https://arxiv.org/abs/1807.06521</p>

<h1 id="introduction">Introduction</h1>

<ul>
  <li>BAM 에서 설명한 것처럼 최근 CNN 성능 향상에 주로 연구되는 요소는 depth, width, cardinality.</li>
  <li>본 논문에선 Convolutional Block Attention Module(CBAM) 제안.</li>
  <li>Convolution을 이용하여 channel, spatial information 을 추출하고 섞어서 사용.</li>
  <li>channel, spatial attention module은 각각 “what”, “where”에 대한 정보를 학습할 수 있음.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cbam/Untitled.png" alt="https://jjerry-k.github.io/public/img/cbam/Untitled.png" /></p>

<h1 id="convolutional-block-attention-module">Convolutional Block Attention Module</h1>

<ul>
  <li>CBAM 의 구조는 다음 사진과 같음.</li>
</ul>

<p>[F: \text{Input feature map} \ F’:\text{Channel attention module feature map} \ F’’: \text{Spatial attention module feature map} \ F’ = M_c(F)\bigotimes F \F’’ = M_s(F’)\bigotimes F’]</p>

<p><img src="https://jjerry-k.github.io/public/img/cbam/Untitled_1.png" alt="https://jjerry-k.github.io/public/img/cbam/Untitled_1.png" /></p>

<h2 id="channel-attention-branch">Channel attention branch</h2>

<p>[M_c(F) = \sigma(MLP(AvgPool(F)) + MLP(MaxPool(F))) \ = \sigma(W1(W0(F^c_{avg})) + W1(W0(F^c_{max})))]</p>

<p>W0 의 output channel 크기: F의 채널 수 / reduction ratio(r)</p>

<p>W1 의 output channel 크기: F의 채널 수</p>

<h2 id="spatial-attention-branch">Spatial attention branch</h2>

<p>[M_s(F)=\sigma(f^{7\times7}([AvgPool(F); MaxPool(F)])) \ = \sigma(f^{7 \times 7}([F^s_{avg};F^s_{max}]))]</p>

<ul>
  <li>7x7 Convolution의 output channel 크기: 1</li>
</ul>

<h2 id="arrangement-of-attention-modules">Arrangement of attention modules</h2>

<ul>
  <li>두 branch의 순서를 어떻게 배열할지 고민.</li>
  <li>실험적으로 Channel → Spatial 로 하기로 함.</li>
</ul>

<h1 id="ablation-study-using-imagenet-1k">Ablation study using ImageNet-1K</h1>

<h2 id="channel-attention">Channel attention</h2>

<ul>
  <li>Pooling 기법별 성능 비교</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cbam/Untitled_2.png" alt="https://jjerry-k.github.io/public/img/cbam/Untitled_2.png" /></p>

<h2 id="spatial-attention">Spatial attention</h2>

<ul>
  <li>Pooling, convolution kernel size 에 따른 성능 비교</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cbam/Untitled_3.png" alt="https://jjerry-k.github.io/public/img/cbam/Untitled_3.png" /></p>

<h2 id="arrangement-of-the-channel-and-spatial-attention">Arrangement of the channel and spatial attention</h2>

<ul>
  <li>Attention module 순서에 따른 성능 비교</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/cbam/Untitled_4.png" alt="https://jjerry-k.github.io/public/img/cbam/Untitled_4.png" /></p>

<h1 id="result">Result</h1>

<h3 id="classification-result-on-imagenet-1k">Classification Result on ImageNet-1K</h3>

<p><img src="https://jjerry-k.github.io/public/img/cbam/Untitled_5.png" alt="https://jjerry-k.github.io/public/img/cbam/Untitled_5.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/cbam/Untitled_6.png" alt="https://jjerry-k.github.io/public/img/cbam/Untitled_6.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/cbam/Untitled_7.png" alt="https://jjerry-k.github.io/public/img/cbam/Untitled_7.png" /></p>

<h3 id="object-detection-on-ms-coco-and-voc-2007">Object Detection on MS COCO and VOC 2007</h3>

<p><img src="https://jjerry-k.github.io/public/img/cbam/Untitled_8.png" alt="https://jjerry-k.github.io/public/img/cbam/Untitled_8.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/cbam/Untitled_9.png" alt="https://jjerry-k.github.io/public/img/cbam/Untitled_9.png" /></p>

<h3 id="network-visualization-with-grad-cam">Network Visualization with Grad-CAM</h3>

<p><img src="https://jjerry-k.github.io/public/img/cbam/Untitled_10.png" alt="https://jjerry-k.github.io/public/img/cbam/Untitled_10.png" /></p>

<h2 id="ps">P.S</h2>

<ul>
  <li>BAM과 동일하게 Original Code가 있지만….논문과 다른 부분이 매우 많음.</li>
</ul>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/04/30/CBAM/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/04/30/CBAM/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/04/29/BAM/">
        Review: BAM
      </a>
    </h1>

    <span class="post-date">29 Apr 2020</span>
     | 
    
    <a href="/blog/tags/#paper" class="post-tag">Paper</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <h1 id="bam-bottleneck-attention-module">BAM: Bottleneck Attention Module</h1>

<p>Author: Jongchan Park, Sanghyun Woo, Joon-Young Lee, In So Kweon<br />
Date: Jul 17, 2018<br />
URL: https://arxiv.org/abs/1807.06514</p>

<h1 id="introduction">Introduction</h1>

<ul>
  <li>
    <p>DL은 Classification, Detection, Segmentation 등 많은 패턴 인식 분야에서 강력한 Tool로 사용.</p>
  </li>
  <li>
    <p>성능을 올리기 위해서 좋은 backbone을 설계하는 것이 기본적인 접근법.</p>
  </li>
  <li>
    <p>직관적인 방법은 더 깊게 설계하는 것.</p>
  </li>
  <li>
    <p>VGGNet는 AlexNet 보다 두배 이상.</p>
  </li>
  <li>
    <p>ResNet 은 VGGNet보다 22배 이상이면서 residual connections 사용하여 gradient flow 를 향상.</p>
  </li>
  <li>
    <p>GoogLeNet 은 매우 깊고 같은 layer에서 다양한 feature를 사용하여 성능 향상.</p>
  </li>
  <li>
    <p>DenseNet 이전 layer의 feature map 들을 concatenation 하여 사용.</p>
  </li>
  <li>
    <p>WideResNet, PyramidNet layer의 channels 를 증가하여 성능 향상.</p>
  </li>
  <li>
    <p>ResNeXt, Xception과 같은 backbone은 grouped convolutions을 이용하여 성능 향상.</p>
  </li>
  <li>
    <p>본 논문에선 attention 의 효과를 보기 위해 기존의 architecture 에 사용하기 쉬운 가벼운 Bottle Attention Module(BAM) 제안</p>
  </li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/bam/Untitled.png" alt="https://jjerry-k.github.io/public/img/bam/Untitled.png" /></p>

<h1 id="bottleneck-attention-module">Bottleneck Attention Module</h1>

<ul>
  <li>BAM 의 구조는 다음 사진과 같음.</li>
</ul>

<p>[F: \text{Input feature map} \ M(F): \text{Attention map} \F’ = F + F\bigotimes M(F) \ M(F) = \sigma(M_c(F) + M_s(F))]</p>

<p><img src="https://jjerry-k.github.io/public/img/bam/Untitled_1.png" alt="https://jjerry-k.github.io/public/img/bam/Untitled_1.png" /></p>

<h2 id="channel-attention-branch">Channel attention branch</h2>

<p>[M_c(F) = BN(MLP(AvgPool(F))) \ = BN(W_1(W_0AvgPool(F) + b_0)+b_1)]</p>

<p>W0 의 output channel 크기: F의 채널 수 / reduction ratio(r)</p>

<p>W1 의 output channel 크기: F의 채널 수</p>

<h2 id="spatial-attention-branch">Spatial attention branch</h2>

<p>[M_s(F)=BN(f_3^{1\times1}(f_2^{3\times3}(f_1^{3\times3}(f_0^{1\times1}(F)))))]</p>

<ul>
  <li>모든 연산은 convolution 연산.</li>
  <li>3x3 Convolution 연산 수행시엔 dilation convolution 사용.</li>
  <li>첫번째~세번째 Convolution 의 output channel 크기: F의 채널 수 / reduction ratio(r)</li>
  <li>마지막 Convolution 의 output channel 크기: 1</li>
</ul>

<h2 id="combine-two-attention-branches">Combine two attention branches</h2>

<p>[M(F) = \sigma(M_c(F) + M_s(F))]</p>

<ul>
  <li>Channel attention branch 출력: 1x1xR</li>
  <li>Spatial attention branch 출력: HxWx1</li>
  <li>두 attention branch를 합치는 방법으로 element-wise summation, multiplication, max operation 고려.</li>
</ul>

<h1 id="ablation-study-using-cifar-100">Ablation study using CIFAR-100</h1>

<h2 id="dilation-value-and-reduction-ratio">Dilation value and Reduction ratio</h2>

<ul>
  <li>Dilation value와 Reduction ratio에 따른 성능 비교</li>
  <li>Table 1 (a)</li>
</ul>

<h2 id="separate-or-combined-branches--combining-methods">Separate or Combined branches &amp; Combining methods</h2>

<ul>
  <li>두 attention branch 사용 방법에 따른 성능 비교</li>
  <li>Table 1 (b)</li>
</ul>

<h2 id="comparison-with-placing-original-convblocks">Comparison with placing original convblocks</h2>

<ul>
  <li>BAM 사용 여부에 따른 성능 비교</li>
  <li>Table 1 (c)</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/bam/Untitled_2.png" alt="https://jjerry-k.github.io/public/img/bam/Untitled_2.png" /></p>

<h2 id="bottleneck-the-efficient-point-to-place-bam">Bottleneck: The efficient point to place BAM</h2>

<ul>
  <li>BAM 사용 위치에 따른 성능 비교.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/bam/Untitled_3.png" alt="https://jjerry-k.github.io/public/img/bam/Untitled_3.png" /></p>

<h1 id="result">Result</h1>

<h2 id="classification-result-on-cifar-100-and-imagenet-1k">Classification Result on CIFAR-100 and ImageNet-1K</h2>

<p><img src="https://jjerry-k.github.io/public/img/bam/Untitled_4.png" alt="https://jjerry-k.github.io/public/img/bam/Untitled_4.png" /></p>

<h2 id="object-detection-on-ms-coco-and-voc-2007">Object Detection on MS COCO and VOC 2007</h2>

<p><img src="https://jjerry-k.github.io/public/img/bam/Untitled_5.png" alt="https://jjerry-k.github.io/public/img/bam/Untitled_5.png" /></p>

<h2 id="comparison-with-squeeze-and-excitation">Comparison with Squeeze-and-Excitation</h2>

<p><img src="https://jjerry-k.github.io/public/img/bam/Untitled_6.png" alt="https://jjerry-k.github.io/public/img/bam/Untitled_6.png" /></p>

<h3 id="ps">P.S</h3>

<ul>
  <li>Original Code가 있지만….논문과 다른 부분이 매우 많음.</li>
</ul>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/04/29/BAM/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/04/29/BAM/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/deeplearning/2020/04/28/MobileNetV3/">
        Review: MobileNet V3
      </a>
    </h1>

    <span class="post-date">28 Apr 2020</span>
     | 
    
    <a href="/blog/tags/#paper" class="post-tag">Paper</a>
    
    

    <h4 style="font-weight: 400; line-height: 1.8;"><article>
      <h1 id="searching-for-mobilenetv3">Searching for MobileNetV3</h1>

<p>Author: Andrew G. Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingxing Tan,
Weijun Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, Quoc V. Le, Hartwig Adam<br />
Date: May 06, 2019<br />
URL: https://arxiv.org/abs/1905.02244</p>

<h1 id="introduction"><strong>Introduction</strong></h1>

<ul>
  <li>Efficient neural network 는 low latency, higher accuracy 와 더불어 전력소모가 줄어들게 하기 때문에 배터리 수명 보존에도 기여.</li>
  <li>이에 힘입어 다음 세대의 더 효율적인 네트워크 제안.</li>
  <li>본 논문에서 중요한 것은 네 가지.
    <ul>
      <li>Complementary search techniques</li>
      <li>New efficient versions of non-linearities practical</li>
      <li>New efficient network design</li>
      <li>New efficient segmentation decoder</li>
    </ul>
  </li>
</ul>

<h1 id="efficient-mobile-building-blocks"><strong>Efficient Mobile Building Blocks</strong></h1>

<ul>
  <li>MobileNetV2의 Inverted residual structure에 <a href="https://arxiv.org/abs/1709.01507">squeeze and excitation</a> 을 추가.</li>
</ul>

<p><img src="https://jjerry-k.github.io/public/img/mobilev3/Untitled.png" alt="https://jjerry-k.github.io/public/img/mobilev3/Untitled.png" /></p>

<h1 id="network-search"><strong>Network Search</strong></h1>

<h2 id="platform-aware-nas-for-block-wise-search"><strong>Platform-Aware NAS for Block-wise Search</strong></h2>

<ul>
  <li>RNN-based controller, factorized hierarchical search space</li>
</ul>

<h2 id="netadapt-for-layer-wise-search"><strong>NetAdapt for Layer-wise Search</strong></h2>

<ol>
  <li>platform-aware NAS로 찾은 Seed network architecture 로 시작.</li>
  <li>매 스텝마다:
(a) 이전의 proposal 에 비해 latency가 최소 a만큼 감소된 새로운 proposal 생성. 
(b) 각 proposal은 이전 스텝의 pre-trained model을 사용하여 새로 제안된 architecture를 채우고 누락된 weight에 대해선 적절한 값으로 채움. 각 proposal 은 T step 동안 finetuning하고 대략적인 accuracy 추출.
(c) 몇몇 metric을 이용하여 최적의 proposal 을 선택.</li>
  <li>목표로하는 latency에 도달할 때까지 반복.</li>
</ol>

<h1 id="network-improvements"><strong>Network Improvements</strong></h1>

<ul>
  <li>Network의 초반, 후반부의 expansive layer 구조 수정.</li>
  <li>새로운 non-linearity fuction 제안.
    <ul>
      <li>h-swish: swish 의 변형 버전, 빠른 계산 속도, 경량화</li>
    </ul>
  </li>
</ul>

<h2 id="redesigning-expensive-layers"><strong>Redesigning Expensive Layers</strong></h2>

<p><img src="https://jjerry-k.github.io/public/img/mobilev3/Untitled_1.png" alt="https://jjerry-k.github.io/public/img/mobilev3/Untitled_01.png" /></p>

<h2 id="nonlinearities"><strong>Nonlinearities</strong></h2>

<ol>
  <li>
    <p>sigmoid → h-swish</p>

\[hard\text{-}swish(x) = x\frac{ReLU6(x + 3)}{6}\]

    <p><img src="https://jjerry-k.github.io/public/img/mobilev3/Untitled_2.png" alt="https://jjerry-k.github.io/public/img/mobilev3/Untitled_02.png" /></p>
  </li>
  <li>
    <p>h-swish 를 deeper layer에서만 사용.</p>
  </li>
</ol>

<p><img src="https://jjerry-k.github.io/public/img/mobilev3/Untitled_3.png" alt="https://jjerry-k.github.io/public/img/mobilev3/Untitled_03.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/mobilev3/Untitled_4.png" alt="https://jjerry-k.github.io/public/img/mobilev3/Untitled_04.png" /></p>

<h2 id="large-squeeze-and-excite"><strong>Large squeeze-and-excite</strong></h2>

<ul>
  <li><a href="https://arxiv.org/abs/1807.11626">MnasNet: Platform-Aware Neural Architecture Search for Mobile</a> 에서 Squeeze-and-Excite(SE) bottleneck 크기만큼 convolutional bottleneck 발생.</li>
  <li>본 논문에선 expansion layer의 채널의 1/4로 고정.</li>
  <li>파라미터 미약하게 증가하면서 정확도 증가.</li>
</ul>

<h1 id="result">Result</h1>

<p><img src="https://jjerry-k.github.io/public/img/mobilev3/Untitled_5.png" alt="https://jjerry-k.github.io/public/img/mobilev3/Untitled_05.png" /></p>

<p><img src="https://jjerry-k.github.io/public/img/mobilev3/Untitled_6.png" alt="https://jjerry-k.github.io/public/img/mobilev3/Untitled_06.png" /></p>

<h3 id="ps">P.S</h3>

<ul>
  <li>Batch size를 4096으로 테스트…. 역시 하드웨어 깡패 구글…</li>
</ul>

    <article></h4>
    <div class="post-more">
      
      <a href="/deeplearning/2020/04/28/MobileNetV3/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/deeplearning/2020/04/28/MobileNetV3/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/blog/page6">Older</a>
  
  
    
      <a class="pagination-item newer" href="/blog/page4">Newer</a>
    
  
</div>


        </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <!-- Modal -->
  <div class="modal fade" id="myModal" role="dialog">
    <div class="modal-dialog">

      <!-- Modal content-->
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal">&times;</button>
          <h4 class="modal-title">Search</h4>
        </div>
        <div class="modal-body">

    <h4><div id="search-container">
      <input type="text" id="search-input" placeholder="검색어 입력" class="input" style="font-size: 1rem; width: 100%; padding: 10px; border: 0px; outline: none; float: left; background: #cecece;" autofocus>
    </div></h4><br>

      <div id="results">
        <h1></h1>
      <ul class="results"></ul>
      </div>
      <br><ul id="results-container"></ul>
    </div>

<!-- Script pointing to jekyll-search.js -->


<script type="text/javascript">
      SimpleJekyllSearch({
        searchInput: document.getElementById('search-input'),
        resultsContainer: document.getElementById('results-container'),
        json: '/dest/search.json',
        searchResultTemplate: '<h4 style="margin-bottom:-0.5rem;"><a class="post-title" style="color:#ac4142;" href="{url}" title="{desc}">{title}</a> <small>{category}</small></h4>',
        noResultsText: '<h4><br>문서가 존재하지 않습니다.</h4>',
        limit: 15,
        fuzzy: false,
        exclude: ['Welcome']
      })
</script>
        </div>
      </div>

    </div>
  </div>

</div>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');
        document.addEventListener('click', function(e) {
          var target = e.target;
          if (target === toggle) {
            checkbox.checked = !checkbox.checked;
            e.preventDefault();
          } else if (checkbox.checked && !sidebar.contains(target)) {
            /* click outside the sidebar when sidebar is open */
            checkbox.checked = false;
          }
        }, false);
      })(document);
    </script>

    
      <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-126636477-1', 'auto');
        ga('send', 'pageview');
      </script>
    

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (absbygoogle = window.adsbygoogle || []).push({
          google_ad_client: "ca-pub-1054696837285307",
          enable_page_level_ads: true
      });
    </script>
  </body>
  
  <script id="dsq-count-scr" src="//jerry.disqus.com/count.js" async></script>
  
</html>
