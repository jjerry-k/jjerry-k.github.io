<!DOCTYPE html>
<html lang="en-us"><head>
  <meta charset="utf-8">
  <!--  google adsense -->
  <script data-ad-client="ca-pub-1054696837285307" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <title>Jerry&#39;s DevLog</title>

  <!-- mobile responsive meta -->
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="this is meta description">
  <meta name="author" content="Jerry Kim">
  <meta name="generator" content="Hugo 0.92.2" />

  <!-- plugins -->
  
  <link rel="stylesheet" href="https://jjerry-k.github.io/plugins/bootstrap/bootstrap.min.css ">
  
  <link rel="stylesheet" href="https://jjerry-k.github.io/plugins/slick/slick.css ">
  
  <link rel="stylesheet" href="https://jjerry-k.github.io/plugins/themify-icons/themify-icons.css ">
  
  <link rel="stylesheet" href="https://jjerry-k.github.io/plugins/venobox/venobox.css ">
  

  <!-- Main Stylesheet -->
  
  <link rel="stylesheet" href="https://jjerry-k.github.io/scss/style.min.css" media="screen">

  <!--Favicon-->
  <link rel="shortcut icon" href="https://jjerry-k.github.io/images/favicon.png " type="image/x-icon">
  <link rel="icon" href="https://jjerry-k.github.io/images/favicon.png " type="image/x-icon">

  
  
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-GFEK5RVZ18"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-GFEK5RVZ18');
  </script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
</head><body>
<!-- preloader start -->
<div class="preloader">
  
  <img src="https://jjerry-k.github.io/images/preloader.gif " alt="preloader">
  
</div>
<!-- preloader end -->
<!-- navigation -->
<header class="navigation">
  <div class="container">
    
    <nav class="navbar navbar-expand-lg navbar-white bg-transparent border-bottom pl-0">
      <a class="navbar-brand mobile-view" href="https://jjerry-k.github.io"><img class="img-fluid"
          src="https://jjerry-k.github.io/images/logo.png" alt="Jerry&#39;s DevLog"></a>
      <button class="navbar-toggler border-0" type="button" data-toggle="collapse" data-target="#navigation">
        <i class="ti-menu h3"></i>
      </button>

      <div class="collapse navbar-collapse text-center" id="navigation">
        <div class="desktop-view">
          <ul class="navbar-nav mr-auto">
            
            <li class="nav-item">
              <a class="nav-link" href="https://www.facebook.com/jerry.kim.566/"><i class="ti-facebook"></i></a>
            </li>
            
            <li class="nav-item">
              <a class="nav-link" href="https://twitter.com/jjerry_k"><i class="ti-twitter-alt"></i></a>
            </li>
            
            <li class="nav-item">
              <a class="nav-link" href="https://www.instagram.com/jjjerry_k/"><i class="ti-instagram"></i></a>
            </li>
            
            <li class="nav-item">
              <a class="nav-link" href="https://github.com/jjerry-k"><i class="ti-github"></i></a>
            </li>
            
            <li class="nav-item">
              <a class="nav-link" href="https://www.linkedin.com/in/jerry-kim-b8804216b/"><i class="ti-linkedin"></i></a>
            </li>
            
          </ul>
        </div>

        <a class="navbar-brand mx-auto desktop-view" href="https://jjerry-k.github.io"><img class="img-fluid"
            src="https://jjerry-k.github.io/images/logo.png" alt="Jerry&#39;s DevLog"></a>

        <ul class="navbar-nav">
          
          
          <li class="nav-item">
            <a class="nav-link" href="https://jjerry-k.github.io/about">About</a>
          </li>
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="https://jjerry-k.github.io/blog">Post</a>
          </li>
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="https://jjerry-k.github.io/contact">Contact</a>
          </li>
          
          
        </ul>

        
        <!-- search -->
        <div class="search pl-lg-4">
          <button id="searchOpen" class="search-btn"><i class="ti-search"></i></button>
          <div class="search-wrapper">
            <form action="https://jjerry-k.github.io/search" class="h-100">
              <input class="search-box px-4" id="search-query" name="s" type="search" placeholder="Type & Hit Enter...">
            </form>
            <button id="searchClose" class="search-close"><i class="ti-close text-dark"></i></button>
          </div>
        </div>
        

        
      </div>
    </nav>
  </div>
</header>
<!-- /navigation -->

<section class="section-sm">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 mx-auto">
        
        <a href="/categories/deeplearning"
          class="text-primary">Deeplearning</a>
        
        <h2>About ONNX</h2>
        <div class="mb-3 post-meta">
          <span>By Jerry Kim</span>
          
          <span class="border-bottom border-primary px-2 mx-1"></span>
          <span>14 May 2024</span>
          
        </div>
        
        <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c0/ONNX_logo_main.png/1200px-ONNX_logo_main.png" class="img-fluid w-100 mb-4" alt="About ONNX">
        
        <div class="content mb-5">
          <p>이번 포스팅은 ONNX(Open Neural Network Exchange) 를 다뤄보려 합니다.</p>
<p>ONNX란 다양한 framework로 만들어진 ML, DL 모델을 공통 포맷으로 맞춰주는 것입니다.</p>
<p>왜 이런게 필요할까요?</p>
<p>예시를 들어보면..</p>
<blockquote>
<h2 id="onnx-사용-x">ONNX 사용 X</h2>
<p>지금까지 TensorFlow로 만들고 배포를 했는데&hellip;<br>
어느 날 PyTorch로 되어있는 모델을 배포해야한다&hellip;<br>
하&hellip;.코드 다시 짜야겠네&hellip;&hellip;..</p>
</blockquote>
<blockquote>
<h2 id="onnx-사용-o">ONNX 사용 O</h2>
<p>(PyTorch 모델 받아서 ONNX로 변환 중&hellip;.)<br>
배포 끝!</p>
</blockquote>
<p>대충 어떤 느낌적인 느낌인지 아시겠죠?</p>
<p>대충 이런 느낌&hellip;</p>
<figure><img src="/images/post/onnx/fig01.png"/>
</figure>

<h2 id="설치법">설치법</h2>
<p>자세한 사항은 다음 <a href="https://github.com/onnx/onnx#installation">링크</a>에 있습니다.<br>
포스팅에는 일부&hellip;만 해볼거에요.<br>
저는 <code>Torch -&gt; ONNX</code>, <code>TensorFlow -&gt; ONNX</code> 둘 다 해볼거기 때문에 GPU 디펜던시가 없도록&hellip;CPU 버전으로 설치하겠습니다.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">conda create -n onnx python<span style="color:#f92672">=</span>3.11
conda activate onnx

<span style="color:#75715e"># PyTorch to ONNX를 위한 패키지</span>
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

<span style="color:#75715e"># TensorFlow to ONNX를 위한 패키지( 버전 호환성 확인 필요 https://github.com/onnx/tensorflow-onnx)</span>
pip install tensorflow<span style="color:#f92672">==</span>2.15 
pip install tf2onnx <span style="color:#75715e"># ONNX도 같이 설치 됩니다.</span>

<span style="color:#75715e"># ONNX 모델을 사용하기 위한 패키지</span>
pip install onnxruntime

<span style="color:#75715e"># 이미지 테스트를 위한 패키지</span>
pip install opencv-python
</code></pre></div><h2 id="변환-예시">변환 예시</h2>
<ul>
<li>각 프레임워크의 모델 Load 부터 Converting 후 변환 전 후 Inference 결과 확인 까지 차례로 진행해보겠습니다.</li>
</ul>
<h3 id="pytorch-to-onnx">PyTorch to ONNX</h3>
<h5 id="1-pytorch-model-load">1. PyTorch model load</h5>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> torchvision
model <span style="color:#f92672">=</span> torchvision<span style="color:#f92672">.</span>models<span style="color:#f92672">.</span>resnet101(weights<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;DEFAULT&#34;</span>)
</code></pre></div><h5 id="2-convert-to-onnx">2. Convert to ONNX</h5>
<ul>
<li>어떠한 shape의 tensor를 입력으로 취하는지 <code>dummy_input</code>을 만들어야합니다.</li>
<li>network의 입력과 출력의 이름을 지정해줘야합니다. (<code>input_name</code>, <code>output_name</code>)</li>
<li>다양한 batch size를 사용할 경우 <code>dynamic_axes</code> 라는 옵션에 입력과 출력의 첫번째 차원을 batch_size로 정의해줍니다.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> torch <span style="color:#f92672">import</span> onnx
dummy_input <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">224</span>)
input_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;input&#34;</span>
output_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;output&#34;</span>
torch<span style="color:#f92672">.</span>onnx<span style="color:#f92672">.</span>export(model, dummy_input, <span style="color:#e6db74">&#34;resnet_torch.onnx&#34;</span>,
                    input_names <span style="color:#f92672">=</span> [input_name], output_names <span style="color:#f92672">=</span> [output_name], 
                    dynamic_axes <span style="color:#f92672">=</span> {input_name : {<span style="color:#ae81ff">0</span> : <span style="color:#e6db74">&#39;batch_size&#39;</span>}, output_name : {<span style="color:#ae81ff">0</span> : <span style="color:#e6db74">&#39;batch_size&#39;</span>}})
print(<span style="color:#e6db74">&#34;Converting complete&#34;</span>)          <span style="color:#75715e"># Converting complete</span>
print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Input name : </span><span style="color:#e6db74">{</span>input_name<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)  <span style="color:#75715e"># Input name : input</span>
print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Output name: </span><span style="color:#e6db74">{</span>output_name<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>) <span style="color:#75715e"># Output name: output</span>
</code></pre></div><h5 id="3-compare-inference-results">3. Compare inference results</h5>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Load saved onnx model</span>
<span style="color:#f92672">import</span> onnxruntime <span style="color:#66d9ef">as</span> ort
tc_sess <span style="color:#f92672">=</span> ort<span style="color:#f92672">.</span>InferenceSession(<span style="color:#e6db74">&#34;resnet_torch.onnx&#34;</span>)

<span style="color:#75715e"># Prepare input image</span>
<span style="color:#f92672">import</span> cv2
<span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
img <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>imread(<span style="color:#e6db74">&#34;cat.png&#34;</span>)
img <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>resize(img, (<span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">224</span>))
img <span style="color:#f92672">=</span> (img[np<span style="color:#f92672">.</span>newaxis, <span style="color:#f92672">...</span>]<span style="color:#f92672">/</span><span style="color:#ae81ff">255.</span>)<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>float32)
img <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>transpose(img, [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>])

<span style="color:#75715e"># Inference two models</span>
<span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
    result_tc <span style="color:#f92672">=</span> model(torch<span style="color:#f92672">.</span>from_numpy(img))<span style="color:#f92672">.</span>numpy()
result_onnx <span style="color:#f92672">=</span> tc_sess<span style="color:#f92672">.</span>run([output_names], {input_name: img})

print()
print(<span style="color:#e6db74">&#34;Compare result&#34;</span>)                                 <span style="color:#75715e"># Compare result</span>
print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;PyTorch: </span><span style="color:#e6db74">{</span>np<span style="color:#f92672">.</span>argmax(result_tc, axis<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)      <span style="color:#75715e"># PyTorch: [283]</span>
print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;ONNX   : </span><span style="color:#e6db74">{</span>np<span style="color:#f92672">.</span>argmax(result_onnx[<span style="color:#ae81ff">0</span>], axis<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>) <span style="color:#75715e"># ONNX   : [283]</span>
</code></pre></div><hr>
<h3 id="tensorflow-to-onnx">TensorFlow to ONNX</h3>
<h5 id="1-tensorflow-mode-load">1. TensorFlow mode load</h5>
<ul>
<li>메세지 관련 코드는 자기 마음입니다.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> os
os<span style="color:#f92672">.</span>environ[<span style="color:#e6db74">&#34;TF_CPP_MIN_LOG_LEVEL&#34;</span>] <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;3&#34;</span> <span style="color:#75715e"># TensorFlow 사용시 warning, error 메세지 없애기 위한 코드</span>

<span style="color:#f92672">from</span> tensorflow.keras.applications <span style="color:#f92672">import</span> ResNet101    
model <span style="color:#f92672">=</span> ResNet101(include_top<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, weights<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;imagenet&#39;</span>)
</code></pre></div><h5 id="2-convert-to-onnx-1">2. Convert to ONNX</h5>
<ul>
<li>network의 입력 이름을 지정해줘야합니다. (<code>input_name</code>)</li>
<li>network의 출력 이름은 network의 layer output 명으로 사용합니다. (<code>output_name</code>)</li>
<li>어떠한 shape의 tensor를 입력으로 취하는지 <code>input_signature</code>을 만들어야합니다.</li>
<li>첫번째 차원에 None을 기입하면 다양한 batch size를 사용할 수 있습니다.</li>
<li>변환시 <code>opset</code> 이라는 변수를 확인해야합니다. (14 ~ 18 지원, 기본값 15 )<br>
참고 자료: <a href="https://github.com/onnx/tensorflow-onnx?tab=readme-ov-file#onnx">https://github.com/onnx/tensorflow-onnx?tab=readme-ov-file#onnx</a></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Converting PyTorch to ONNX</span>
<span style="color:#f92672">import</span> onnx
<span style="color:#f92672">import</span> tf2onnx
<span style="color:#f92672">import</span> tensorflow <span style="color:#66d9ef">as</span> tf

input_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;input&#34;</span>
output_name <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>layers[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>name
input_signature <span style="color:#f92672">=</span> [tf<span style="color:#f92672">.</span>TensorSpec([<span style="color:#66d9ef">None</span>, <span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">3</span>], tf<span style="color:#f92672">.</span>float32, name<span style="color:#f92672">=</span>input_name)]

onnx_model, _ <span style="color:#f92672">=</span> tf2onnx<span style="color:#f92672">.</span>convert<span style="color:#f92672">.</span>from_keras(model, input_signature, opset<span style="color:#f92672">=</span><span style="color:#ae81ff">16</span>)
onnx<span style="color:#f92672">.</span>save(onnx_model, <span style="color:#e6db74">&#34;resnet_tensorflow.onnx&#34;</span>)

print(<span style="color:#e6db74">&#34;Converting complete&#34;</span>)           <span style="color:#75715e"># Converting complete</span>
print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Input name : </span><span style="color:#e6db74">{</span>input_names<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)   <span style="color:#75715e"># Input name : input</span>
print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Output name: </span><span style="color:#e6db74">{</span>output_names<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)  <span style="color:#75715e"># Output name: predictions</span>
</code></pre></div><h5 id="3-compare-inference-results-1">3. Compare inference results</h5>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Compare result</span>
<span style="color:#f92672">import</span> onnxruntime <span style="color:#66d9ef">as</span> ort
tf_sess <span style="color:#f92672">=</span> ort<span style="color:#f92672">.</span>InferenceSession(<span style="color:#e6db74">&#34;resnet_tensorflow.onnx&#34;</span>)

<span style="color:#f92672">import</span> cv2
<span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
img <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>imread(<span style="color:#e6db74">&#34;cat.png&#34;</span>)
img <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>resize(img, (<span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">224</span>))
img <span style="color:#f92672">=</span> (img[np<span style="color:#f92672">.</span>newaxis, <span style="color:#f92672">...</span>]<span style="color:#f92672">/</span><span style="color:#ae81ff">255.</span>)<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>float32)

result_tf <span style="color:#f92672">=</span> model(img)
result_onnx <span style="color:#f92672">=</span> tf_sess<span style="color:#f92672">.</span>run(output_names, {input_names[<span style="color:#ae81ff">0</span>]: img})

print()
print(<span style="color:#e6db74">&#34;Compare result&#34;</span>)                                     <span style="color:#75715e"># Compare result</span>
print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;TensorFlow: </span><span style="color:#e6db74">{</span>np<span style="color:#f92672">.</span>argmax(result_tf, axis<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)       <span style="color:#75715e"># TensorFlow: [499]</span>
print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;ONNX      : </span><span style="color:#e6db74">{</span>np<span style="color:#f92672">.</span>argmax(result_onnx[<span style="color:#ae81ff">0</span>], axis<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)  <span style="color:#75715e"># ONNX      : [499]</span>
</code></pre></div><p>두 프레임워크 모두 변환 전후의 결과가 동일하도록 잘 변환 되었네요!<br>
이번 포스팅에선 정말 간단하게 ONNX에 대해 정말 손톱만 담궈봤습니다.<br>
그럼 이만&hellip;</p>
<h2 id="ps">P.S</h2>
<ul>
<li>모든 모델들이 변환이 가능하진 않습니다&hellip;! 커스텀 레이어까지 변환을 완벽 지원하진 않으니까&hellip;&hellip;&hellip;&hellip;..!</li>
</ul>

        </div>

        
        <div style="text-align:center; margin:20px 0px 20px 0px">
          <a href="https://www.buymeacoffee.com/jjerry" target="_blank">
            <img src="https://jjerry-k.github.io/images/promotion.png" alt="support-btn"
            style="height: 100px !important;width: 100px !important;" />
          </br>
            <span class="caption">도움이 되셨다면 몰랑이에게 밀크티를...! </br> 더 다양한 포스팅을 채우도록 노력할게요!</span>
          </a>
        </div>
        
        
        
<div id="disqus_thread"></div>
<script type="text/javascript">

(function() {
    
    
    if (window.location.hostname == "localhost")
        return;

    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    var disqus_shortname = 'jjerry-k';
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
      </div>
    </div>
  </div>
</section>



<footer>
  <div class="container">
    <div class="row justify-content-center">
      <div class="col-12 text-center mb-5">
        <a href="https://jjerry-k.github.io"><img src="https://jjerry-k.github.io/images/logo.png" alt="Jerry&#39;s DevLog"></a>
      </div>
               
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Contact Me</h6>
        <ul class="list-unstyled">
          
          <li class="mb-3"><a class="text-dark" href="tel:Top%20Secret"><i
                class="ti-mobile mr-3 text-primary"></i>Top Secret</a></li>
          
                     
          <li class="mb-3"><i class="ti-location-pin mr-3 text-primary"></i>Seoul, Korea of Republic</li>
          
                     
          <li class="mb-3"><a class="text-dark" href="mailto:jaeyeol2931@gmail.com"><i
                class="ti-email mr-3 text-primary"></i>jaeyeol2931@gmail.com</a>
          
          </li>
        </ul>
      </div>
      
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Social Contacts</h6>
        <ul class="list-unstyled">
          
          <li class="mb-3"><a class="text-dark" href="https://www.facebook.com/jerry.kim.566/">facebook</a></li>
          
          <li class="mb-3"><a class="text-dark" href="https://twitter.com/jjerry_k">twitter</a></li>
          
          <li class="mb-3"><a class="text-dark" href="https://www.instagram.com/jjjerry_k/">instagram</a></li>
          
          <li class="mb-3"><a class="text-dark" href="https://github.com/jjerry-k">github</a></li>
          
          <li class="mb-3"><a class="text-dark" href="https://www.linkedin.com/in/jerry-kim-b8804216b/">linkedin</a></li>
          
        </ul>
      </div>
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Categories</h6>
        <ul class="list-unstyled">
          <li class="mb-3"><a class="text-dark"
              href="/categories/deeplearning">Deeplearning</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/living">Living</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/project">Project</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/python">Python</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/tech">Tech</a>
          </li>
        </ul>
      </div>
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Quick Links</h6>
        <ul class="list-unstyled">
          
          <li class="mb-3"><a class="text-dark" href="https://jjerry-k.github.io/about">About</a></li>
          
          <li class="mb-3"><a class="text-dark" href="https://jjerry-k.github.io/blog">Post</a></li>
          
          <li class="mb-3"><a class="text-dark" href="https://jjerry-k.github.io/contact">Contact</a></li>
          
        </ul>
      </div>
      <div class="col-12 border-top py-4 text-center">
        | copyright © 2020 <a href="https://themefisher.com">Themefisher</a> All Rights Reserved |
      </div>
    </div>
  </div>
</footer>

<script>
  var indexURL = "https://jjerry-k.github.io/index.json"
</script>

<!-- JS Plugins -->

<script src="https://jjerry-k.github.io/plugins/jQuery/jquery.min.js"></script>

<script src="https://jjerry-k.github.io/plugins/bootstrap/bootstrap.min.js"></script>

<script src="https://jjerry-k.github.io/plugins/slick/slick.min.js"></script>

<script src="https://jjerry-k.github.io/plugins/venobox/venobox.min.js"></script>

<script src="https://jjerry-k.github.io/plugins/search/fuse.min.js"></script>

<script src="https://jjerry-k.github.io/plugins/search/mark.js"></script>

<script src="https://jjerry-k.github.io/plugins/search/search.js"></script>

<!-- Main Script -->

<script src="https://jjerry-k.github.io/js/script.min.js"></script></body>
</html>